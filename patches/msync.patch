diff --git a/wine/dlls/ntdll/Makefile.in b/wine/dlls/ntdll/Makefile.in
index 5db70d19b..f45b1e174 100644
--- a/wine/dlls/ntdll/Makefile.in
+++ b/wine/dlls/ntdll/Makefile.in
@@ -48,6 +48,7 @@ C_SRCS = \
 	unix/env.c \
 	unix/esync.c \
 	unix/file.c \
+	unix/msync.c \
 	unix/loader.c \
 	unix/loadorder.c \
 	unix/process.c \
diff --git a/wine/dlls/ntdll/unix/esync.c b/wine/dlls/ntdll/unix/esync.c
index 500edec7f..b5853649d 100644
--- a/wine/dlls/ntdll/unix/esync.c
+++ b/wine/dlls/ntdll/unix/esync.c
@@ -50,6 +50,7 @@
 
 #include "unix_private.h"
 #include "esync.h"
+#include "msync.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(esync);
 
@@ -58,7 +59,7 @@ int do_esync(void)
     static int do_esync_cached = -1;
 
     if (do_esync_cached == -1)
-        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC")) && !do_msync();;
 
     return do_esync_cached;
 }
@@ -649,6 +650,9 @@ NTSTATUS esync_set_event( HANDLE handle )
     if ((ret = get_object( handle, &obj ))) return ret;
     event = obj->shm;
 
+    if (obj->type != ESYNC_MANUAL_EVENT && obj->type != ESYNC_AUTO_EVENT)
+        return STATUS_OBJECT_TYPE_MISMATCH;
+
     if (obj->type == ESYNC_MANUAL_EVENT)
     {
         /* Acquire the spinlock. */
@@ -976,7 +980,7 @@ static NTSTATUS __esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEA
             return ret;
     }
 
-    if (objs[count - 1] && objs[count - 1]->type == ESYNC_QUEUE)
+    if (count && objs[count - 1] && objs[count - 1]->type == ESYNC_QUEUE)
         msgwait = TRUE;
 
     if (has_esync && has_server)
@@ -1011,7 +1015,7 @@ static NTSTATUS __esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEA
             grab_object( objs[i] );
     }
 
-    if (wait_any || count == 1)
+    if (wait_any || count <= 1)
     {
         /* Try to check objects now, so we can obviate poll() at least. */
         for (i = 0; i < count; i++)
diff --git a/wine/dlls/ntdll/unix/loader.c b/wine/dlls/ntdll/unix/loader.c
index d5901d862..8e54c9942 100644
--- a/wine/dlls/ntdll/unix/loader.c
+++ b/wine/dlls/ntdll/unix/loader.c
@@ -91,6 +91,7 @@
 #include "winternl.h"
 #include "unix_private.h"
 #include "esync.h"
+#include "msync.h"
 #include "wine/list.h"
 #include "wine/debug.h"
 
@@ -2478,6 +2479,7 @@ static void start_main_thread(void)
     signal_init_thread( teb );
     dbg_init();
     startup_info_size = server_init_process();
+    msync_init();
     esync_init();
     virtual_map_user_shared_data();
     init_cpu_info();
diff --git a/wine/dlls/ntdll/unix/loader.c.orig b/wine/dlls/ntdll/unix/loader.c.orig
new file mode 100644
index 000000000..d5901d862
--- /dev/null
+++ b/wine/dlls/ntdll/unix/loader.c.orig
@@ -0,0 +1,2850 @@
+/*
+ * Unix interface for loader functions
+ *
+ * Copyright (C) 2020 Alexandre Julliard
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#if 0
+#pragma makedep unix
+#endif
+
+#include "config.h"
+
+#include <assert.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <stdarg.h>
+#include <stdio.h>
+#include <signal.h>
+#include <string.h>
+#include <stdlib.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <sys/wait.h>
+#include <unistd.h>
+#include <dlfcn.h>
+#ifdef HAVE_PWD_H
+# include <pwd.h>
+#endif
+#ifdef HAVE_ELF_H
+# include <elf.h>
+#endif
+#ifdef HAVE_LINK_H
+# include <link.h>
+#endif
+#ifdef HAVE_SYS_AUXV_H
+# include <sys/auxv.h>
+#endif
+#ifdef HAVE_SYS_RESOURCE_H
+# include <sys/resource.h>
+#endif
+#include <limits.h>
+#ifdef HAVE_SYS_SYSCTL_H
+# include <sys/sysctl.h>
+#endif
+#ifdef __APPLE__
+# include <CoreFoundation/CoreFoundation.h>
+# define LoadResource MacLoadResource
+# define GetCurrentThread MacGetCurrentThread
+# include <CoreServices/CoreServices.h>
+# undef LoadResource
+# undef GetCurrentThread
+# include <pthread.h>
+# include <mach/mach.h>
+# include <mach/mach_error.h>
+# include <mach-o/getsect.h>
+# include <crt_externs.h>
+# include <spawn.h>
+# ifndef _POSIX_SPAWN_DISABLE_ASLR
+#  define _POSIX_SPAWN_DISABLE_ASLR 0x0100
+# endif
+# include <sys/utsname.h>
+#endif
+#ifdef __ANDROID__
+# include <jni.h>
+#endif
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#define NONAMELESSUNION
+#define NONAMELESSSTRUCT
+#include "windef.h"
+#include "winnt.h"
+#include "winbase.h"
+#include "winnls.h"
+#include "winioctl.h"
+#include "winternl.h"
+#include "unix_private.h"
+#include "esync.h"
+#include "wine/list.h"
+#include "wine/debug.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(module);
+
+#ifdef __i386__
+static const char so_dir[] = "/i386-unix";
+#elif defined(__x86_64__)
+static const char so_dir[] = "/x86_64-unix";
+static const char so_dir_32on64[] = "/x86_32on64-unix";
+#elif defined(__arm__)
+static const char so_dir[] = "/arm-unix";
+#elif defined(__aarch64__)
+static const char so_dir[] = "/aarch64-unix";
+#else
+static const char so_dir[] = "";
+#endif
+
+void     (WINAPI *pDbgUiRemoteBreakin)( void *arg ) = NULL;
+NTSTATUS (WINAPI *pKiRaiseUserExceptionDispatcher)(void) = NULL;
+NTSTATUS (WINAPI *pKiUserExceptionDispatcher)(EXCEPTION_RECORD*,CONTEXT*) = NULL;
+void     (WINAPI *pKiUserApcDispatcher)(CONTEXT*,ULONG_PTR,ULONG_PTR,ULONG_PTR,PNTAPCFUNC) = NULL;
+void     (WINAPI *pKiUserCallbackDispatcher)(ULONG,void*,ULONG) = NULL;
+void     (WINAPI *pLdrInitializeThunk)(CONTEXT*,void**,ULONG_PTR,ULONG_PTR) = NULL;
+void     (WINAPI *pRtlUserThreadStart)( PRTL_THREAD_START_ROUTINE entry, void *arg ) = NULL;
+void     (WINAPI *p__wine_ctrl_routine)(void*);
+SYSTEM_DLL_INIT_BLOCK *pLdrSystemDllInitBlock = NULL;
+
+static NTSTATUS (CDECL *p__wine_set_unix_funcs)( int version, const struct unix_funcs *funcs );
+static void *p__wine_syscall_dispatcher;
+
+extern typeof(NtReadFile) __wine_rpc_NtReadFile;
+
+static void * const syscalls[] =
+{
+    NtAcceptConnectPort,
+    NtAccessCheck,
+    NtAccessCheckAndAuditAlarm,
+    NtAddAtom,
+    NtAdjustGroupsToken,
+    NtAdjustPrivilegesToken,
+    NtAlertResumeThread,
+    NtAlertThread,
+    NtAlertThreadByThreadId,
+    NtAllocateLocallyUniqueId,
+    NtAllocateUuids,
+    NtAllocateVirtualMemory,
+    NtAllocateVirtualMemoryEx,
+    NtAreMappedFilesTheSame,
+    NtAssignProcessToJobObject,
+    NtCallbackReturn,
+    NtCancelIoFile,
+    NtCancelIoFileEx,
+    NtCancelTimer,
+    NtClearEvent,
+    NtClose,
+    NtCompareObjects,
+    NtCompleteConnectPort,
+    NtConnectPort,
+    NtContinue,
+    NtCreateDebugObject,
+    NtCreateDirectoryObject,
+    NtCreateEvent,
+    NtCreateFile,
+    NtCreateIoCompletion,
+    NtCreateJobObject,
+    NtCreateKey,
+    NtCreateKeyTransacted,
+    NtCreateKeyedEvent,
+    NtCreateLowBoxToken,
+    NtCreateMailslotFile,
+    NtCreateMutant,
+    NtCreateNamedPipeFile,
+    NtCreatePagingFile,
+    NtCreatePort,
+    NtCreateSection,
+    NtCreateSemaphore,
+    NtCreateSymbolicLinkObject,
+    NtCreateThread,
+    NtCreateThreadEx,
+    NtCreateTimer,
+    NtCreateUserProcess,
+    NtDebugActiveProcess,
+    NtDebugContinue,
+    NtDelayExecution,
+    NtDeleteAtom,
+    NtDeleteFile,
+    NtDeleteKey,
+    NtDeleteValueKey,
+    NtDeviceIoControlFile,
+    NtDisplayString,
+    NtDuplicateObject,
+    NtDuplicateToken,
+    NtEnumerateKey,
+    NtEnumerateValueKey,
+    NtFilterToken,
+    NtFindAtom,
+    NtFlushBuffersFile,
+    NtFlushInstructionCache,
+    NtFlushKey,
+    NtFlushProcessWriteBuffers,
+    NtFlushVirtualMemory,
+    NtFreeVirtualMemory,
+    NtFsControlFile,
+    NtGetContextThread,
+    NtGetCurrentProcessorNumber,
+    NtGetNextThread,
+    NtGetNlsSectionPtr,
+    NtGetWriteWatch,
+    NtImpersonateAnonymousToken,
+    NtInitializeNlsFiles,
+    NtInitiatePowerAction,
+    NtIsProcessInJob,
+    NtListenPort,
+    NtLoadDriver,
+    NtLoadKey,
+    NtLoadKey2,
+    NtLockFile,
+    NtLockVirtualMemory,
+    NtMakeTemporaryObject,
+    NtMapViewOfSection,
+    NtNotifyChangeDirectoryFile,
+    NtNotifyChangeKey,
+    NtNotifyChangeMultipleKeys,
+    NtOpenDirectoryObject,
+    NtOpenEvent,
+    NtOpenFile,
+    NtOpenIoCompletion,
+    NtOpenJobObject,
+    NtOpenKey,
+    NtOpenKeyEx,
+    NtOpenKeyTransacted,
+    NtOpenKeyTransactedEx,
+    NtOpenKeyedEvent,
+    NtOpenMutant,
+    NtOpenProcess,
+    NtOpenProcessToken,
+    NtOpenProcessTokenEx,
+    NtOpenSection,
+    NtOpenSemaphore,
+    NtOpenSymbolicLinkObject ,
+    NtOpenThread,
+    NtOpenThreadToken,
+    NtOpenThreadTokenEx,
+    NtOpenTimer,
+    NtPowerInformation,
+    NtPrivilegeCheck,
+    NtProtectVirtualMemory,
+    NtPulseEvent,
+    NtQueryAttributesFile,
+    NtQueryDefaultLocale,
+    NtQueryDefaultUILanguage,
+    NtQueryDirectoryFile,
+    NtQueryDirectoryObject,
+    NtQueryEaFile,
+    NtQueryEvent,
+    NtQueryFullAttributesFile,
+    NtQueryInformationAtom,
+    NtQueryInformationFile,
+    NtQueryInformationJobObject,
+    NtQueryInformationProcess,
+    NtQueryInformationThread,
+    NtQueryInformationToken,
+    NtQueryInstallUILanguage,
+    NtQueryIoCompletion,
+    NtQueryKey,
+    NtQueryLicenseValue,
+    NtQueryMultipleValueKey,
+    NtQueryMutant,
+    NtQueryObject,
+    NtQueryPerformanceCounter,
+    NtQuerySection,
+    NtQuerySecurityObject,
+    NtQuerySemaphore ,
+    NtQuerySymbolicLinkObject,
+    NtQuerySystemEnvironmentValue,
+    NtQuerySystemEnvironmentValueEx,
+    NtQuerySystemInformation,
+    NtQuerySystemInformationEx,
+    NtQuerySystemTime,
+    NtQueryTimer,
+    NtQueryTimerResolution,
+    NtQueryValueKey,
+    NtQueryVirtualMemory,
+    NtQueryVolumeInformationFile,
+    NtQueueApcThread,
+    NtRaiseException,
+    NtRaiseHardError,
+    NtReadFile,
+    NtReadFileScatter,
+    NtReadVirtualMemory,
+    NtRegisterThreadTerminatePort,
+    NtReleaseKeyedEvent,
+    NtReleaseMutant,
+    NtReleaseSemaphore,
+    NtRemoveIoCompletion,
+    NtRemoveIoCompletionEx,
+    NtRemoveProcessDebug,
+    NtRenameKey,
+    NtReplaceKey,
+    NtReplyWaitReceivePort,
+    NtRequestWaitReplyPort,
+    NtResetEvent,
+    NtResetWriteWatch,
+    NtRestoreKey,
+    NtResumeProcess,
+    NtResumeThread,
+    NtSaveKey,
+    NtSecureConnectPort,
+    NtSetContextThread,
+    NtSetDebugFilterState,
+    NtSetDefaultLocale,
+    NtSetDefaultUILanguage,
+    NtSetEaFile,
+    NtSetEvent,
+    NtSetInformationDebugObject,
+    NtSetInformationFile,
+    NtSetInformationJobObject,
+    NtSetInformationKey,
+    NtSetInformationObject,
+    NtSetInformationProcess,
+    NtSetInformationThread,
+    NtSetInformationToken,
+    NtSetIntervalProfile,
+    NtSetIoCompletion,
+    NtSetLdtEntries,
+    NtSetSecurityObject,
+    NtSetSystemInformation,
+    NtSetSystemTime,
+    NtSetThreadExecutionState,
+    NtSetTimer,
+    NtSetTimerResolution,
+    NtSetValueKey,
+    NtSetVolumeInformationFile,
+    NtShutdownSystem,
+    NtSignalAndWaitForSingleObject,
+    NtSuspendProcess,
+    NtSuspendThread,
+    NtSystemDebugControl,
+    NtTerminateJobObject,
+    NtTerminateProcess,
+    NtTerminateThread,
+    NtTestAlert,
+    NtTraceControl,
+    NtUnloadDriver,
+    NtUnloadKey,
+    NtUnlockFile,
+    NtUnlockVirtualMemory,
+    NtUnmapViewOfSection,
+    NtWaitForAlertByThreadId,
+    NtWaitForDebugEvent,
+    NtWaitForKeyedEvent,
+    NtWaitForMultipleObjects,
+    NtWaitForSingleObject,
+#ifndef _WIN64
+    NtWow64AllocateVirtualMemory64,
+    NtWow64GetNativeSystemInformation,
+    NtWow64ReadVirtualMemory64,
+    NtWow64WriteVirtualMemory64,
+#endif
+    NtWriteFile,
+    NtWriteFileGather,
+    NtWriteVirtualMemory,
+    NtYieldExecution,
+    __wine_dbg_write,
+    __wine_rpc_NtReadFile,
+    __wine_unix_call,
+    __wine_unix_spawnvp,
+    wine_nt_to_unix_file_name,
+    wine_server_call,
+    wine_server_fd_to_handle,
+    wine_server_handle_to_fd,
+    wine_unix_to_nt_file_name,
+};
+
+static BYTE syscall_args[ARRAY_SIZE(syscalls)];
+
+SYSTEM_SERVICE_TABLE KeServiceDescriptorTable[4];
+
+#ifdef __GNUC__
+static void fatal_error( const char *err, ... ) __attribute__((noreturn, format(printf,1,2)));
+#endif
+
+#if defined(linux) || defined(__APPLE__)
+static const BOOL use_preloader = TRUE;
+#else
+static const BOOL use_preloader = FALSE;
+#endif
+
+static char *argv0;
+static const char *bin_dir;
+static const char *dll_dir;
+static const char *ntdll_dir;
+static SIZE_T dll_path_maxlen;
+static int *p___wine_main_argc;
+static char ***p___wine_main_argv;
+static WCHAR ***p___wine_main_wargv;
+
+const char *home_dir = NULL;
+const char *data_dir = NULL;
+const char *build_dir = NULL;
+const char *config_dir = NULL;
+const char **dll_paths = NULL;
+const char **system_dll_paths = NULL;
+const char *user_name = NULL;
+SECTION_IMAGE_INFORMATION main_image_info = { NULL };
+static HMODULE ntdll_module;
+static const IMAGE_EXPORT_DIRECTORY *ntdll_exports;
+
+/* adjust an array of pointers to make them into RVAs */
+static inline void fixup_rva_ptrs( void *array, BYTE *base, unsigned int count )
+{
+    BYTE **src = array;
+    DWORD *dst = array;
+
+    for ( ; count; count--, src++, dst++) *dst = *src ? *src - base : 0;
+}
+
+/* adjust an array of 32-bit pointers to make them into RVAs */
+static inline void fixup_rva_ptrs32( void *array, BYTE *base, unsigned int count )
+{
+    BYTE *src = array;
+    BYTE *dst = array;
+
+    for ( ; count; count--, src+=sizeof(DWORD), dst+=sizeof(DWORD))
+    {
+        DWORD srcptr = *(DWORD*)src;
+        *(DWORD*)dst = srcptr ? (BYTE *)UIntToPtr(srcptr) - base : 0;
+    }
+}
+
+
+/* fixup an array of RVAs by adding the specified delta */
+static inline void fixup_rva_dwords( DWORD *ptr, int delta, unsigned int count )
+{
+    for ( ; count; count--, ptr++) if (*ptr) *ptr += delta;
+}
+
+/* fixup an array of 32-bit RVAs by adding the specified delta */
+static inline void fixup_rva_dwords32( DWORD *dptr, int delta, unsigned int count )
+{
+    BYTE *ptr = (BYTE *)dptr;
+    for ( ; count; count--, ptr+=sizeof(DWORD))
+        if (*(DWORD*)ptr) *(DWORD*)ptr += delta;
+}
+
+
+/* fixup an array of name/ordinal RVAs by adding the specified delta */
+static inline void fixup_rva_names( UINT_PTR *ptr, int delta )
+{
+    for ( ; *ptr; ptr++) if (!(*ptr & IMAGE_ORDINAL_FLAG)) *ptr += delta;
+}
+
+/* fixup an array of name/ordinal 32-bit RVAs by adding the specified delta */
+static inline void fixup_rva_names32( UINT_PTR *uiptr, int delta )
+{
+    BYTE *ptr = (BYTE *)uiptr;
+    for ( ; *(UINT*)ptr; ptr+=4) if (!(*(UINT*)ptr & IMAGE_ORDINAL_FLAG32)) *(UINT*)ptr += delta;
+#ifdef __x86_64__
+    /* 32-bit .so DLL on x86_64 must be a hybrid Winelib dll */
+    ptr+=4;
+    for ( ; *(UINT*)ptr; ptr+=4) if (!(*(UINT*)ptr & IMAGE_ORDINAL_FLAG32)) *(UINT*)ptr += delta;
+#endif
+}
+
+
+/* fixup RVAs in the resource directory */
+static void fixup_so_resources( IMAGE_RESOURCE_DIRECTORY *dir, BYTE *root, int delta )
+{
+    IMAGE_RESOURCE_DIRECTORY_ENTRY *entry = (IMAGE_RESOURCE_DIRECTORY_ENTRY *)(dir + 1);
+    unsigned int i;
+
+    for (i = 0; i < dir->NumberOfNamedEntries + dir->NumberOfIdEntries; i++, entry++)
+    {
+        void *ptr = root + entry->u2.s2.OffsetToDirectory;
+        if (entry->u2.s2.DataIsDirectory) fixup_so_resources( ptr, root, delta );
+        else fixup_rva_dwords( &((IMAGE_RESOURCE_DATA_ENTRY *)ptr)->OffsetToData, delta, 1 );
+    }
+}
+
+/* fixup 32-bit RVAs in the resource directory */
+static void fixup_so_resources32( IMAGE_RESOURCE_DIRECTORY *dir, BYTE *root, int delta )
+{
+    IMAGE_RESOURCE_DIRECTORY_ENTRY *entry = (IMAGE_RESOURCE_DIRECTORY_ENTRY *)(dir + 1);
+    unsigned int i;
+
+    for (i = 0; i < dir->NumberOfNamedEntries + dir->NumberOfIdEntries; i++, entry++)
+    {
+        void *ptr = root + entry->u2.s2.OffsetToDirectory;
+        if (entry->u2.s2.DataIsDirectory) fixup_so_resources32( ptr, root, delta );
+        else fixup_rva_dwords32( &((IMAGE_RESOURCE_DATA_ENTRY *)ptr)->OffsetToData, delta, 1 );
+    }
+}
+
+
+/* die on a fatal error; use only during initialization */
+static void fatal_error( const char *err, ... )
+{
+    va_list args;
+
+    va_start( args, err );
+    fprintf( stderr, "wine: " );
+    vfprintf( stderr, err, args );
+    va_end( args );
+    exit(1);
+}
+
+static void fixup_so_32on64_sels( void *handle, const char *name )
+{
+/* Each hybrid Winelib .so has its own copy of the selectors, set them here. */
+#if defined(__APPLE__) && defined(__x86_64__)
+    unsigned short *cs32, *cs64, *ds32;
+    cs32 = dlsym( handle, "wine_32on64_cs32" );
+    cs64 = dlsym( handle, "wine_32on64_cs64" );
+    ds32 = dlsym( handle, "wine_32on64_ds32" );
+
+    if (cs32) *cs32 = cs32_sel;
+    if (cs64) *cs64 = cs64_sel;
+    if (ds32) *ds32 = ds32_sel;
+#endif
+}
+
+static void set_max_limit( int limit )
+{
+    struct rlimit rlimit;
+
+    if (!getrlimit( limit, &rlimit ))
+    {
+        rlimit.rlim_cur = rlimit.rlim_max;
+        if (setrlimit( limit, &rlimit ) != 0)
+        {
+#if defined(__APPLE__) && defined(RLIMIT_NOFILE) && defined(OPEN_MAX)
+            /* On Leopard, setrlimit(RLIMIT_NOFILE, ...) fails on attempts to set
+             * rlim_cur above OPEN_MAX (even if rlim_max > OPEN_MAX). */
+            if (limit == RLIMIT_NOFILE && rlimit.rlim_cur > OPEN_MAX)
+            {
+                rlimit.rlim_cur = OPEN_MAX;
+                setrlimit( limit, &rlimit );
+            }
+#endif
+        }
+    }
+}
+
+/* canonicalize path and return its directory name */
+static char *realpath_dirname( const char *name )
+{
+    char *p, *fullpath = realpath( name, NULL );
+
+    if (fullpath)
+    {
+        p = strrchr( fullpath, '/' );
+        if (p == fullpath) p++;
+        if (p) *p = 0;
+    }
+    return fullpath;
+}
+
+/* if string ends with tail, remove it */
+static char *remove_tail( const char *str, const char *tail )
+{
+    size_t len = strlen( str );
+    size_t tail_len = strlen( tail );
+    char *ret;
+
+    if (len < tail_len) return NULL;
+    if (strcmp( str + len - tail_len, tail )) return NULL;
+    ret = malloc( len - tail_len + 1 );
+    memcpy( ret, str, len - tail_len );
+    ret[len - tail_len] = 0;
+    return ret;
+}
+
+/* build a path from the specified dir and name */
+static char *build_path( const char *dir, const char *name )
+{
+    size_t len = strlen( dir );
+    char *ret = malloc( len + strlen( name ) + 2 );
+
+    memcpy( ret, dir, len );
+    if (len && ret[len - 1] != '/') ret[len++] = '/';
+    if (name[0] == '/') name++;
+    strcpy( ret + len, name );
+    return ret;
+}
+
+
+static const char *get_pe_dir( WORD machine )
+{
+    if (!machine) machine = current_machine;
+
+    switch(machine)
+    {
+    case IMAGE_FILE_MACHINE_I386:  return "/i386-windows";
+    case IMAGE_FILE_MACHINE_AMD64: return "/x86_64-windows";
+    case IMAGE_FILE_MACHINE_ARMNT: return "/arm-windows";
+    case IMAGE_FILE_MACHINE_ARM64: return "/aarch64-windows";
+    default: return "";
+    }
+}
+
+
+static void set_dll_path(void)
+{
+    char *p, *path = getenv( "WINEDLLPATH" );
+    int i, count = 0;
+
+    if (path) for (p = path, count = 1; *p; p++) if (*p == ':') count++;
+
+    dll_paths = malloc( (count + 2) * sizeof(*dll_paths) );
+    count = 0;
+
+    if (!build_dir) dll_paths[count++] = dll_dir;
+
+    if (path)
+    {
+        path = strdup(path);
+        for (p = strtok( path, ":" ); p; p = strtok( NULL, ":" )) dll_paths[count++] = strdup( p );
+        free( path );
+    }
+
+    for (i = 0; i < count; i++) dll_path_maxlen = max( dll_path_maxlen, strlen(dll_paths[i]) );
+    dll_paths[count] = NULL;
+}
+
+
+static void set_system_dll_path(void)
+{
+    const char *p, *path = SYSTEMDLLPATH;
+    int count = 0;
+
+    if (path && *path) for (p = path, count = 1; *p; p++) if (*p == ':') count++;
+
+    system_dll_paths = malloc( (count + 1) * sizeof(*system_dll_paths) );
+    count = 0;
+
+    if (path && *path)
+    {
+        char *path_copy = strdup(path);
+        for (p = strtok( path_copy, ":" ); p; p = strtok( NULL, ":" ))
+            system_dll_paths[count++] = strdup( p );
+        free( path_copy );
+    }
+    system_dll_paths[count] = NULL;
+}
+
+
+static void set_home_dir(void)
+{
+    const char *home = getenv( "HOME" );
+    const char *name = getenv( "USER" );
+    const char *p;
+
+    if (!home || !name)
+    {
+        struct passwd *pwd = getpwuid( getuid() );
+        if (pwd)
+        {
+            if (!home) home = pwd->pw_dir;
+            if (!name) name = pwd->pw_name;
+        }
+        if (!name) name = "wine";
+    }
+    if ((p = strrchr( name, '/' ))) name = p + 1;
+    if ((p = strrchr( name, '\\' ))) name = p + 1;
+    home_dir = strdup( home );
+    user_name = strdup( name );
+}
+
+
+static void set_config_dir(void)
+{
+    char *p, *dir;
+    const char *prefix = getenv( "WINEPREFIX" );
+
+    if (prefix)
+    {
+        if (prefix[0] != '/')
+            fatal_error( "invalid directory %s in WINEPREFIX: not an absolute path\n", prefix );
+        config_dir = dir = strdup( prefix );
+        for (p = dir + strlen(dir) - 1; p > dir && *p == '/'; p--) *p = 0;
+    }
+    else
+    {
+        if (!home_dir) fatal_error( "could not determine your home directory\n" );
+        if (home_dir[0] != '/') fatal_error( "the home directory %s is not an absolute path\n", home_dir );
+        config_dir = build_path( home_dir, ".wine" );
+    }
+}
+
+static void init_paths( char *argv[] )
+{
+    Dl_info info;
+
+    argv0 = strdup( argv[0] );
+
+    if (!dladdr( init_paths, &info ) || !(ntdll_dir = realpath_dirname( info.dli_fname )))
+        fatal_error( "cannot get path to ntdll.so\n" );
+
+    if (!(build_dir = remove_tail( ntdll_dir, "/dlls/ntdll" )))
+    {
+        if (!(dll_dir = remove_tail( ntdll_dir, so_dir ))) dll_dir = ntdll_dir;
+#if (defined(__linux__) && !defined(__ANDROID__)) || defined(__FreeBSD_kernel__) || defined(__NetBSD__)
+        bin_dir = realpath_dirname( "/proc/self/exe" );
+#elif defined (__FreeBSD__) || defined(__DragonFly__)
+        {
+            static int pathname[] = { CTL_KERN, KERN_PROC, KERN_PROC_PATHNAME, -1 };
+            size_t path_size = PATH_MAX;
+            char *path = malloc( path_size );
+            if (path && !sysctl( pathname, sizeof(pathname)/sizeof(pathname[0]), path, &path_size, NULL, 0 ))
+                bin_dir = realpath_dirname( path );
+            free( path );
+        }
+#else
+        bin_dir = realpath_dirname( argv0 );
+#endif
+        if (!bin_dir) bin_dir = build_path( dll_dir, DLL_TO_BINDIR );
+        data_dir = build_path( bin_dir, BIN_TO_DATADIR );
+    }
+
+    set_dll_path();
+    set_system_dll_path();
+    set_home_dir();
+    set_config_dir();
+}
+
+/* whether to use wow64 for i386 EXEs or launch a 32-bit wine */
+BOOL needs_wow64(void)
+{
+#if defined(__APPLE__) && defined(__x86_64__)
+    static int result = -1;
+    struct utsname name;
+    unsigned major, minor;
+
+    if (result == -1)
+    {
+        result = (uname(&name) == 0 &&
+                  sscanf(name.release, "%u.%u", &major, &minor) == 2 &&
+                  major >= 19 /* macOS 10.15 Catalina */);
+    }
+    return (result == 1) ? TRUE : FALSE;
+#else
+    return FALSE;
+#endif
+}
+
+
+static void preloader_exec( char **argv )
+{
+    if (use_preloader)
+    {
+        static const char *preloader = "wine-preloader";
+        char *p;
+
+        if (!(p = strrchr( argv[1], '/' ))) p = argv[1];
+        else p++;
+
+        if (strlen(p) > 2 && !strcmp( p + strlen(p) - 2, "64" )) preloader = "wine64-preloader";
+        argv[0] = malloc( p - argv[1] + strlen(preloader) + 1 );
+        memcpy( argv[0], argv[1], p - argv[1] );
+        strcpy( argv[0] + (p - argv[1]), preloader );
+
+#ifdef __APPLE__
+        {
+            posix_spawnattr_t attr;
+            posix_spawnattr_init( &attr );
+            posix_spawnattr_setflags( &attr, POSIX_SPAWN_SETEXEC | _POSIX_SPAWN_DISABLE_ASLR );
+            posix_spawn( NULL, argv[0], NULL, &attr, argv, *_NSGetEnviron() );
+            posix_spawnattr_destroy( &attr );
+        }
+#endif
+        execv( argv[0], argv );
+        free( argv[0] );
+    }
+    execv( argv[1], argv + 1 );
+}
+
+static NTSTATUS loader_exec( const char *loader, char **argv, WORD machine )
+{
+    char *p, *path;
+
+    if (build_dir)
+    {
+        argv[1] = build_path( build_dir, (machine == IMAGE_FILE_MACHINE_AMD64) ? "loader/wine64" : needs_wow64() ? "loader/wine64" : "loader/wine" );
+        preloader_exec( argv );
+        return STATUS_INVALID_IMAGE_FORMAT;
+    }
+
+    if ((p = strrchr( loader, '/' ))) loader = p + 1;
+
+    argv[1] = build_path( bin_dir, loader );
+    preloader_exec( argv );
+
+    argv[1] = getenv( "WINELOADER" );
+    if (argv[1]) preloader_exec( argv );
+
+    if ((path = getenv( "PATH" )))
+    {
+        for (p = strtok( strdup( path ), ":" ); p; p = strtok( NULL, ":" ))
+        {
+            argv[1] = build_path( p, loader );
+            preloader_exec( argv );
+        }
+    }
+
+    argv[1] = build_path( BINDIR, loader );
+    preloader_exec( argv );
+    return STATUS_INVALID_IMAGE_FORMAT;
+}
+
+
+/***********************************************************************
+ *           exec_wineloader
+ *
+ * argv[0] and argv[1] must be reserved for the preloader and loader respectively.
+ */
+NTSTATUS exec_wineloader( char **argv, int socketfd, const pe_image_info_t *pe_info )
+{
+    WORD machine = pe_info->machine;
+    ULONGLONG res_start = pe_info->base;
+    ULONGLONG res_end = pe_info->base + pe_info->map_size;
+    const char *loader = argv0;
+    const char *loader_env = getenv( "WINELOADER" );
+    char preloader_reserve[64], socket_env[64];
+    BOOL is_child_64bit;
+
+    if (pe_info->image_flags & IMAGE_FLAGS_WineFakeDll) res_start = res_end = 0;
+    if (pe_info->image_flags & IMAGE_FLAGS_ComPlusNativeReady) machine = native_machine;
+
+    is_child_64bit = is_machine_64bit( machine );
+
+    if ((!is_win64 ^ !is_child_64bit) && !needs_wow64())
+    {
+        /* remap WINELOADER to the alternate 32/64-bit version if necessary */
+        if (loader_env)
+        {
+            int len = strlen( loader_env );
+            char *env = malloc( sizeof("WINELOADER=") + len + 2 );
+
+            if (!env) return STATUS_NO_MEMORY;
+            strcpy( env, "WINELOADER=" );
+            strcat( env, loader_env );
+            if (is_child_64bit)
+            {
+                strcat( env, "64" );
+            }
+            else
+            {
+                len += sizeof("WINELOADER=") - 1;
+                if (!strcmp( env + len - 2, "64" )) env[len - 2] = 0;
+            }
+            loader = env;
+            putenv( env );
+        }
+        else loader = is_child_64bit ? "wine64" : needs_wow64() ? "wine64" : "wine";
+    }
+
+    signal( SIGPIPE, SIG_DFL );
+
+    sprintf( socket_env, "WINESERVERSOCKET=%u", socketfd );
+    sprintf( preloader_reserve, "WINEPRELOADRESERVE=%x%08x-%x%08x",
+             (ULONG)(res_start >> 32), (ULONG)res_start, (ULONG)(res_end >> 32), (ULONG)res_end );
+
+    putenv( preloader_reserve );
+    putenv( socket_env );
+
+    return loader_exec( loader, argv, machine );
+}
+
+
+/***********************************************************************
+ *           exec_wineserver
+ *
+ * Exec a new wine server.
+ */
+static void exec_wineserver( char **argv )
+{
+    char *path;
+
+    if (build_dir)
+    {
+        if (!is_win64)  /* look for 64-bit server */
+        {
+            char *loader = realpath_dirname( build_path( build_dir, "loader/wine64" ));
+            if (loader)
+            {
+                argv[0] = build_path( loader, "../server/wineserver" );
+                execv( argv[0], argv );
+            }
+        }
+        argv[0] = build_path( build_dir, "server/wineserver" );
+        execv( argv[0], argv );
+        return;
+    }
+
+    argv[0] = build_path( bin_dir, "wineserver" );
+    execv( argv[0], argv );
+
+    argv[0] = getenv( "WINESERVER" );
+    if (argv[0]) execv( argv[0], argv );
+
+    if ((path = getenv( "PATH" )))
+    {
+        for (path = strtok( strdup( path ), ":" ); path; path = strtok( NULL, ":" ))
+        {
+            argv[0] = build_path( path, "wineserver" );
+            execvp( argv[0], argv );
+        }
+    }
+
+    argv[0] = build_path( BINDIR, "wineserver" );
+    execv( argv[0], argv );
+}
+
+
+/***********************************************************************
+ *           start_server
+ *
+ * Start a new wine server.
+ */
+void start_server( BOOL debug )
+{
+    static BOOL started;  /* we only try once */
+    char *argv[3];
+    static char debug_flag[] = "-d";
+
+    if (!started)
+    {
+        int status;
+        int pid = fork();
+        if (pid == -1) fatal_error( "fork: %s", strerror(errno) );
+        if (!pid)
+        {
+            argv[1] = debug ? debug_flag : NULL;
+            argv[2] = NULL;
+            exec_wineserver( argv );
+            fatal_error( "could not exec wineserver\n" );
+        }
+        waitpid( pid, &status, 0 );
+        status = WIFEXITED(status) ? WEXITSTATUS(status) : 1;
+        if (status == 2) return;  /* server lock held by someone else, will retry later */
+        if (status) exit(status);  /* server failed */
+        started = TRUE;
+    }
+}
+
+
+/*************************************************************************
+ *		map_so_dll
+ *
+ * Map a builtin dll in memory and fixup RVAs.
+ */
+static NTSTATUS map_so_dll( const IMAGE_NT_HEADERS *nt_descr, HMODULE module )
+{
+    static const char builtin_signature[32] = "Wine builtin DLL";
+    IMAGE_DATA_DIRECTORY *dir;
+    IMAGE_DOS_HEADER *dos;
+    IMAGE_NT_HEADERS *nt = NULL;
+    IMAGE_NT_HEADERS32 *nt32 = NULL;
+    IMAGE_SECTION_HEADER *sec;
+    BYTE *addr = (BYTE *)module;
+    DWORD code_start, code_end, data_start, data_end, align_mask;
+    int delta, nb_sections = 2;  /* code + data */
+    unsigned int i;
+    DWORD size = (sizeof(IMAGE_DOS_HEADER)
+                  + sizeof(builtin_signature)
+                  + nb_sections * sizeof(IMAGE_SECTION_HEADER));
+
+    dos = (IMAGE_DOS_HEADER *)addr;
+
+    if (nt_descr->OptionalHeader.Magic == IMAGE_NT_OPTIONAL_HDR32_MAGIC)
+    {
+        nt32  = (IMAGE_NT_HEADERS32 *)((BYTE *)(dos + 1) + sizeof(builtin_signature));
+        size += sizeof(IMAGE_NT_HEADERS32);
+        sec   = (IMAGE_SECTION_HEADER *)(nt32 + 1);
+    }
+    else
+    {
+        nt    = (IMAGE_NT_HEADERS *)((BYTE *)(dos + 1) + sizeof(builtin_signature));
+        size += sizeof(IMAGE_NT_HEADERS);
+        sec   = (IMAGE_SECTION_HEADER *)(nt + 1);
+    }
+
+    if (anon_mmap_fixed( addr, size, PROT_READ | PROT_WRITE, 0 ) != addr) return STATUS_NO_MEMORY;
+
+    /* build the DOS and NT headers */
+
+    dos->e_magic    = IMAGE_DOS_SIGNATURE;
+    dos->e_cblp     = 0x90;
+    dos->e_cp       = 3;
+    dos->e_cparhdr  = (sizeof(*dos) + 0xf) / 0x10;
+    dos->e_minalloc = 0;
+    dos->e_maxalloc = 0xffff;
+    dos->e_ss       = 0x0000;
+    dos->e_sp       = 0x00b8;
+    dos->e_lfanew   = sizeof(*dos) + sizeof(builtin_signature);
+    memcpy( dos + 1, builtin_signature, sizeof(builtin_signature) );
+
+    if (nt32)
+        *nt32 = *(IMAGE_NT_HEADERS32*)nt_descr;
+    else
+        *nt = *nt_descr;
+
+#ifdef __x86_64__
+    /* This flag is set for hybrid DLLs so the PE-side loader.c can tell it's hybrid */
+    if (nt32)
+        nt32->FileHeader.Characteristics |= IMAGE_FILE_BYTES_REVERSED_HI;
+#endif
+
+    delta      = (const BYTE *)nt_descr - addr;
+    align_mask = (nt32 ? nt32->OptionalHeader.SectionAlignment : nt->OptionalHeader.SectionAlignment) - 1;
+    code_start = (size + align_mask) & ~align_mask;
+    data_start = delta & ~align_mask;
+#ifdef __APPLE__
+    {
+        Dl_info dli;
+        unsigned long data_size;
+        /* need the mach_header, not the PE header, to give to getsegmentdata(3) */
+        dladdr(addr, &dli);
+        code_end   = getsegmentdata(dli.dli_fbase, "__DATA", &data_size) - addr;
+        data_end   = (code_end + data_size + align_mask) & ~align_mask;
+    }
+#else
+    code_end   = data_start;
+    data_end   = ((nt32 ? nt32->OptionalHeader.SizeOfImage : nt->OptionalHeader.SizeOfImage) + delta + align_mask) & ~align_mask;
+#endif
+
+    if (nt32)
+        fixup_rva_ptrs32( &nt32->OptionalHeader.AddressOfEntryPoint, addr, 1 );
+    else
+        fixup_rva_ptrs( &nt->OptionalHeader.AddressOfEntryPoint, addr, 1 );
+
+    if (nt32)
+    {
+    nt32->FileHeader.NumberOfSections                = nb_sections;
+    nt32->OptionalHeader.BaseOfCode                  = code_start;
+    nt32->OptionalHeader.BaseOfData                  = data_start;
+    nt32->OptionalHeader.SizeOfCode                  = code_end - code_start;
+    nt32->OptionalHeader.SizeOfInitializedData       = data_end - data_start;
+    nt32->OptionalHeader.SizeOfUninitializedData     = 0;
+    nt32->OptionalHeader.SizeOfImage                 = data_end;
+    nt32->OptionalHeader.ImageBase                   = (ULONG_PTR)addr;
+    }
+    else
+    {
+    nt->FileHeader.NumberOfSections                = nb_sections;
+    nt->OptionalHeader.BaseOfCode                  = code_start;
+#ifndef _WIN64
+    nt->OptionalHeader.BaseOfData                  = data_start;
+#endif
+    nt->OptionalHeader.SizeOfCode                  = code_end - code_start;
+    nt->OptionalHeader.SizeOfInitializedData       = data_end - data_start;
+    nt->OptionalHeader.SizeOfUninitializedData     = 0;
+    nt->OptionalHeader.SizeOfImage                 = data_end;
+    nt->OptionalHeader.ImageBase                   = (ULONG_PTR)addr;
+    }
+
+    /* build the code section */
+
+    memcpy( sec->Name, ".text", sizeof(".text") );
+    sec->SizeOfRawData = code_end - code_start;
+    sec->Misc.VirtualSize = sec->SizeOfRawData;
+    sec->VirtualAddress   = code_start;
+    sec->PointerToRawData = code_start;
+    sec->Characteristics  = (IMAGE_SCN_CNT_CODE | IMAGE_SCN_MEM_EXECUTE | IMAGE_SCN_MEM_READ);
+    sec++;
+
+    /* build the data section */
+
+    memcpy( sec->Name, ".data", sizeof(".data") );
+    sec->SizeOfRawData = data_end - data_start;
+    sec->Misc.VirtualSize = sec->SizeOfRawData;
+    sec->VirtualAddress   = data_start;
+    sec->PointerToRawData = data_start;
+    sec->Characteristics  = (IMAGE_SCN_CNT_INITIALIZED_DATA |
+                             IMAGE_SCN_MEM_WRITE | IMAGE_SCN_MEM_READ);
+    sec++;
+
+    if (nt32)
+    {
+    for (i = 0; i < nt32->OptionalHeader.NumberOfRvaAndSizes; i++)
+        fixup_rva_dwords32( &nt32->OptionalHeader.DataDirectory[i].VirtualAddress, delta, 1 );
+    }
+    else
+    {
+    for (i = 0; i < nt->OptionalHeader.NumberOfRvaAndSizes; i++)
+        fixup_rva_dwords( &nt->OptionalHeader.DataDirectory[i].VirtualAddress, delta, 1 );
+    }
+
+    /* build the import directory */
+
+    if (nt32)
+        dir = &nt32->OptionalHeader.DataDirectory[IMAGE_FILE_IMPORT_DIRECTORY];
+    else
+        dir = &nt->OptionalHeader.DataDirectory[IMAGE_FILE_IMPORT_DIRECTORY];
+    if (dir->Size)
+    {
+        IMAGE_IMPORT_DESCRIPTOR *imports = (IMAGE_IMPORT_DESCRIPTOR *)(addr + dir->VirtualAddress);
+
+        while (imports->Name)
+        {
+            if (nt32)
+            {
+            fixup_rva_dwords32( &imports->u.OriginalFirstThunk, delta, 1 );
+            fixup_rva_dwords32( &imports->Name, delta, 1 );
+            fixup_rva_dwords32( &imports->FirstThunk, delta, 1 );
+            if (imports->u.OriginalFirstThunk)
+                fixup_rva_names32( (UINT_PTR *)(addr + imports->u.OriginalFirstThunk), delta );
+            if (imports->FirstThunk)
+                fixup_rva_names32( (UINT_PTR *)(addr + imports->FirstThunk), delta );
+            }
+            else
+            {
+            fixup_rva_dwords( &imports->u.OriginalFirstThunk, delta, 1 );
+            fixup_rva_dwords( &imports->Name, delta, 1 );
+            fixup_rva_dwords( &imports->FirstThunk, delta, 1 );
+            if (imports->u.OriginalFirstThunk)
+                fixup_rva_names( (UINT_PTR *)(addr + imports->u.OriginalFirstThunk), delta );
+            if (imports->FirstThunk)
+                fixup_rva_names( (UINT_PTR *)(addr + imports->FirstThunk), delta );
+            }
+            imports++;
+        }
+    }
+
+    /* build the resource directory */
+    if (nt32)
+        dir = &nt32->OptionalHeader.DataDirectory[IMAGE_FILE_RESOURCE_DIRECTORY];
+    else
+        dir = &nt->OptionalHeader.DataDirectory[IMAGE_FILE_RESOURCE_DIRECTORY];
+    if (dir->Size)
+    {
+        void *ptr = addr + dir->VirtualAddress;
+        if (nt32)
+            fixup_so_resources32( ptr, ptr, delta );
+        else
+            fixup_so_resources( ptr, ptr, delta );
+    }
+
+    /* build the export directory */
+    if (nt32)
+        dir = &nt32->OptionalHeader.DataDirectory[IMAGE_FILE_EXPORT_DIRECTORY];
+    else
+        dir = &nt->OptionalHeader.DataDirectory[IMAGE_FILE_EXPORT_DIRECTORY];
+    if (dir->Size)
+    {
+        IMAGE_EXPORT_DIRECTORY *exports = (IMAGE_EXPORT_DIRECTORY *)(addr + dir->VirtualAddress);
+
+        if (nt32)
+        {
+        fixup_rva_dwords32( &exports->Name, delta, 1 );
+        fixup_rva_dwords32( &exports->AddressOfFunctions, delta, 1 );
+        fixup_rva_dwords32( &exports->AddressOfNames, delta, 1 );
+        fixup_rva_dwords32( &exports->AddressOfNameOrdinals, delta, 1 );
+        fixup_rva_dwords32( (DWORD *)(addr + exports->AddressOfNames), delta, exports->NumberOfNames );
+#ifdef __x86_64__
+        /* 32-bit .so DLL on x86_64 must be a hybrid Winelib dll */
+        fixup_rva_ptrs32( addr + exports->AddressOfFunctions, addr, exports->NumberOfFunctions * 2 );
+#else
+        fixup_rva_ptrs( addr + exports->AddressOfFunctions, addr, exports->NumberOfFunctions );
+#endif
+        }
+        else
+        {
+        fixup_rva_dwords( &exports->Name, delta, 1 );
+        fixup_rva_dwords( &exports->AddressOfFunctions, delta, 1 );
+        fixup_rva_dwords( &exports->AddressOfNames, delta, 1 );
+        fixup_rva_dwords( &exports->AddressOfNameOrdinals, delta, 1 );
+        fixup_rva_dwords( (DWORD *)(addr + exports->AddressOfNames), delta, exports->NumberOfNames );
+        fixup_rva_ptrs( addr + exports->AddressOfFunctions, addr, exports->NumberOfFunctions );
+        }
+    }
+    return STATUS_SUCCESS;
+}
+
+static ULONG_PTR find_ordinal_export( HMODULE module, const IMAGE_EXPORT_DIRECTORY *exports, DWORD ordinal )
+{
+    const DWORD *functions = (const DWORD *)((BYTE *)module + exports->AddressOfFunctions);
+
+    if (ordinal >= exports->NumberOfFunctions) return 0;
+    if (!functions[ordinal]) return 0;
+    return (ULONG_PTR)module + functions[ordinal];
+}
+
+static ULONG_PTR find_named_export( HMODULE module, const IMAGE_EXPORT_DIRECTORY *exports,
+                                    const char *name )
+{
+    const WORD *ordinals = (const WORD *)((BYTE *)module + exports->AddressOfNameOrdinals);
+    const DWORD *names = (const DWORD *)((BYTE *)module + exports->AddressOfNames);
+    int min = 0, max = exports->NumberOfNames - 1;
+
+    while (min <= max)
+    {
+        int res, pos = (min + max) / 2;
+        char *ename = (char *)module + names[pos];
+        if (!(res = strcmp( ename, name ))) return find_ordinal_export( module, exports, ordinals[pos] );
+        if (res > 0) max = pos - 1;
+        else min = pos + 1;
+    }
+    return 0;
+}
+
+static inline void *get_rva( void *module, ULONG_PTR addr )
+{
+    return (BYTE *)module + addr;
+}
+
+static const void *get_module_data_dir( HMODULE module, ULONG dir, ULONG *size )
+{
+    const IMAGE_NT_HEADERS *nt = get_rva( module, ((IMAGE_DOS_HEADER *)module)->e_lfanew );
+    const IMAGE_DATA_DIRECTORY *data;
+
+    if (nt->OptionalHeader.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC)
+        data = &((const IMAGE_NT_HEADERS64 *)nt)->OptionalHeader.DataDirectory[dir];
+    else if (nt->OptionalHeader.Magic == IMAGE_NT_OPTIONAL_HDR32_MAGIC)
+        data = &((const IMAGE_NT_HEADERS32 *)nt)->OptionalHeader.DataDirectory[dir];
+    else
+        return NULL;
+    if (!data->VirtualAddress || !data->Size) return NULL;
+    if (size) *size = data->Size;
+    return get_rva( module, data->VirtualAddress );
+}
+
+static void load_ntdll_functions( HMODULE module )
+{
+    ntdll_exports = get_module_data_dir( module, IMAGE_FILE_EXPORT_DIRECTORY, NULL );
+    assert( ntdll_exports );
+
+#define GET_FUNC(name) \
+    if (!(p##name = (void *)find_named_export( module, ntdll_exports, #name ))) \
+        ERR( "%s not found\n", #name )
+
+    GET_FUNC( DbgUiRemoteBreakin );
+    GET_FUNC( KiRaiseUserExceptionDispatcher );
+    GET_FUNC( KiUserExceptionDispatcher );
+    GET_FUNC( KiUserApcDispatcher );
+    GET_FUNC( KiUserCallbackDispatcher );
+    GET_FUNC( LdrInitializeThunk );
+    GET_FUNC( LdrSystemDllInitBlock );
+    GET_FUNC( RtlUserThreadStart );
+    GET_FUNC( __wine_ctrl_routine );
+    GET_FUNC( __wine_set_unix_funcs );
+    GET_FUNC( __wine_syscall_dispatcher );
+#ifdef __i386__
+    {
+        void **p__wine_ldt_copy;
+        GET_FUNC( __wine_ldt_copy );
+        *p__wine_ldt_copy = &__wine_ldt_copy;
+    }
+#endif
+#undef GET_FUNC
+}
+
+static void load_ntdll_wow64_functions( HMODULE module )
+{
+    const IMAGE_EXPORT_DIRECTORY *exports;
+
+    exports = get_module_data_dir( module, IMAGE_FILE_EXPORT_DIRECTORY, NULL );
+    assert( exports );
+
+    pLdrSystemDllInitBlock->ntdll_handle = (ULONG_PTR)module;
+
+#define GET_FUNC(name) pLdrSystemDllInitBlock->p##name = find_named_export( module, exports, #name )
+    GET_FUNC( KiUserApcDispatcher );
+    GET_FUNC( KiUserCallbackDispatcher );
+    GET_FUNC( KiUserExceptionDispatcher );
+    GET_FUNC( LdrInitializeThunk );
+    GET_FUNC( LdrSystemDllInitBlock );
+    GET_FUNC( RtlUserThreadStart );
+    GET_FUNC( RtlpFreezeTimeBias );
+    GET_FUNC( RtlpQueryProcessDebugInformationRemote );
+#undef GET_FUNC
+
+    p__wine_ctrl_routine = (void *)find_named_export( module, exports, "__wine_ctrl_routine" );
+
+    /* also set the 32-bit LdrSystemDllInitBlock */
+    memcpy( (void *)(ULONG_PTR)pLdrSystemDllInitBlock->pLdrSystemDllInitBlock,
+            pLdrSystemDllInitBlock, sizeof(*pLdrSystemDllInitBlock) );
+}
+
+/* reimplementation of LdrProcessRelocationBlock */
+static const IMAGE_BASE_RELOCATION *process_relocation_block( void *module, const IMAGE_BASE_RELOCATION *rel,
+                                                              INT_PTR delta )
+{
+    char *page = get_rva( module, rel->VirtualAddress );
+    UINT count = (rel->SizeOfBlock - sizeof(*rel)) / sizeof(USHORT);
+    USHORT *relocs = (USHORT *)(rel + 1);
+
+    while (count--)
+    {
+        USHORT offset = *relocs & 0xfff;
+        switch (*relocs >> 12)
+        {
+        case IMAGE_REL_BASED_ABSOLUTE:
+            break;
+        case IMAGE_REL_BASED_HIGH:
+            *(short *)(page + offset) += HIWORD(delta);
+            break;
+        case IMAGE_REL_BASED_LOW:
+            *(short *)(page + offset) += LOWORD(delta);
+            break;
+        case IMAGE_REL_BASED_HIGHLOW:
+            *(int *)(page + offset) += delta;
+            break;
+        case IMAGE_REL_BASED_DIR64:
+            *(INT64 *)(page + offset) += delta;
+            break;
+        case IMAGE_REL_BASED_THUMB_MOV32:
+        {
+            DWORD *inst = (DWORD *)(page + offset);
+            WORD lo = ((inst[0] << 1) & 0x0800) + ((inst[0] << 12) & 0xf000) +
+                      ((inst[0] >> 20) & 0x0700) + ((inst[0] >> 16) & 0x00ff);
+            WORD hi = ((inst[1] << 1) & 0x0800) + ((inst[1] << 12) & 0xf000) +
+                      ((inst[1] >> 20) & 0x0700) + ((inst[1] >> 16) & 0x00ff);
+            DWORD imm = MAKELONG( lo, hi ) + delta;
+
+            lo = LOWORD( imm );
+            hi = HIWORD( imm );
+            inst[0] = (inst[0] & 0x8f00fbf0) + ((lo >> 1) & 0x0400) + ((lo >> 12) & 0x000f) +
+                                               ((lo << 20) & 0x70000000) + ((lo << 16) & 0xff0000);
+            inst[1] = (inst[1] & 0x8f00fbf0) + ((hi >> 1) & 0x0400) + ((hi >> 12) & 0x000f) +
+                                               ((hi << 20) & 0x70000000) + ((hi << 16) & 0xff0000);
+            break;
+        }
+        default:
+            FIXME("Unknown/unsupported relocation %x\n", *relocs);
+            return NULL;
+        }
+        relocs++;
+    }
+    return (IMAGE_BASE_RELOCATION *)relocs;  /* return address of next block */
+}
+
+static void relocate_ntdll( void *module )
+{
+    const IMAGE_NT_HEADERS *nt = get_rva( module, ((IMAGE_DOS_HEADER *)module)->e_lfanew );
+    const IMAGE_BASE_RELOCATION *rel, *end;
+    const IMAGE_SECTION_HEADER *sec;
+    ULONG protect_old[96], i, size;
+    INT_PTR delta;
+
+    ERR( "ntdll could not be mapped at preferred address (%p), expect trouble\n", module );
+
+    if (!(rel = get_module_data_dir( module, IMAGE_DIRECTORY_ENTRY_BASERELOC, &size ))) return;
+
+    sec = (IMAGE_SECTION_HEADER *)((char *)&nt->OptionalHeader + nt->FileHeader.SizeOfOptionalHeader);
+    for (i = 0; i < nt->FileHeader.NumberOfSections; i++)
+    {
+        void *addr = get_rva( module, sec[i].VirtualAddress );
+        SIZE_T size = sec[i].SizeOfRawData;
+        NtProtectVirtualMemory( NtCurrentProcess(), &addr, &size, PAGE_READWRITE, &protect_old[i] );
+    }
+
+    end = (IMAGE_BASE_RELOCATION *)((const char *)rel + size);
+    delta = (char *)module - (char *)nt->OptionalHeader.ImageBase;
+    while (rel && rel < end - 1 && rel->SizeOfBlock) rel = process_relocation_block( module, rel, delta );
+
+    for (i = 0; i < nt->FileHeader.NumberOfSections; i++)
+    {
+        void *addr = get_rva( module, sec[i].VirtualAddress );
+        SIZE_T size = sec[i].SizeOfRawData;
+        NtProtectVirtualMemory( NtCurrentProcess(), &addr, &size, protect_old[i], &protect_old[i] );
+    }
+}
+
+
+static void *callback_module;
+
+/***********************************************************************
+ *           load_builtin_callback
+ *
+ * Load a library in memory; callback function for wine_dll_register
+ */
+static void load_builtin_callback( void *module, const char *filename )
+{
+    callback_module = module;
+}
+
+
+/***********************************************************************
+ *           load_libwine
+ */
+static void load_libwine(void)
+{
+#ifdef __APPLE__
+#define LIBWINE "libwine.1.dylib"
+#else
+#define LIBWINE "libwine.so.1"
+#endif
+    typedef void (*load_dll_callback_t)( void *, const char * );
+    void (*p_wine_dll_set_callback)( load_dll_callback_t load );
+    char ***p___wine_main_environ;
+
+    char *path;
+    void *handle;
+
+    if (build_dir) path = build_path( build_dir, "libs/wine/" LIBWINE );
+    else path = build_path( ntdll_dir, LIBWINE );
+
+    handle = dlopen( path, RTLD_NOW );
+    free( path );
+    if (!handle && !(handle = dlopen( LIBWINE, RTLD_NOW ))) return;
+
+    p_wine_dll_set_callback = dlsym( handle, "wine_dll_set_callback" );
+    p___wine_main_argc      = dlsym( handle, "__wine_main_argc" );
+    p___wine_main_argv      = dlsym( handle, "__wine_main_argv" );
+    p___wine_main_wargv     = dlsym( handle, "__wine_main_wargv" );
+    p___wine_main_environ   = dlsym( handle, "__wine_main_environ" );
+
+    if (p_wine_dll_set_callback) p_wine_dll_set_callback( load_builtin_callback );
+    if (p___wine_main_environ) *p___wine_main_environ = main_envp;
+}
+
+
+/***********************************************************************
+ *           fill_builtin_image_info
+ */
+static void fill_builtin_image_info( void *module, pe_image_info_t *info )
+{
+    const IMAGE_DOS_HEADER *dos = (const IMAGE_DOS_HEADER *)module;
+    const IMAGE_NT_HEADERS *nt = (IMAGE_NT_HEADERS *)((const BYTE *)dos + dos->e_lfanew);
+    const IMAGE_NT_HEADERS32 *nt32 = NULL;
+
+    if (nt->OptionalHeader.Magic == IMAGE_NT_OPTIONAL_HDR32_MAGIC)
+        nt32 = (IMAGE_NT_HEADERS32 *)nt;
+
+    info->base            = nt32 ? nt32->OptionalHeader.ImageBase : nt->OptionalHeader.ImageBase;
+    info->entry_point     = nt32 ? nt32->OptionalHeader.AddressOfEntryPoint : nt->OptionalHeader.AddressOfEntryPoint;
+    info->map_size        = nt32 ? nt32->OptionalHeader.SizeOfImage : nt->OptionalHeader.SizeOfImage;
+    info->stack_size      = nt32 ? nt32->OptionalHeader.SizeOfStackReserve : nt->OptionalHeader.SizeOfStackReserve;
+    info->stack_commit    = nt32 ? nt32->OptionalHeader.SizeOfStackCommit : nt->OptionalHeader.SizeOfStackCommit;
+    info->zerobits        = 0;
+    info->subsystem       = nt32 ? nt32->OptionalHeader.Subsystem : nt->OptionalHeader.Subsystem;
+    info->subsystem_minor = nt32 ? nt32->OptionalHeader.MinorSubsystemVersion : nt->OptionalHeader.MinorSubsystemVersion;
+    info->subsystem_major = nt32 ? nt32->OptionalHeader.MajorSubsystemVersion : nt->OptionalHeader.MajorSubsystemVersion;
+    info->osversion_major = nt32 ? nt32->OptionalHeader.MajorOperatingSystemVersion : nt->OptionalHeader.MajorOperatingSystemVersion;
+    info->osversion_minor = nt32 ? nt32->OptionalHeader.MinorOperatingSystemVersion : nt->OptionalHeader.MinorOperatingSystemVersion;
+    info->image_charact   = nt32 ? nt32->FileHeader.Characteristics : nt->FileHeader.Characteristics;
+    info->dll_charact     = nt32 ? nt32->OptionalHeader.DllCharacteristics : nt->OptionalHeader.DllCharacteristics;
+    info->machine         = nt32 ? nt32->FileHeader.Machine : nt->FileHeader.Machine;
+    info->contains_code   = TRUE;
+    info->image_flags     = IMAGE_FLAGS_WineBuiltin;
+    info->loader_flags    = 0;
+    info->header_size     = nt32 ? nt32->OptionalHeader.SizeOfHeaders : nt->OptionalHeader.SizeOfHeaders;
+    info->file_size       = nt32 ? nt32->OptionalHeader.SizeOfImage : nt->OptionalHeader.SizeOfImage;
+    info->checksum        = nt32 ? nt32->OptionalHeader.CheckSum : nt->OptionalHeader.CheckSum;
+    info->dbg_offset      = 0;
+    info->dbg_size        = 0;
+}
+
+
+/***********************************************************************
+ *           dlopen_dll
+ */
+static NTSTATUS dlopen_dll( const char *so_name, UNICODE_STRING *nt_name, void **ret_module,
+                            pe_image_info_t *image_info, BOOL prefer_native )
+{
+    void *module, *handle;
+    const IMAGE_NT_HEADERS *nt;
+
+    callback_module = (void *)1;
+    handle = dlopen( so_name, RTLD_NOW );
+    if (!handle)
+    {
+        WARN( "failed to load .so lib %s: %s\n", debugstr_a(so_name), dlerror() );
+        return STATUS_INVALID_IMAGE_FORMAT;
+    }
+    fixup_so_32on64_sels( handle, so_name );
+    if (callback_module != (void *)1)  /* callback was called */
+    {
+        if (!callback_module) return STATUS_NO_MEMORY;
+        WARN( "got old-style builtin library %s, constructors won't work\n", debugstr_a(so_name) );
+        module = callback_module;
+        if (get_builtin_so_handle( module )) goto already_loaded;
+    }
+    else if ((nt = dlsym( handle, "__wine_spec_nt_header" )))
+    {
+        const IMAGE_NT_HEADERS32 *nt32 = (const IMAGE_NT_HEADERS32 *)nt;
+        if (nt->OptionalHeader.Magic == IMAGE_NT_OPTIONAL_HDR32_MAGIC)
+            module = (HMODULE)UIntToPtr((nt32->OptionalHeader.ImageBase + 0xffff) & ~0xffff);
+        else
+            module = (HMODULE)((nt->OptionalHeader.ImageBase + 0xffff) & ~0xffff);
+
+        if (get_builtin_so_handle( module )) goto already_loaded;
+        if (map_so_dll( nt, module ))
+        {
+            dlclose( handle );
+            return STATUS_NO_MEMORY;
+        }
+    }
+    else  /* already loaded .so */
+    {
+        WARN( "%s already loaded?\n", debugstr_a(so_name));
+        return STATUS_INVALID_IMAGE_FORMAT;
+    }
+
+    fill_builtin_image_info( module, image_info );
+    if (prefer_native && (image_info->dll_charact & IMAGE_DLLCHARACTERISTICS_PREFER_NATIVE))
+    {
+        TRACE( "%s has prefer-native flag, ignoring builtin\n", debugstr_a(so_name) );
+        dlclose( handle );
+        return STATUS_IMAGE_ALREADY_LOADED;
+    }
+
+    if (virtual_create_builtin_view( module, nt_name, image_info, handle ))
+    {
+        dlclose( handle );
+        return STATUS_NO_MEMORY;
+    }
+    *ret_module = module;
+    return STATUS_SUCCESS;
+
+already_loaded:
+    fill_builtin_image_info( module, image_info );
+    *ret_module = module;
+    dlclose( handle );
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           ntdll_init_syscalls
+ */
+NTSTATUS ntdll_init_syscalls( ULONG id, SYSTEM_SERVICE_TABLE *table, void **dispatcher )
+{
+    struct syscall_info
+    {
+        void  *dispatcher;
+        USHORT limit;
+        BYTE  args[1];
+    } *info = (struct syscall_info *)dispatcher;
+
+    if (id > 3) return STATUS_INVALID_PARAMETER;
+    if (info->limit != table->ServiceLimit)
+    {
+        ERR( "syscall count mismatch %u / %lu\n", info->limit, table->ServiceLimit );
+        NtTerminateProcess( GetCurrentProcess(), STATUS_INVALID_PARAMETER );
+    }
+    info->dispatcher = __wine_syscall_dispatcher;
+    memcpy( table->ArgumentTable, info->args, table->ServiceLimit );
+    KeServiceDescriptorTable[id] = *table;
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           __wine_unix_call
+ */
+NTSTATUS WINAPI __wine_unix_call( unixlib_handle_t handle, unsigned int code, void *args )
+{
+    return ((unixlib_entry_t*)(UINT_PTR)handle)[code]( args );
+}
+
+#if defined(__APPLE__) && defined(__x86_64__)
+static void* non_native_support_lib;
+static void (*register_non_native_code_region) (void*, void*);
+static bool (*supports_non_native_code_regions) (void);
+static void init_non_native_support(void)
+{
+    register_non_native_code_region = NULL;
+    register_non_native_code_region = NULL;
+    non_native_support_lib = dlopen("@rpath/libd3dshared.dylib", RTLD_LOCAL);
+    if (non_native_support_lib)
+    {
+        register_non_native_code_region = dlsym(non_native_support_lib, "register_non_native_code_region");
+        supports_non_native_code_regions = dlsym(non_native_support_lib, "supports_non_native_code_regions");
+    }
+}
+
+static void CDECL pe_module_loaded(void* start, void* end)
+{
+    if ((supports_non_native_code_regions && supports_non_native_code_regions()))
+    {
+        TRACE("Marking non_native_code_region: %p, %p", start, end);
+        register_non_native_code_region(start, end);
+    }
+}
+static BOOL CDECL gs_patching_needed(void)
+{
+    return (supports_non_native_code_regions && supports_non_native_code_regions() == false);
+}
+#elif defined(__x86_64__)
+static void CDECL pe_module_loaded(void* start, void* end)
+{
+
+}
+static BOOL CDECL gs_patching_needed(void)
+{
+    return false;
+}
+#endif
+
+/***********************************************************************
+ *           load_so_dll
+ */
+static NTSTATUS CDECL load_so_dll( UNICODE_STRING *nt_name, void **module )
+{
+    static const WCHAR soW[] = {'.','s','o',0};
+    OBJECT_ATTRIBUTES attr;
+    UNICODE_STRING redir;
+    pe_image_info_t info;
+    char *unix_name;
+    NTSTATUS status;
+    DWORD len;
+
+    if (get_load_order( nt_name ) == LO_DISABLED) return STATUS_DLL_NOT_FOUND;
+    InitializeObjectAttributes( &attr, nt_name, OBJ_CASE_INSENSITIVE, 0, 0 );
+    get_redirect( &attr, &redir );
+
+    if (nt_to_unix_file_name( &attr, &unix_name, FILE_OPEN ))
+    {
+        free( redir.Buffer );
+        return STATUS_DLL_NOT_FOUND;
+    }
+
+    /* remove .so extension from Windows name */
+    len = nt_name->Length / sizeof(WCHAR);
+    if (len > 3 && !wcsicmp( nt_name->Buffer + len - 3, soW )) nt_name->Length -= 3 * sizeof(WCHAR);
+
+    status = dlopen_dll( unix_name, nt_name, module, &info, FALSE );
+    free( unix_name );
+    free( redir.Buffer );
+    return status;
+}
+
+
+/* check if the library is the correct architecture */
+/* only returns false for a valid library of the wrong arch */
+static int check_library_arch( int fd )
+{
+#ifdef __APPLE__
+    struct  /* Mach-O header */
+    {
+        unsigned int magic;
+        unsigned int cputype;
+    } header;
+
+    if (read( fd, &header, sizeof(header) ) != sizeof(header)) return 1;
+    if (header.magic != 0xfeedface) return 1;
+    if (sizeof(void *) == sizeof(int)) return !(header.cputype >> 24);
+    else return (header.cputype >> 24) == 1; /* CPU_ARCH_ABI64 */
+#else
+    struct  /* ELF header */
+    {
+        unsigned char magic[4];
+        unsigned char class;
+        unsigned char data;
+        unsigned char version;
+    } header;
+
+    if (read( fd, &header, sizeof(header) ) != sizeof(header)) return 1;
+    if (memcmp( header.magic, "\177ELF", 4 )) return 1;
+    if (header.version != 1 /* EV_CURRENT */) return 1;
+#ifdef WORDS_BIGENDIAN
+    if (header.data != 2 /* ELFDATA2MSB */) return 1;
+#else
+    if (header.data != 1 /* ELFDATA2LSB */) return 1;
+#endif
+    if (sizeof(void *) == sizeof(int)) return header.class == 1; /* ELFCLASS32 */
+    else return header.class == 2; /* ELFCLASS64 */
+#endif
+}
+
+static inline char *prepend( char *buffer, const char *str, size_t len )
+{
+    return memcpy( buffer - len, str, len );
+}
+
+/***********************************************************************
+ *	open_dll_file
+ *
+ * Open a file for a new dll. Helper for open_builtin_pe_file.
+ */
+static NTSTATUS open_dll_file( const char *name, OBJECT_ATTRIBUTES *attr, HANDLE *mapping )
+{
+    LARGE_INTEGER size;
+    NTSTATUS status;
+    HANDLE handle;
+
+    if ((status = open_unix_file( &handle, name, GENERIC_READ | SYNCHRONIZE, attr, 0,
+                                  FILE_SHARE_READ | FILE_SHARE_DELETE, FILE_OPEN,
+                                  FILE_SYNCHRONOUS_IO_NONALERT | FILE_NON_DIRECTORY_FILE, NULL, 0 )))
+    {
+        if (status != STATUS_OBJECT_PATH_NOT_FOUND && status != STATUS_OBJECT_NAME_NOT_FOUND)
+        {
+            /* if the file exists but failed to open, report the error */
+            struct stat st;
+            if (!stat( name, &st )) return status;
+        }
+        /* otherwise continue searching */
+        return STATUS_DLL_NOT_FOUND;
+    }
+
+    size.QuadPart = 0;
+    status = NtCreateSection( mapping, STANDARD_RIGHTS_REQUIRED | SECTION_QUERY |
+                              SECTION_MAP_READ | SECTION_MAP_EXECUTE,
+                              NULL, &size, PAGE_EXECUTE_READ, SEC_IMAGE, handle );
+    NtClose( handle );
+    return status;
+}
+
+
+/***********************************************************************
+ *           open_builtin_pe_file
+ */
+static NTSTATUS open_builtin_pe_file( const char *name, OBJECT_ATTRIBUTES *attr, void **module,
+                                      SIZE_T *size, SECTION_IMAGE_INFORMATION *image_info,
+                                      ULONG_PTR zero_bits, WORD machine, BOOL prefer_native )
+{
+    NTSTATUS status;
+    HANDLE mapping;
+
+    *module = NULL;
+    status = open_dll_file( name, attr, &mapping );
+    if (!status)
+    {
+        status = virtual_map_builtin_module( mapping, module, size, image_info, zero_bits, machine, prefer_native );
+        NtClose( mapping );
+    }
+    return status;
+}
+
+
+/***********************************************************************
+ *           open_builtin_so_file
+ */
+static NTSTATUS open_builtin_so_file( const char *name, OBJECT_ATTRIBUTES *attr, void **module,
+                                      SECTION_IMAGE_INFORMATION *image_info,
+                                      WORD machine, BOOL prefer_native )
+{
+    NTSTATUS status;
+    int fd;
+
+    *module = NULL;
+#ifdef __x86_64__
+    /* In Wow64 mode, try to load hybrid .dll.so's */
+    if (machine != current_machine && machine != IMAGE_FILE_MACHINE_I386) return STATUS_DLL_NOT_FOUND;
+#else
+    if (machine != current_machine) return STATUS_DLL_NOT_FOUND;
+#endif
+
+    if ((fd = open( name, O_RDONLY )) == -1) return STATUS_DLL_NOT_FOUND;
+
+    if (check_library_arch( fd ))
+    {
+        pe_image_info_t info;
+
+        status = dlopen_dll( name, attr->ObjectName, module, &info, prefer_native );
+        if (!status) virtual_fill_image_information( &info, image_info );
+        else if (status != STATUS_IMAGE_ALREADY_LOADED)
+        {
+            ERR( "failed to load .so lib %s\n", debugstr_a(name) );
+            status = STATUS_PROCEDURE_NOT_FOUND;
+        }
+    }
+    else status = STATUS_IMAGE_MACHINE_TYPE_MISMATCH;
+
+    close( fd );
+    return status;
+}
+
+
+/***********************************************************************
+ *           find_builtin_dll
+ */
+static NTSTATUS find_builtin_dll( UNICODE_STRING *nt_name, void **module, SIZE_T *size_ptr,
+                                  SECTION_IMAGE_INFORMATION *image_info,
+                                  ULONG_PTR zero_bits, WORD machine, BOOL prefer_native )
+{
+    unsigned int i, pos, namepos, namelen, maxlen = 0;
+    unsigned int len = nt_name->Length / sizeof(WCHAR);
+    char *ptr = NULL, *file, *ext = NULL;
+    const char *pe_dir = get_pe_dir( machine );
+    OBJECT_ATTRIBUTES attr;
+    NTSTATUS status = STATUS_DLL_NOT_FOUND;
+    BOOL found_image = FALSE;
+
+    /* CX HACK 20810: in wow64/32-bit-bottle mode, use 32-bit builtin EXEs */
+    if (wow64_using_32bit_prefix &&
+        len > 4 &&
+        (nt_name->Buffer[len-3] == 'e' &&
+         nt_name->Buffer[len-2] == 'x' &&
+         nt_name->Buffer[len-1] == 'e'))
+        pe_dir = get_pe_dir( IMAGE_FILE_MACHINE_I386 );
+
+    for (i = namepos = 0; i < len; i++)
+        if (nt_name->Buffer[i] == '/' || nt_name->Buffer[i] == '\\') namepos = i + 1;
+    len -= namepos;
+    if (!len) return STATUS_DLL_NOT_FOUND;
+    InitializeObjectAttributes( &attr, nt_name, 0, 0, NULL );
+
+    if (build_dir) maxlen = strlen(build_dir) + sizeof("/programs/") + len;
+    maxlen = max( maxlen, dll_path_maxlen + 1 ) + len + sizeof("/aarch64-windows") + sizeof(".so");
+
+    if (!(file = malloc( maxlen ))) return STATUS_NO_MEMORY;
+
+    pos = maxlen - len - sizeof(".so");
+    /* we don't want to depend on the current codepage here */
+    for (i = 0; i < len; i++)
+    {
+        if (nt_name->Buffer[namepos + i] > 127) goto done;
+        file[pos + i] = (char)nt_name->Buffer[namepos + i];
+        if (file[pos + i] >= 'A' && file[pos + i] <= 'Z') file[pos + i] += 'a' - 'A';
+        else if (file[pos + i] == '.') ext = file + pos + i;
+    }
+    file[--pos] = '/';
+
+    if (build_dir)
+    {
+        /* try as a dll */
+        ptr = file + pos;
+        namelen = len + 1;
+        file[pos + len + 1] = 0;
+        if (ext && !strcmp( ext, ".dll" )) namelen -= 4;
+        ptr = prepend( ptr, ptr, namelen );
+        ptr = prepend( ptr, "/dlls", sizeof("/dlls") - 1 );
+        ptr = prepend( ptr, build_dir, strlen(build_dir) );
+        status = open_builtin_pe_file( ptr, &attr, module, size_ptr, image_info, zero_bits, machine, prefer_native );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+        strcpy( file + pos + len + 1, ".so" );
+        status = open_builtin_so_file( ptr, &attr, module, image_info, machine, prefer_native );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+
+        /* now as a program */
+        ptr = file + pos;
+        namelen = len + 1;
+        file[pos + len + 1] = 0;
+        if (ext && !strcmp( ext, ".exe" )) namelen -= 4;
+        ptr = prepend( ptr, ptr, namelen );
+        ptr = prepend( ptr, "/programs", sizeof("/programs") - 1 );
+        ptr = prepend( ptr, build_dir, strlen(build_dir) );
+        status = open_builtin_pe_file( ptr, &attr, module, size_ptr, image_info, zero_bits, machine, prefer_native );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+        strcpy( file + pos + len + 1, ".so" );
+        status = open_builtin_so_file( ptr, &attr, module, image_info, machine, prefer_native );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+    }
+
+    for (i = 0; dll_paths[i]; i++)
+    {
+        ptr = file + pos;
+        file[pos + len + 1] = 0;
+        ptr = prepend( ptr, pe_dir, strlen(pe_dir) );
+        ptr = prepend( ptr, dll_paths[i], strlen(dll_paths[i]) );
+        status = open_builtin_pe_file( ptr, &attr, module, size_ptr, image_info, zero_bits, machine, prefer_native );
+        /* use so dir for unix lib */
+        ptr = file + pos;
+#ifdef __x86_64__
+        /* In Wow64 mode, a .dll.so must be hybrid */
+        if (machine == IMAGE_FILE_MACHINE_I386)
+            ptr = prepend( ptr, so_dir_32on64, strlen(so_dir_32on64) );
+        else
+#endif
+        ptr = prepend( ptr, so_dir, strlen(so_dir) );
+        ptr = prepend( ptr, dll_paths[i], strlen(dll_paths[i]) );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+        strcpy( file + pos + len + 1, ".so" );
+        status = open_builtin_so_file( ptr, &attr, module, image_info, machine, prefer_native );
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+        file[pos + len + 1] = 0;
+        ptr = prepend( file + pos, dll_paths[i], strlen(dll_paths[i]) );
+        status = open_builtin_pe_file( ptr, &attr, module, size_ptr, image_info, zero_bits, machine, prefer_native );
+        if (status == STATUS_IMAGE_MACHINE_TYPE_MISMATCH)
+        {
+            found_image = TRUE;
+            continue;
+        }
+        if (status != STATUS_DLL_NOT_FOUND) goto done;
+        strcpy( file + pos + len + 1, ".so" );
+        status = open_builtin_so_file( ptr, &attr, module, image_info, machine, prefer_native );
+        if (status == STATUS_IMAGE_MACHINE_TYPE_MISMATCH) found_image = TRUE;
+        else if (status != STATUS_DLL_NOT_FOUND) goto done;
+    }
+
+    if (found_image) status = STATUS_IMAGE_MACHINE_TYPE_MISMATCH;
+    WARN( "cannot find builtin library for %s\n", debugstr_us(nt_name) );
+done:
+    if (status >= 0 && ext)
+    {
+        strcpy( ext, ".so" );
+        load_builtin_unixlib( *module, ptr );
+    }
+    free( file );
+    return status;
+}
+
+
+/***********************************************************************
+ *           load_builtin
+ *
+ * Load the builtin dll if specified by load order configuration.
+ * Return STATUS_IMAGE_ALREADY_LOADED if we should keep the native one that we have found.
+ */
+NTSTATUS load_builtin( const pe_image_info_t *image_info, WCHAR *filename,
+                       void **module, SIZE_T *size, ULONG_PTR zero_bits )
+{
+    WORD machine = image_info->machine;  /* request same machine as the native one */
+    NTSTATUS status;
+    UNICODE_STRING nt_name;
+    SECTION_IMAGE_INFORMATION info;
+    enum loadorder loadorder;
+
+    init_unicode_string( &nt_name, filename );
+    loadorder = get_load_order( &nt_name );
+
+    if (loadorder == LO_DISABLED) return STATUS_DLL_NOT_FOUND;
+
+    if (image_info->image_flags & IMAGE_FLAGS_WineBuiltin)
+    {
+        if (loadorder == LO_NATIVE) return STATUS_DLL_NOT_FOUND;
+        loadorder = LO_BUILTIN_NATIVE;  /* load builtin, then fallback to the file we found */
+    }
+    else if (image_info->image_flags & IMAGE_FLAGS_WineFakeDll)
+    {
+        TRACE( "%s is a fake Wine dll\n", debugstr_w(filename) );
+        if (loadorder == LO_NATIVE) return STATUS_DLL_NOT_FOUND;
+        loadorder = LO_BUILTIN;  /* builtin with no fallback since mapping a fake dll is not useful */
+    }
+
+    switch (loadorder)
+    {
+    case LO_NATIVE:
+    case LO_NATIVE_BUILTIN:
+        return STATUS_IMAGE_ALREADY_LOADED;
+    case LO_BUILTIN:
+        return find_builtin_dll( &nt_name, module, size, &info, zero_bits, machine, FALSE );
+    default:
+        status = find_builtin_dll( &nt_name, module, size, &info, zero_bits, machine, (loadorder == LO_DEFAULT) );
+        if (status == STATUS_DLL_NOT_FOUND || status == STATUS_IMAGE_MACHINE_TYPE_MISMATCH)
+            return STATUS_IMAGE_ALREADY_LOADED;
+        return status;
+    }
+}
+
+
+/***************************************************************************
+ *	get_machine_wow64_dir
+ *
+ * cf. GetSystemWow64Directory2.
+ */
+static const WCHAR *get_machine_wow64_dir( WORD machine )
+{
+    static const WCHAR system32[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\','s','y','s','t','e','m','3','2','\\',0};
+    static const WCHAR syswow64[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\','s','y','s','w','o','w','6','4','\\',0};
+    static const WCHAR sysarm32[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\','s','y','s','a','r','m','3','2','\\',0};
+    static const WCHAR sysx8664[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\','s','y','s','x','8','6','6','4','\\',0};
+    static const WCHAR sysarm64[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\','s','y','s','a','r','m','6','4','\\',0};
+
+    if (machine == native_machine || wow64_using_32bit_prefix) machine = IMAGE_FILE_MACHINE_TARGET_HOST;
+
+    switch (machine)
+    {
+    case IMAGE_FILE_MACHINE_TARGET_HOST: return system32;
+    case IMAGE_FILE_MACHINE_I386:        return syswow64;
+    case IMAGE_FILE_MACHINE_ARMNT:       return sysarm32;
+    case IMAGE_FILE_MACHINE_AMD64:       return sysx8664;
+    case IMAGE_FILE_MACHINE_ARM64:       return sysarm64;
+    default: return NULL;
+    }
+}
+
+
+/***************************************************************************
+ *	is_builtin_path
+ *
+ * Check if path is inside a system directory, to support loading builtins
+ * when the corresponding file doesn't exist yet.
+ */
+BOOL is_builtin_path( const UNICODE_STRING *path, WORD *machine )
+{
+    unsigned int i, len = path->Length / sizeof(WCHAR), dirlen;
+    const WCHAR *sysdir, *p = path->Buffer;
+
+    /* only fake builtin existence during prefix bootstrap */
+    if (!is_prefix_bootstrap) return FALSE;
+
+    for (i = 0; i < supported_machines_count; i++)
+    {
+        sysdir = get_machine_wow64_dir( supported_machines[i] );
+        dirlen = wcslen( sysdir );
+        if (len <= dirlen) continue;
+        if (wcsnicmp( p, sysdir, dirlen )) continue;
+        /* check for remaining path components */
+        for (p += dirlen, len -= dirlen; len; p++, len--) if (*p == '\\') return FALSE;
+        *machine = supported_machines[i];
+        return TRUE;
+    }
+    return FALSE;
+}
+
+
+/***********************************************************************
+ *           open_main_image
+ */
+static NTSTATUS open_main_image( WCHAR *image, void **module, SECTION_IMAGE_INFORMATION *info,
+                                 enum loadorder loadorder )
+{
+    static const WCHAR soW[] = {'.','s','o',0};
+    UNICODE_STRING nt_name;
+    OBJECT_ATTRIBUTES attr;
+    pe_image_info_t pe_info;
+    SIZE_T size = 0;
+    char *unix_name;
+    NTSTATUS status;
+    HANDLE mapping;
+    WCHAR *p;
+
+    if (loadorder == LO_DISABLED) NtTerminateProcess( GetCurrentProcess(), STATUS_DLL_NOT_FOUND );
+
+    init_unicode_string( &nt_name, image );
+    InitializeObjectAttributes( &attr, &nt_name, OBJ_CASE_INSENSITIVE, 0, NULL );
+    if (nt_to_unix_file_name( &attr, &unix_name, FILE_OPEN )) return STATUS_DLL_NOT_FOUND;
+
+    status = open_dll_file( unix_name, &attr, &mapping );
+    if (!status)
+    {
+        *module = NULL;
+        status = NtMapViewOfSection( mapping, NtCurrentProcess(), module, 0, 0, NULL, &size,
+                                     ViewShare, 0, PAGE_EXECUTE_READ );
+        if (!status)
+        {
+            NtQuerySection( mapping, SectionImageInformation, info, sizeof(*info), NULL );
+            if (info->u.s.ComPlusNativeReady && !wow64_using_32bit_prefix) info->Machine = native_machine;
+        }
+        NtClose( mapping );
+    }
+    else if (status == STATUS_INVALID_IMAGE_NOT_MZ && loadorder != LO_NATIVE)
+    {
+        /* remove .so extension from Windows name */
+        p = image + wcslen(image);
+        if (p - image > 3 && !wcsicmp( p - 3, soW ))
+        {
+            p[-3] = 0;
+            nt_name.Length -= 3 * sizeof(WCHAR);
+        }
+        status = dlopen_dll( unix_name, &nt_name, module, &pe_info, FALSE );
+        if (!status) virtual_fill_image_information( &pe_info, info );
+    }
+    free( unix_name );
+    return status;
+}
+
+
+/***********************************************************************
+ *           load_main_exe
+ */
+NTSTATUS load_main_exe( const WCHAR *dos_name, const char *unix_name, const WCHAR *curdir,
+                        WCHAR **image, void **module )
+{
+    enum loadorder loadorder = LO_INVALID;
+    UNICODE_STRING nt_name;
+    WCHAR *tmp = NULL;
+    BOOL contains_path;
+    NTSTATUS status;
+    SIZE_T size;
+    struct stat st;
+    WORD machine;
+
+    /* special case for Unix file name */
+    if (unix_name && unix_name[0] == '/' && !stat( unix_name, &st ))
+    {
+        if ((status = unix_to_nt_file_name( unix_name, image ))) goto failed;
+        init_unicode_string( &nt_name, *image );
+        loadorder = get_load_order( &nt_name );
+        status = open_main_image( *image, module, &main_image_info, loadorder );
+        if (status != STATUS_DLL_NOT_FOUND) return status;
+        free( *image );
+    }
+
+    if (!dos_name)
+    {
+        dos_name = tmp = malloc( (strlen(unix_name) + 1) * sizeof(WCHAR) );
+        ntdll_umbstowcs( unix_name, strlen(unix_name) + 1, tmp, strlen(unix_name) + 1 );
+    }
+    contains_path = (wcschr( dos_name, '/' ) ||
+                     wcschr( dos_name, '\\' ) ||
+                     (dos_name[0] && dos_name[1] == ':'));
+
+    if ((status = get_full_path( dos_name, curdir, image ))) goto failed;
+    free( tmp );
+
+    init_unicode_string( &nt_name, *image );
+    if (loadorder == LO_INVALID) loadorder = get_load_order( &nt_name );
+
+    status = open_main_image( *image, module, &main_image_info, loadorder );
+    if (status != STATUS_DLL_NOT_FOUND) return status;
+
+    /* if path is in system dir, we can load the builtin even if the file itself doesn't exist */
+    if (loadorder != LO_NATIVE && is_builtin_path( &nt_name, &machine ))
+    {
+        status = find_builtin_dll( &nt_name, module, &size, &main_image_info, 0, machine, FALSE );
+        if (status != STATUS_DLL_NOT_FOUND) return status;
+    }
+    if (!contains_path) return STATUS_DLL_NOT_FOUND;
+
+failed:
+    MESSAGE( "wine: failed to open %s: %x\n",
+             unix_name ? debugstr_a(unix_name) : debugstr_w(dos_name), status );
+    NtTerminateProcess( GetCurrentProcess(), status );
+    return status;  /* unreached */
+}
+
+
+/***********************************************************************
+ *           load_start_exe
+ *
+ * Load start.exe as main image.
+ */
+NTSTATUS load_start_exe( WCHAR **image, void **module )
+{
+    static const WCHAR startW[] = {'s','t','a','r','t','.','e','x','e',0};
+    UNICODE_STRING nt_name;
+    NTSTATUS status;
+    SIZE_T size;
+
+    *image = malloc( sizeof("\\??\\C:\\windows\\system32\\start.exe") * sizeof(WCHAR) );
+    wcscpy( *image, get_machine_wow64_dir( current_machine ));
+    wcscat( *image, startW );
+    init_unicode_string( &nt_name, *image );
+    status = find_builtin_dll( &nt_name, module, &size, &main_image_info, 0, current_machine, FALSE );
+    if (status)
+    {
+        MESSAGE( "wine: failed to load start.exe: %x\n", status );
+        NtTerminateProcess( GetCurrentProcess(), status );
+    }
+    return status;
+}
+
+
+#ifdef __FreeBSD__
+/* The PT_LOAD segments are sorted in increasing order, and the first
+ * starts at the beginning of the ELF file. By parsing the file, we can
+ * find that first PT_LOAD segment, from which we can find the base
+ * address it wanted, and knowing mapbase where the binary was actually
+ * loaded, use them to work out the relocbase offset. */
+static BOOL get_relocbase(caddr_t mapbase, caddr_t *relocbase)
+{
+    Elf_Half i;
+#ifdef _WIN64
+    const Elf64_Ehdr *elf_header = (Elf64_Ehdr*) mapbase;
+#else
+    const Elf32_Ehdr *elf_header = (Elf32_Ehdr*) mapbase;
+#endif
+    const Elf_Phdr *prog_header = (const Elf_Phdr *)(mapbase + elf_header->e_phoff);
+
+    for (i = 0; i < elf_header->e_phnum; i++)
+    {
+         if (prog_header->p_type == PT_LOAD)
+         {
+             caddr_t desired_base = (caddr_t)((prog_header->p_vaddr / prog_header->p_align) * prog_header->p_align);
+             *relocbase = (caddr_t) (mapbase - desired_base);
+             return TRUE;
+         }
+         prog_header++;
+    }
+    return FALSE;
+}
+#endif
+
+/*************************************************************************
+ *              init_builtin_dll
+ */
+static void CDECL init_builtin_dll( void *module )
+{
+#ifdef HAVE_DLINFO
+    void *handle = NULL;
+    struct link_map *map;
+    void (*init_func)(int, char **, char **) = NULL;
+    void (**init_array)(int, char **, char **) = NULL;
+    ULONG_PTR i, init_arraysz = 0;
+#ifdef _WIN64
+    const Elf64_Dyn *dyn;
+#else
+    const Elf32_Dyn *dyn;
+#endif
+
+    if (!(handle = get_builtin_so_handle( module ))) return;
+    if (dlinfo( handle, RTLD_DI_LINKMAP, &map )) map = NULL;
+    release_builtin_module( module );
+    if (!map) return;
+
+    for (dyn = map->l_ld; dyn->d_tag; dyn++)
+    {
+        caddr_t relocbase = (caddr_t)map->l_addr;
+
+#ifdef __FreeBSD__
+        /* On older FreeBSD versions, l_addr was the absolute load address, now it's the relocation offset. */
+        if (offsetof(struct link_map, l_addr) == 0)
+            if (!get_relocbase(map->l_addr, &relocbase))
+                return;
+#endif
+        switch (dyn->d_tag)
+        {
+        case 0x60009990: init_array = (void *)(relocbase + dyn->d_un.d_val); break;
+        case 0x60009991: init_arraysz = dyn->d_un.d_val; break;
+        case 0x60009992: init_func = (void *)(relocbase + dyn->d_un.d_val); break;
+        }
+    }
+
+    TRACE( "%p: got init_func %p init_array %p %lu\n", module, init_func, init_array, init_arraysz );
+
+    if (init_func) init_func( main_argc, main_argv, main_envp );
+
+    if (init_array)
+        for (i = 0; i < init_arraysz / sizeof(*init_array); i++)
+            init_array[i]( main_argc, main_argv, main_envp );
+#endif
+}
+
+
+/***********************************************************************
+ *           load_ntdll
+ */
+static void load_ntdll(void)
+{
+    static WCHAR path[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\',
+                           's','y','s','t','e','m','3','2','\\','n','t','d','l','l','.','d','l','l',0};
+    const char *pe_dir = get_pe_dir( current_machine );
+    NTSTATUS status;
+    SECTION_IMAGE_INFORMATION info;
+    OBJECT_ATTRIBUTES attr;
+    UNICODE_STRING str;
+    void *module;
+    SIZE_T size = 0;
+    char *name;
+
+    init_unicode_string( &str, path );
+    InitializeObjectAttributes( &attr, &str, 0, 0, NULL );
+
+    name = malloc( strlen( ntdll_dir ) + strlen( pe_dir ) + sizeof("/ntdll.dll.so") );
+    if (build_dir) sprintf( name, "%s/ntdll.dll", ntdll_dir );
+    else sprintf( name, "%s%s/ntdll.dll", dll_dir, pe_dir );
+    status = open_builtin_pe_file( name, &attr, &module, &size, &info, 0, current_machine, FALSE );
+    if (status == STATUS_DLL_NOT_FOUND)
+    {
+        sprintf( name, "%s/ntdll.dll.so", ntdll_dir );
+        status = open_builtin_so_file( name, &attr, &module, &info, current_machine, FALSE );
+    }
+    if (status == STATUS_IMAGE_NOT_AT_BASE) relocate_ntdll( module );
+    else if (status) fatal_error( "failed to load %s error %x\n", name, status );
+    free( name );
+    load_ntdll_functions( module );
+    ntdll_module = module;
+}
+
+
+/***********************************************************************
+ *           load_apiset_dll
+ */
+static void load_apiset_dll(void)
+{
+    static WCHAR path[] = {'\\','?','?','\\','C',':','\\','w','i','n','d','o','w','s','\\',
+                           's','y','s','t','e','m','3','2','\\',
+                           'a','p','i','s','e','t','s','c','h','e','m','a','.','d','l','l',0};
+    const char *pe_dir = get_pe_dir( current_machine );
+    const IMAGE_NT_HEADERS *nt;
+    const IMAGE_SECTION_HEADER *sec;
+    API_SET_NAMESPACE *map;
+    OBJECT_ATTRIBUTES attr;
+    UNICODE_STRING str;
+    NTSTATUS status;
+    HANDLE handle, mapping;
+    SIZE_T size;
+    char *name;
+    void *ptr;
+    UINT i;
+
+    init_unicode_string( &str, path );
+    InitializeObjectAttributes( &attr, &str, 0, 0, NULL );
+
+    name = malloc( strlen( ntdll_dir ) + strlen( pe_dir ) + sizeof("/apisetschema.dll") );
+    if (build_dir) sprintf( name, "%s/dlls/apisetschema/apisetschema.dll", build_dir );
+    else sprintf( name, "%s%s/apisetschema.dll", dll_dir, pe_dir );
+    status = open_unix_file( &handle, name, GENERIC_READ | SYNCHRONIZE, &attr, 0,
+                             FILE_SHARE_READ | FILE_SHARE_DELETE, FILE_OPEN,
+                             FILE_SYNCHRONOUS_IO_NONALERT | FILE_NON_DIRECTORY_FILE, NULL, 0 );
+    free( name );
+
+    if (!status)
+    {
+        status = NtCreateSection( &mapping, STANDARD_RIGHTS_REQUIRED | SECTION_QUERY | SECTION_MAP_READ,
+                                  NULL, NULL, PAGE_READONLY, SEC_COMMIT, handle );
+        NtClose( handle );
+    }
+    if (!status)
+    {
+        status = map_section( mapping, &ptr, &size, PAGE_READONLY );
+        NtClose( mapping );
+    }
+    if (!status)
+    {
+        nt = get_rva( ptr, ((IMAGE_DOS_HEADER *)ptr)->e_lfanew );
+        sec = (IMAGE_SECTION_HEADER *)((char *)&nt->OptionalHeader + nt->FileHeader.SizeOfOptionalHeader);
+
+        for (i = 0; i < nt->FileHeader.NumberOfSections; i++, sec++)
+        {
+            if (memcmp( (char *)sec->Name, ".apiset", 8 )) continue;
+            map = (API_SET_NAMESPACE *)((char *)ptr + sec->PointerToRawData);
+            if (sec->PointerToRawData < size &&
+                size - sec->PointerToRawData >= sec->Misc.VirtualSize &&
+                map->Version == 6 &&
+                map->Size <= sec->Misc.VirtualSize)
+            {
+                NtCurrentTeb()->Peb->ApiSetMap = map;
+                if (wow_peb) wow_peb->ApiSetMap = PtrToUlong(map);
+                TRACE( "loaded %s apiset at %p\n", debugstr_w(path), map );
+                return;
+            }
+            break;
+        }
+        NtUnmapViewOfSection( NtCurrentProcess(), ptr );
+        status = STATUS_APISET_NOT_PRESENT;
+    }
+    ERR( "failed to load apiset: %x\n", status );
+}
+
+
+/***********************************************************************
+ *           load_wow64_ntdll
+ */
+static void load_wow64_ntdll( USHORT machine )
+{
+    static const WCHAR ntdllW[] = {'n','t','d','l','l','.','d','l','l',0};
+    SECTION_IMAGE_INFORMATION info;
+    UNICODE_STRING nt_name;
+    void *module;
+    NTSTATUS status;
+    SIZE_T size;
+    WCHAR *path = malloc( sizeof("\\??\\C:\\windows\\system32\\ntdll.dll") * sizeof(WCHAR) );
+
+    wcscpy( path, get_machine_wow64_dir( machine ));
+    wcscat( path, ntdllW );
+    init_unicode_string( &nt_name, path );
+    status = find_builtin_dll( &nt_name, &module, &size, &info, 0, machine, FALSE );
+    switch (status)
+    {
+    case STATUS_IMAGE_NOT_AT_BASE:
+        relocate_ntdll( module );
+        /* fall through */
+    case STATUS_SUCCESS:
+        load_ntdll_wow64_functions( module );
+        TRACE("loaded %s at %p\n", debugstr_w(path), module );
+        break;
+    default:
+        ERR( "failed to load %s error %x\n", debugstr_w(path), status );
+        break;
+    }
+    free( path );
+}
+
+
+/***********************************************************************
+ *           get_image_address
+ */
+static ULONG_PTR get_image_address(void)
+{
+#ifdef HAVE_GETAUXVAL
+    ULONG_PTR size, num, phdr_addr = getauxval( AT_PHDR );
+    ElfW(Phdr) *phdr;
+
+    if (!phdr_addr) return 0;
+    phdr = (ElfW(Phdr) *)phdr_addr;
+    size = getauxval( AT_PHENT );
+    num = getauxval( AT_PHNUM );
+    while (num--)
+    {
+        if (phdr->p_type == PT_PHDR) return phdr_addr - phdr->p_offset;
+        phdr = (ElfW(Phdr) *)((char *)phdr + size);
+    }
+#elif defined(__APPLE__) && defined(TASK_DYLD_INFO)
+    struct task_dyld_info dyld_info;
+    mach_msg_type_number_t size = TASK_DYLD_INFO_COUNT;
+
+    if (task_info(mach_task_self(), TASK_DYLD_INFO, (task_info_t)&dyld_info, &size) == KERN_SUCCESS)
+        return dyld_info.all_image_info_addr;
+#endif
+    return 0;
+}
+
+
+/***********************************************************************
+ *           unix_funcs
+ */
+static struct unix_funcs unix_funcs =
+{
+    load_so_dll,
+    init_builtin_dll,
+    unwind_builtin_dll,
+    RtlGetSystemTimePrecise,
+#ifdef __aarch64__
+    NtCurrentTeb,
+#endif
+#if defined(__x86_64__)
+    pe_module_loaded,
+    gs_patching_needed,
+#endif
+};
+
+
+#if defined(__APPLE__) && defined(__x86_64__)
+static __thread struct tm localtime_tls;
+struct tm *my_localtime(const time_t *timep)
+{
+    return localtime_r(timep, &localtime_tls);
+}
+
+static void hook(void *to_hook, const void *replace)
+{
+    size_t offset;
+    int ret;
+
+    struct hooked_function
+    {
+        char jmp[8];
+        const void *dst;
+    } *hooked_function = to_hook;
+    ULONG_PTR intval = (UINT_PTR)to_hook;
+
+    intval -= (intval % 4096);
+    ret = mprotect((void *)intval, 0x2000, PROT_EXEC | PROT_READ | PROT_WRITE);
+
+    /* The offset is from the end of the jmp instruction (6 bytes) to the start of the destination. */
+    offset = offsetof(struct hooked_function, dst) - offsetof(struct hooked_function, jmp) - 0x6;
+
+    /* jmp *(rip + offset) */
+    hooked_function->jmp[0] = 0xff;
+    hooked_function->jmp[1] = 0x25;
+    hooked_function->jmp[2] = offset;
+    hooked_function->jmp[3] = 0x00;
+    hooked_function->jmp[4] = 0x00;
+    hooked_function->jmp[5] = 0x00;
+    /* Filler */
+    hooked_function->jmp[6] = 0xcc;
+    hooked_function->jmp[7] = 0xcc;
+    /* Dest address absolute */
+    hooked_function->dst = replace;
+
+    //size = sizeof(*hooked_function);
+    //NtProtectVirtualMemory(proc, (void **)hooked_function, &size, old_protect, &old_protect);
+}
+#endif
+
+/* CX HACK 21109: dlopen opengl32.dll.so early in 32-on-64 */
+#if defined(__APPLE__) && defined(__x86_64__)
+static void dlopen_32on64_opengl32(void)
+{
+    char file[MAX_PATH];
+    unsigned int i;
+    struct stat st;
+    void *handle;
+
+    for (i = 0; dll_paths[i]; i++)
+    {
+        snprintf(file, MAX_PATH, "%s%s/opengl32.dll.so", dll_paths[i], so_dir_32on64);
+
+        if (!stat(file, &st) &&
+            (handle = dlopen(file, RTLD_NOW)))
+        {
+            /* Nothing special about the NT header; just using something
+             * we know will be there. */
+            Dl_info info = {0};
+            void *symaddr = dlsym(handle, "__wine_spec_nt_header");
+            dladdr(symaddr, &info);
+
+            FIXME("loaded %s early @ %p\n", debugstr_a(file), info.dli_fbase);
+            return;
+        }
+    }
+
+    FIXME("couldn't load opengl32.dll.so early\n");
+}
+#endif
+
+/***********************************************************************
+ *           start_main_thread
+ */
+static void start_main_thread(void)
+{
+    SYSTEM_SERVICE_TABLE syscall_table = { (ULONG_PTR *)syscalls, NULL, ARRAY_SIZE(syscalls), syscall_args };
+    NTSTATUS status;
+    TEB *teb = virtual_alloc_first_teb();
+
+    signal_init_threading();
+    signal_alloc_thread( teb );
+    signal_init_thread( teb );
+    dbg_init();
+    startup_info_size = server_init_process();
+    esync_init();
+    virtual_map_user_shared_data();
+    init_cpu_info();
+    init_files();
+    load_libwine();
+    init_startup_info();
+    if (p___wine_main_argc) *p___wine_main_argc = main_argc;
+    if (p___wine_main_argv) *p___wine_main_argv = main_argv;
+    if (p___wine_main_wargv) *p___wine_main_wargv = main_wargv;
+    *(ULONG_PTR *)&peb->CloudFileFlags = get_image_address();
+    set_load_order_app_name( main_wargv[0] );
+    init_thread_stack( teb, 0, 0, 0 );
+    NtCreateKeyedEvent( &keyed_event, GENERIC_READ | GENERIC_WRITE, NULL, 0 );
+    load_ntdll();
+    if (main_image_info.Machine != current_machine)
+    {
+        load_wow64_ntdll( main_image_info.Machine );
+
+    /* CX HACK 21109: dlopen opengl32.dll.so early in 32-on-64 */
+#if defined(__APPLE__) && defined(__x86_64__)
+        if (main_image_info.Machine == IMAGE_FILE_MACHINE_I386)
+            dlopen_32on64_opengl32();
+#endif
+    }
+    else
+    {
+        init_non_native_support();
+    }
+    load_apiset_dll();
+    ntdll_init_syscalls( 0, &syscall_table, p__wine_syscall_dispatcher );
+    status = p__wine_set_unix_funcs( NTDLL_UNIXLIB_VERSION, &unix_funcs );
+    if (status == STATUS_REVISION_MISMATCH)
+    {
+        ERR( "ntdll library version mismatch\n" );
+        NtTerminateProcess( GetCurrentProcess(), status );
+    }
+#if defined(__APPLE__) && defined(__x86_64__)
+    /* This is necessary because we poke PEB into pthread TLS at offset 0x60. It is normally in use by
+     * localtime(), which is called a lot by system libraries. Make localtime() go away. */
+    hook(localtime, my_localtime);
+#endif
+    server_init_process_done();
+}
+
+#ifdef __ANDROID__
+
+#ifndef WINE_JAVA_CLASS
+#define WINE_JAVA_CLASS "org/winehq/wine/WineActivity"
+#endif
+
+JavaVM *java_vm = NULL;
+jobject java_object = 0;
+unsigned short java_gdt_sel = 0;
+
+/* main Wine initialisation */
+static jstring wine_init_jni( JNIEnv *env, jobject obj, jobjectArray cmdline, jobjectArray environment )
+{
+    char **argv;
+    char *str;
+    char error[1024];
+    int i, argc, length;
+
+    /* get the command line array */
+
+    argc = (*env)->GetArrayLength( env, cmdline );
+    for (i = length = 0; i < argc; i++)
+    {
+        jobject str_obj = (*env)->GetObjectArrayElement( env, cmdline, i );
+        length += (*env)->GetStringUTFLength( env, str_obj ) + 1;
+    }
+
+    argv = malloc( (argc + 1) * sizeof(*argv) + length );
+    str = (char *)(argv + argc + 1);
+    for (i = 0; i < argc; i++)
+    {
+        jobject str_obj = (*env)->GetObjectArrayElement( env, cmdline, i );
+        length = (*env)->GetStringUTFLength( env, str_obj );
+        (*env)->GetStringUTFRegion( env, str_obj, 0,
+                                    (*env)->GetStringLength( env, str_obj ), str );
+        argv[i] = str;
+        str[length] = 0;
+        str += length + 1;
+    }
+    argv[argc] = NULL;
+
+    /* set the environment variables */
+
+    if (environment)
+    {
+        int count = (*env)->GetArrayLength( env, environment );
+        for (i = 0; i < count - 1; i += 2)
+        {
+            jobject var_obj = (*env)->GetObjectArrayElement( env, environment, i );
+            jobject val_obj = (*env)->GetObjectArrayElement( env, environment, i + 1 );
+            const char *var = (*env)->GetStringUTFChars( env, var_obj, NULL );
+
+            if (val_obj)
+            {
+                const char *val = (*env)->GetStringUTFChars( env, val_obj, NULL );
+                setenv( var, val, 1 );
+                if (!strcmp( var, "LD_LIBRARY_PATH" ))
+                {
+                    void (*update_func)( const char * ) = dlsym( RTLD_DEFAULT,
+                                                                 "android_update_LD_LIBRARY_PATH" );
+                    if (update_func) update_func( val );
+                }
+                else if (!strcmp( var, "WINEDEBUGLOG" ))
+                {
+                    int fd = open( val, O_WRONLY | O_CREAT | O_APPEND, 0666 );
+                    if (fd != -1)
+                    {
+                        dup2( fd, 2 );
+                        close( fd );
+                    }
+                }
+                (*env)->ReleaseStringUTFChars( env, val_obj, val );
+            }
+            else unsetenv( var );
+
+            (*env)->ReleaseStringUTFChars( env, var_obj, var );
+        }
+    }
+
+    java_object = (*env)->NewGlobalRef( env, obj );
+
+    init_paths( argv );
+    virtual_init();
+    init_environment( argc, argv, environ );
+
+#ifdef __i386__
+    {
+        unsigned short java_fs;
+        __asm__( "mov %%fs,%0" : "=r" (java_fs) );
+        if (!(java_fs & 4)) java_gdt_sel = java_fs;
+        __asm__( "mov %0,%%fs" :: "r" (0) );
+        start_main_thread();
+        __asm__( "mov %0,%%fs" :: "r" (java_fs) );
+    }
+#else
+    start_main_thread();
+#endif
+    return (*env)->NewStringUTF( env, error );
+}
+
+jint JNI_OnLoad( JavaVM *vm, void *reserved )
+{
+    static const JNINativeMethod method =
+    {
+        "wine_init", "([Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String;", wine_init_jni
+    };
+
+    JNIEnv *env;
+    jclass class;
+
+    java_vm = vm;
+    if ((*vm)->AttachCurrentThread( vm, &env, NULL ) != JNI_OK) return JNI_ERR;
+    if (!(class = (*env)->FindClass( env, WINE_JAVA_CLASS ))) return JNI_ERR;
+    (*env)->RegisterNatives( env, class, &method, 1 );
+    return JNI_VERSION_1_6;
+}
+
+#endif  /* __ANDROID__ */
+
+#ifdef __APPLE__
+static void *apple_wine_thread( void *arg )
+{
+    start_main_thread();
+    return NULL;
+}
+
+/***********************************************************************
+ *           apple_create_wine_thread
+ *
+ * Spin off a secondary thread to complete Wine initialization, leaving
+ * the original thread for the Mac frameworks.
+ *
+ * Invoked as a CFRunLoopSource perform callback.
+ */
+static void apple_create_wine_thread( void *arg )
+{
+    pthread_t thread;
+    pthread_attr_t attr;
+
+    pthread_attr_init( &attr );
+    pthread_attr_setdetachstate( &attr, PTHREAD_CREATE_JOINABLE );
+    /* CW HACK 21133: set Wine thread QoS class */
+    pthread_attr_set_qos_class_np( &attr, QOS_CLASS_USER_INTERACTIVE, 0 );
+    if (pthread_create( &thread, &attr, apple_wine_thread, NULL )) exit(1);
+    pthread_attr_destroy( &attr );
+}
+
+
+/***********************************************************************
+ *           apple_main_thread
+ *
+ * Park the process's original thread in a Core Foundation run loop for
+ * use by the Mac frameworks, especially receiving and handling
+ * distributed notifications.  Spin off a new thread for the rest of the
+ * Wine initialization.
+ */
+static void apple_main_thread(void)
+{
+    CFRunLoopSourceContext source_context = { 0 };
+    CFRunLoopSourceRef source;
+
+    if (!pthread_main_np()) return;
+
+    /* Multi-processing Services can get confused about the main thread if the
+     * first time it's used is on a secondary thread.  Use it here to make sure
+     * that doesn't happen. */
+    MPTaskIsPreemptive(MPCurrentTaskID());
+
+    /* Give ourselves the best chance of having the distributed notification
+     * center scheduled on this thread's run loop.  In theory, it's scheduled
+     * in the first thread to ask for it. */
+    CFNotificationCenterGetDistributedCenter();
+
+    /* We use this run loop source for two purposes.  First, a run loop exits
+     * if it has no more sources scheduled.  So, we need at least one source
+     * to keep the run loop running.  Second, although it's not critical, it's
+     * preferable for the Wine initialization to not proceed until we know
+     * the run loop is running.  So, we signal our source immediately after
+     * adding it and have its callback spin off the Wine thread. */
+    source_context.perform = apple_create_wine_thread;
+    source = CFRunLoopSourceCreate( NULL, 0, &source_context );
+    CFRunLoopAddSource( CFRunLoopGetCurrent(), source, kCFRunLoopCommonModes );
+    CFRunLoopSourceSignal( source );
+    CFRelease( source );
+    CFRunLoopRun(); /* Should never return, except on error. */
+}
+#endif  /* __APPLE__ */
+
+
+#ifdef __ANDROID__
+
+static int pre_exec(void)
+{
+#if defined(__i386__) || defined(__x86_64__)
+    return 1;  /* we have a preloader */
+#else
+    return 0;  /* no exec needed */
+#endif
+}
+
+#elif defined(__linux__) && (defined(__i386__) || defined(__arm__))
+
+static void check_vmsplit( void *stack )
+{
+    if (stack < (void *)0x80000000)
+    {
+        /* if the stack is below 0x80000000, assume we can safely try a munmap there */
+        if (munmap( (void *)0x80000000, 1 ) == -1 && errno == EINVAL)
+            ERR( "Warning: memory above 0x80000000 doesn't seem to be accessible.\n"
+                 "Wine requires a 3G/1G user/kernel memory split to work properly.\n" );
+    }
+}
+
+static int pre_exec(void)
+{
+    int temp;
+
+    check_vmsplit( &temp );
+    return 1;  /* we have a preloader on x86/arm */
+}
+
+#elif defined(__linux__) && (defined(__x86_64__) || defined(__aarch64__))
+
+static int pre_exec(void)
+{
+    return 1;  /* we have a preloader on x86-64/arm64 */
+}
+
+#elif defined(__APPLE__) && (defined(__i386__) || defined(__x86_64__))
+
+static int pre_exec(void)
+{
+    return 1;  /* we have a preloader */
+}
+
+#elif (defined(__FreeBSD__) || defined (__FreeBSD_kernel__) || defined(__DragonFly__))
+
+static int pre_exec(void)
+{
+    struct rlimit rl;
+
+    rl.rlim_cur = 0x02000000;
+    rl.rlim_max = 0x02000000;
+    setrlimit( RLIMIT_DATA, &rl );
+    return 1;
+}
+
+#else
+
+static int pre_exec(void)
+{
+    return 0;  /* no exec needed */
+}
+
+#endif
+
+
+/***********************************************************************
+ *           check_command_line
+ *
+ * Check if command line is one that needs to be handled specially.
+ */
+static void check_command_line( int argc, char *argv[] )
+{
+    static const char usage[] =
+        "Usage: wine PROGRAM [ARGUMENTS...]   Run the specified program\n"
+        "       wine --help                   Display this help and exit\n"
+        "       wine --version                Output version information and exit";
+
+    if (argc <= 1)
+    {
+        fprintf( stderr, "%s\n", usage );
+        exit(1);
+    }
+    if (!strcmp( argv[1], "--help" ))
+    {
+        printf( "%s\n", usage );
+        exit(0);
+    }
+    if (!strcmp( argv[1], "--version" ))
+    {
+        printf( "%s\n", wine_build );
+        exit(0);
+    }
+}
+
+
+/***********************************************************************
+ *           __wine_main
+ *
+ * Main entry point called by the wine loader.
+ */
+void __wine_main( int argc, char *argv[], char *envp[] )
+{
+    init_paths( argv );
+
+    if (!getenv( "WINELOADERNOEXEC" ))  /* first time around */
+    {
+        check_command_line( argc, argv );
+        if (pre_exec())
+        {
+            static char noexec[] = "WINELOADERNOEXEC=1";
+            char **new_argv = malloc( (argc + 2) * sizeof(*argv) );
+
+            memcpy( new_argv + 1, argv, (argc + 1) * sizeof(*argv) );
+            putenv( noexec );
+            loader_exec( argv0, new_argv, current_machine );
+            fatal_error( "could not exec the wine loader\n" );
+        }
+    }
+
+#ifdef RLIMIT_NOFILE
+    set_max_limit( RLIMIT_NOFILE );
+#endif
+#ifdef RLIMIT_AS
+    set_max_limit( RLIMIT_AS );
+#endif
+
+    virtual_init();
+    init_environment( argc, argv, envp );
+
+#ifdef __APPLE__
+    apple_main_thread();
+#endif
+    start_main_thread();
+}
diff --git a/wine/dlls/ntdll/unix/msync.c b/wine/dlls/ntdll/unix/msync.c
new file mode 100644
index 000000000..1dbfb25b1
--- /dev/null
+++ b/wine/dlls/ntdll/unix/msync.c
@@ -0,0 +1,1491 @@
+/*
+ * mach semaphore-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ * Copyright (C) 2023 Marc-Aurel Zent
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#if 0
+#pragma makedep unix
+#endif
+
+#include "config.h"
+
+#include <assert.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <limits.h>
+#include <stdarg.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#ifdef HAVE_SYS_SYSCALL_H
+# include <sys/syscall.h>
+#endif
+#ifdef __APPLE__
+# include <mach/mach_init.h>
+# include <mach/mach_port.h>
+# include <mach/message.h>
+# include <mach/port.h>
+# include <mach/task.h>
+# include <mach/semaphore.h>
+# include <mach/error.h>
+# include <servers/bootstrap.h>
+# include <os/lock.h>
+#endif
+#include <sched.h>
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#define NONAMELESSUNION
+#include "windef.h"
+#include "winternl.h"
+#include "wine/debug.h"
+#include "wine/server.h"
+
+#include "unix_private.h"
+#include "msync.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(msync);
+
+static LONGLONG update_timeout( ULONGLONG end )
+{
+    LARGE_INTEGER now;
+    LONGLONG timeleft;
+
+    NtQuerySystemTime( &now );
+    timeleft = end - now.QuadPart;
+    if (timeleft < 0) timeleft = 0;
+    return timeleft;
+}
+
+static inline mach_timespec_t convert_to_mach_time( LONGLONG win32_time )
+{
+    mach_timespec_t ret;
+    
+    ret.tv_sec = win32_time / (ULONGLONG)TICKSPERSEC;
+    ret.tv_nsec = (win32_time % TICKSPERSEC) * 100;
+    return ret;
+}
+
+extern mach_msg_return_t mach_msg_overwrite_trap( mach_msg_header_t *msg, mach_msg_option_t option,
+        mach_msg_size_t send_size, mach_msg_size_t rcv_size, mach_port_name_t rcv_name, mach_msg_timeout_t timeout,
+        mach_msg_priority_t priority, mach_msg_header_t *rcv_msg, mach_msg_size_t rcv_limit);
+
+/* this is a lot, but running out cripples performance */
+#define MAX_POOL_SEMAPHORES 1024
+#define POOL_SHRINK_THRESHOLD 30
+#define POOL_SHRINK_COUNT 10
+
+struct semaphore_memory_pool
+{
+    semaphore_t semaphores[MAX_POOL_SEMAPHORES];
+    semaphore_t *free_semaphores[MAX_POOL_SEMAPHORES];
+    unsigned int count;
+    unsigned int total;
+    os_unfair_lock lock;
+};
+
+static struct semaphore_memory_pool *pool;
+
+static void semaphore_pool_init(void)
+{
+    unsigned int i;
+
+    pool = malloc( sizeof(struct semaphore_memory_pool) );
+
+    pool->lock = OS_UNFAIR_LOCK_INIT;
+
+    for (i = 0; i < MAX_POOL_SEMAPHORES; i++)
+    {
+        pool->free_semaphores[i] = &pool->semaphores[i];
+    }
+    
+    pool->count = 0;
+    pool->total = 0;
+}
+
+static inline semaphore_t *semaphore_pool_alloc(void)
+{
+    semaphore_t *new_semaphore;
+    kern_return_t kr;
+
+    os_unfair_lock_lock(&pool->lock);
+
+    if (pool->count == 0)
+    {
+        if (pool->total < MAX_POOL_SEMAPHORES)
+        {
+            TRACE("Dynamically growing semaphore pool\n");
+            kr = semaphore_create(mach_task_self(), &pool->semaphores[pool->total], SYNC_POLICY_FIFO, 0);
+            if (kr != KERN_SUCCESS)
+                ERR("Cannot create dynamic semaphore: %#x %s\n", kr, mach_error_string(kr));
+            
+            new_semaphore = &pool->semaphores[pool->total];
+            pool->total++;
+
+            os_unfair_lock_unlock(&pool->lock);
+
+            return new_semaphore;
+        }
+        else
+        {
+            os_unfair_lock_unlock(&pool->lock);
+            
+            WARN("Semaphore pool exhausted, consider increasing MAX_POOL_SEMAPHORES\n");
+            new_semaphore = malloc(sizeof(semaphore_t));
+            kr = semaphore_create(mach_task_self(), new_semaphore, SYNC_POLICY_FIFO, 0);
+            if (kr != KERN_SUCCESS)
+                ERR("Cannot create dynamic semaphore: %#x %s\n", kr, mach_error_string(kr));
+
+            return new_semaphore;
+        }
+    }
+
+    new_semaphore = pool->free_semaphores[pool->count - 1];
+    pool->count--;
+
+    os_unfair_lock_unlock(&pool->lock);
+
+    return new_semaphore;
+}
+
+static inline void semaphore_pool_free(semaphore_t *sem)
+{
+    int i;
+    
+    os_unfair_lock_lock(&pool->lock);
+
+    if (sem < pool->semaphores || sem >= pool->semaphores + MAX_POOL_SEMAPHORES)
+    {
+        os_unfair_lock_unlock(&pool->lock);
+        
+        semaphore_destroy(mach_task_self(), *sem);
+        free(sem);
+
+        return;
+    }
+    
+    if (pool->count >= POOL_SHRINK_THRESHOLD)
+    {
+        TRACE("Dynamically shrinking semaphore pool\n");
+        for (i = 0; i < POOL_SHRINK_COUNT; i++)
+        {
+            semaphore_destroy(mach_task_self(), *sem);
+            pool->total--;
+        }
+    }
+    else
+    {
+        pool->free_semaphores[pool->count] = sem;
+        pool->count++;
+    }
+
+    os_unfair_lock_unlock(&pool->lock);
+}
+
+struct msync
+{
+    void *shm;              /* pointer to shm section */
+    enum msync_type type;
+    unsigned int shm_idx;
+};
+
+static inline void resize_wait_objs( struct msync **wait_objs, int *count )
+{
+    int read_index = 0;
+    int write_index = 0;
+
+    for (; read_index < *count; read_index++)
+    {
+        if (wait_objs[read_index] != NULL)
+        {
+            if (read_index != write_index)
+                wait_objs[write_index] = wait_objs[read_index];
+            write_index++;
+        }
+    }
+    *count = write_index;
+}
+
+typedef struct
+{
+    mach_msg_header_t header;
+    mach_msg_body_t body;
+    mach_msg_port_descriptor_t descriptor;
+} mach_register_message_prolog_t;
+
+typedef struct
+{
+    mach_register_message_prolog_t prolog;
+    unsigned int shm_idx[MAXIMUM_WAIT_OBJECTS + 1];
+} mach_register_message_t;
+
+typedef struct
+{
+    mach_msg_header_t header;
+    unsigned int shm_idx[MAXIMUM_WAIT_OBJECTS + 1];
+} mach_unregister_message_t;
+
+static mach_port_t server_port;
+
+static const mach_msg_bits_t msgh_bits_complex_send = MACH_MSGH_BITS_SET(
+                MACH_MSG_TYPE_COPY_SEND, 0, 0, MACH_MSGH_BITS_COMPLEX);
+
+static const mach_msg_bits_t msgh_bits_send = MACH_MSGH_BITS_REMOTE(MACH_MSG_TYPE_COPY_SEND);
+
+static inline void server_register_wait( semaphore_t sem, unsigned int msgh_id,
+                                        struct msync **wait_objs, const int count )
+{
+    int i, is_mutex;
+    mach_msg_return_t mr;
+    __thread static mach_register_message_t message;
+    
+    message.prolog.header.msgh_remote_port = server_port;
+    message.prolog.header.msgh_bits = msgh_bits_complex_send;
+    message.prolog.header.msgh_id = msgh_id;
+
+    message.prolog.body.msgh_descriptor_count = 1;
+    
+    message.prolog.descriptor.name = sem;
+    message.prolog.descriptor.disposition = MACH_MSG_TYPE_COPY_SEND;
+    message.prolog.descriptor.type = MACH_MSG_PORT_DESCRIPTOR;
+    
+    for (i = 0; i < count; i++)
+    {
+        is_mutex = wait_objs[i]->type == MSYNC_MUTEX ? 1 : 0;
+        message.shm_idx[i] = wait_objs[i]->shm_idx | (is_mutex << 19);
+    }
+
+    message.prolog.header.msgh_size = sizeof(mach_register_message_prolog_t) +
+                                      count * sizeof(unsigned int);
+
+    mr = mach_msg_overwrite_trap( (mach_msg_header_t *)&message, MACH_SEND_MSG, message.prolog.header.msgh_size,
+                     0, MACH_PORT_NULL, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL, NULL, 0 );
+    
+    if (mr != MACH_MSG_SUCCESS)
+        ERR("Failed to send server register wait: %#x\n", mr);
+}
+
+static inline void server_remove_wait( semaphore_t sem, unsigned int msgh_id,
+                                        struct msync **wait_objs, const int count )
+{
+    int i;
+    mach_msg_return_t mr;
+    __thread static mach_unregister_message_t message;
+    
+    message.header.msgh_remote_port = server_port;
+    message.header.msgh_bits = msgh_bits_send;
+    message.header.msgh_id = msgh_id;
+    
+    for (i = 0; i < count; i++)
+        message.shm_idx[i] = wait_objs[i]->shm_idx;
+    
+    message.header.msgh_size = sizeof(mach_msg_header_t) +
+                               count * sizeof(unsigned int);
+
+    mr = mach_msg_overwrite_trap( (mach_msg_header_t *)&message, MACH_SEND_MSG, message.header.msgh_size,
+                     0, MACH_PORT_NULL, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL, NULL, 0 );
+    
+    if (mr != MACH_MSG_SUCCESS)
+        ERR("Failed to send server remove wait: %#x\n", mr);
+}
+
+static NTSTATUS msync_wait_multiple( struct msync **wait_objs,
+                                     int count, ULONGLONG *end )
+{
+    int i, val, tid;
+    semaphore_t *sem;
+    kern_return_t kr;
+    LONGLONG timeleft;
+    unsigned int msgh_id;
+
+    resize_wait_objs( wait_objs, &count );
+
+    tid = GetCurrentThreadId();
+    for (i = 0; i < count; i++)
+    {
+        val = __atomic_load_n((int *)wait_objs[i]->shm, __ATOMIC_SEQ_CST);
+        if (wait_objs[i]->type == MSYNC_MUTEX)
+        {
+            if (val == 0 || val == ~0 || val == tid) return STATUS_PENDING;
+        }
+        else
+        {
+            if (val != 0)  return STATUS_PENDING;
+        }
+    }
+
+    sem = semaphore_pool_alloc();
+    msgh_id = (tid << 8) | count;
+    server_register_wait( *sem, msgh_id, wait_objs, count );
+
+    do
+    {
+        if (end)
+        {
+            timeleft = update_timeout( *end );
+            if (!timeleft)
+            {
+                kr = KERN_OPERATION_TIMED_OUT;
+                break;
+            }
+            kr = semaphore_timedwait( *sem, convert_to_mach_time( timeleft ) );
+        }
+        else
+            kr = semaphore_wait( *sem );
+    } while (kr == KERN_ABORTED);
+    
+    semaphore_pool_free( sem );
+
+    switch (kr) {
+        case KERN_SUCCESS:
+            if (count > 1)
+                server_remove_wait( *sem, msgh_id, wait_objs, count );
+            return STATUS_SUCCESS;
+        case KERN_OPERATION_TIMED_OUT:
+            server_remove_wait( *sem, msgh_id, wait_objs, count );
+            return STATUS_TIMEOUT;
+        case KERN_TERMINATED:
+            server_remove_wait( *sem, msgh_id, wait_objs, count );
+            if (end)
+            {
+                timeleft = update_timeout( *end );
+                usleep(timeleft / 10);
+                return STATUS_TIMEOUT;
+            }
+            pause();
+            return STATUS_PENDING;
+        default:
+            server_remove_wait( *sem, msgh_id, wait_objs, count );
+            ERR("Unexpected kernel return code: %#x %s\n", kr, mach_error_string(kr));
+            return STATUS_PENDING;
+    }
+}
+
+int do_msync(void)
+{
+#ifdef __APPLE__
+    static int do_msync_cached = -1;
+
+    if (do_msync_cached == -1)
+        do_msync_cached = getenv("WINEMSYNC") && atoi(getenv("WINEMSYNC"));
+
+    return do_msync_cached;
+#else
+    static int once;
+    if (!once++)
+        FIXME("mach semaphores not supported on this platform.\n");
+    return 0;
+#endif
+}
+
+struct semaphore
+{
+    int count;
+    int max;
+};
+C_ASSERT(sizeof(struct semaphore) == 8);
+
+struct event
+{
+    int signaled;
+    int unused;
+};
+C_ASSERT(sizeof(struct event) == 8);
+
+struct mutex
+{
+    int tid;
+    int count;  /* recursion count */
+};
+C_ASSERT(sizeof(struct mutex) == 8);
+
+static char shm_name[29];
+static int shm_fd;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+
+static os_unfair_lock shm_addrs_lock = OS_UNFAIR_LOCK_INIT;
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+    void *ret;
+
+    os_unfair_lock_lock( &shm_addrs_lock );
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            ERR("Failed to grow shm_addrs array to size %d.\n", shm_addrs_size);
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+            ERR("Failed to map page %d (offset %#lx).\n", entry, entry * pagesize);
+
+        TRACE("Mapping page %d at %p.\n", entry, addr);
+
+        if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    ret = (void *)((unsigned long)shm_addrs[entry] + offset);
+
+    os_unfair_lock_unlock( &shm_addrs_lock );
+
+    return ret;
+}
+
+/* We'd like lookup to be fast. To that end, we use a static list indexed by handle.
+ * This is copied and adapted from the fd cache code. */
+
+#define MSYNC_LIST_BLOCK_SIZE  (65536 / sizeof(struct msync))
+#define MSYNC_LIST_ENTRIES     256
+
+static struct msync *msync_list[MSYNC_LIST_ENTRIES];
+static struct msync msync_list_initial_block[MSYNC_LIST_BLOCK_SIZE];
+
+static inline UINT_PTR handle_to_index( HANDLE handle, UINT_PTR *entry )
+{
+    UINT_PTR idx = (((UINT_PTR)handle) >> 2) - 1;
+    *entry = idx / MSYNC_LIST_BLOCK_SIZE;
+    return idx % MSYNC_LIST_BLOCK_SIZE;
+}
+
+static struct msync *add_to_list( HANDLE handle, enum msync_type type, unsigned int shm_idx )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+    void *shm = get_shm( shm_idx );
+
+    if (entry >= MSYNC_LIST_ENTRIES)
+    {
+        FIXME( "too many allocated handles, not caching %p\n", handle );
+        return FALSE;
+    }
+
+    if (!msync_list[entry])  /* do we need to allocate a new block of entries? */
+    {
+        if (!entry) msync_list[0] = msync_list_initial_block;
+        else
+        {
+            void *ptr = anon_mmap_alloc( MSYNC_LIST_BLOCK_SIZE * sizeof(struct msync),
+                                         PROT_READ | PROT_WRITE );
+            if (ptr == MAP_FAILED) return FALSE;
+            msync_list[entry] = ptr;
+        }
+    }
+
+    if (!__sync_val_compare_and_swap((int *)&msync_list[entry][idx].type, 0, type ))
+    {
+        msync_list[entry][idx].shm = shm;
+        msync_list[entry][idx].shm_idx = shm_idx;
+    }
+
+    return &msync_list[entry][idx];
+}
+
+static struct msync *get_cached_object( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    if (entry >= MSYNC_LIST_ENTRIES || !msync_list[entry]) return NULL;
+    if (!msync_list[entry][idx].type) return NULL;
+
+    return &msync_list[entry][idx];
+}
+
+/* Gets an object. This is either a proper msync object (i.e. an event,
+ * semaphore, etc. created using create_msync) or a generic synchronizable
+ * server-side object which the server will signal (e.g. a process, thread,
+ * message queue, etc.) */
+static NTSTATUS get_object( HANDLE handle, struct msync **obj )
+{
+    NTSTATUS ret = STATUS_SUCCESS;
+    unsigned int shm_idx = 0;
+    enum msync_type type;
+
+    if ((*obj = get_cached_object( handle ))) return STATUS_SUCCESS;
+
+    if ((INT_PTR)handle < 0)
+    {
+        /* We can deal with pseudo-handles, but it's just easier this way */
+        return STATUS_NOT_IMPLEMENTED;
+    }
+
+    /* We need to try grabbing it from the server. */
+    SERVER_START_REQ( get_msync_idx )
+    {
+        req->handle = wine_server_obj_handle( handle );
+        if (!(ret = wine_server_call( req )))
+        {
+            shm_idx = reply->shm_idx;
+            type    = reply->type;
+        }
+    }
+    SERVER_END_REQ;
+
+    if (ret)
+    {
+        WARN("Failed to retrieve shm index for handle %p, status %#x.\n", handle, ret);
+        *obj = NULL;
+        return ret;
+    }
+
+    TRACE("Got shm index %d for handle %p.\n", shm_idx, handle);
+    *obj = add_to_list( handle, type, shm_idx );
+    return ret;
+}
+
+NTSTATUS msync_close( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    TRACE("%p.\n", handle);
+
+    if (entry < MSYNC_LIST_ENTRIES && msync_list[entry])
+    {
+        if (__atomic_exchange_n( &msync_list[entry][idx].type, 0, __ATOMIC_SEQ_CST ))
+            return STATUS_SUCCESS;
+    }
+
+    return STATUS_INVALID_HANDLE;
+}
+
+static NTSTATUS create_msync( enum msync_type type, HANDLE *handle,
+    ACCESS_MASK access, const OBJECT_ATTRIBUTES *attr, int low, int high )
+{
+    NTSTATUS ret;
+    data_size_t len;
+    struct object_attributes *objattr;
+    unsigned int shm_idx;
+
+    if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
+
+    SERVER_START_REQ( create_msync )
+    {
+        req->access = access;
+        req->low    = low;
+        req->high   = high;
+        req->type   = type;
+        wine_server_add_data( req, objattr, len );
+        ret = wine_server_call( req );
+        if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            shm_idx = reply->shm_idx;
+            type    = reply->type;
+        }
+    }
+    SERVER_END_REQ;
+
+    if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+    {
+        add_to_list( *handle, type, shm_idx );
+        TRACE("-> handle %p, shm index %d.\n", *handle, shm_idx);
+    }
+
+    free( objattr );
+    return ret;
+}
+
+static NTSTATUS open_msync( enum msync_type type, HANDLE *handle,
+    ACCESS_MASK access, const OBJECT_ATTRIBUTES *attr )
+{
+    NTSTATUS ret;
+    unsigned int shm_idx;
+
+    SERVER_START_REQ( open_msync )
+    {
+        req->access     = access;
+        req->attributes = attr->Attributes;
+        req->rootdir    = wine_server_obj_handle( attr->RootDirectory );
+        req->type       = type;
+        if (attr->ObjectName)
+            wine_server_add_data( req, attr->ObjectName->Buffer, attr->ObjectName->Length );
+        if (!(ret = wine_server_call( req )))
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            type = reply->type;
+            shm_idx = reply->shm_idx;
+        }
+    }
+    SERVER_END_REQ;
+
+    if (!ret)
+    {
+        add_to_list( *handle, type, shm_idx );
+        TRACE("-> handle %p, shm index %u.\n", *handle, shm_idx);
+    }
+    return ret;
+}
+
+void msync_init(void)
+{
+    struct stat st;
+    mach_port_t bootstrap_port;
+
+    if (!do_msync())
+    {
+        /* make sure the server isn't running with WINEMSYNC */
+        HANDLE handle;
+        NTSTATUS ret;
+
+        ret = create_msync( 0, &handle, 0, NULL, 0, 0 );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+        {
+            ERR("Server is running with WINEMSYNC but this process is not, please enable WINEMSYNC or restart wineserver.\n");
+            exit(1);
+        }
+
+        return;
+    }
+
+    if (stat( config_dir, &st ) == -1)
+        ERR("Cannot stat %s\n", config_dir);
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-msync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-msync", (unsigned long)st.st_ino );
+
+    if ((shm_fd = shm_open( shm_name, O_RDWR, 0644 )) == -1)
+    {
+        /* probably the server isn't running with WINEMSYNC, tell the user and bail */
+        if (errno == ENOENT)
+            ERR("Failed to open msync shared memory file; make sure no stale wineserver instances are running without WINEMSYNC.\n");
+        else
+            ERR("Failed to initialize shared memory: %s\n", strerror( errno ));
+        exit(1);
+    }
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+    
+    semaphore_pool_init();
+    
+    /* Bootstrap mach wineserver communication */
+    
+    if (task_get_special_port(mach_task_self(), TASK_BOOTSTRAP_PORT, &bootstrap_port) != KERN_SUCCESS)
+    {
+        ERR("Failed task_get_special_port\n");
+        exit(1);
+    }
+
+    if (bootstrap_look_up(bootstrap_port, shm_name + 1, &server_port) != KERN_SUCCESS)
+    {
+        ERR("Failed bootstrap_look_up for %s\n", shm_name + 1);
+        exit(1);
+    }
+}
+
+NTSTATUS msync_create_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, LONG initial, LONG max )
+{
+    TRACE("name %s, initial %d, max %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial, max);
+
+    return create_msync( MSYNC_SEMAPHORE, handle, access, attr, initial, max );
+}
+
+NTSTATUS msync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_msync( MSYNC_SEMAPHORE, handle, access, attr );
+}
+
+static inline void signal_all( struct msync *obj )
+{
+    __thread static mach_msg_header_t send_header;
+
+    send_header.msgh_bits = msgh_bits_send;
+    send_header.msgh_id = obj->shm_idx;
+    send_header.msgh_size = sizeof(send_header);
+    send_header.msgh_remote_port = server_port;
+    
+    mach_msg_overwrite_trap( &send_header, MACH_SEND_MSG, send_header.msgh_size, 0,
+              MACH_PORT_NULL, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL, NULL, 0 );
+}
+
+NTSTATUS msync_release_semaphore( HANDLE handle, ULONG count, ULONG *prev )
+{
+    struct msync *obj;
+    struct semaphore *semaphore;
+    ULONG current;
+    NTSTATUS ret;
+
+    TRACE("%p, %d, %p.\n", handle, count, prev);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    semaphore = obj->shm;
+
+    do
+    {
+        current = semaphore->count;
+        if (count + current > semaphore->max)
+            return STATUS_SEMAPHORE_LIMIT_EXCEEDED;
+    } while (__sync_val_compare_and_swap( &semaphore->count, current, count + current ) != current);
+
+    if (prev) *prev = current;
+
+    signal_all( obj );
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct msync *obj;
+    struct semaphore *semaphore;
+    SEMAPHORE_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    semaphore = obj->shm;
+
+    out->CurrentCount = semaphore->count;
+    out->MaximumCount = semaphore->max;
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE event_type, BOOLEAN initial )
+{
+    enum msync_type type = (event_type == SynchronizationEvent ? MSYNC_AUTO_EVENT : MSYNC_MANUAL_EVENT);
+
+    TRACE("name %s, %s-reset, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>",
+        event_type == NotificationEvent ? "manual" : "auto", initial);
+
+    return create_msync( type, handle, access, attr, initial, 0xdeadbeef );
+}
+
+NTSTATUS msync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_msync( MSYNC_AUTO_EVENT, handle, access, attr );
+}
+
+NTSTATUS msync_set_event( HANDLE handle, LONG *prev )
+{
+    struct event *event;
+    struct msync *obj;
+    LONG current;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    if (obj->type != MSYNC_MANUAL_EVENT && obj->type != MSYNC_AUTO_EVENT)
+        return STATUS_OBJECT_TYPE_MISMATCH;
+
+    if (!(current = __atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST )))
+        signal_all( obj );
+
+    if (prev) *prev = current;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_reset_event( HANDLE handle, LONG *prev )
+{
+    struct event *event;
+    struct msync *obj;
+    LONG current;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    current = __atomic_exchange_n( &event->signaled, 0, __ATOMIC_SEQ_CST );
+
+    if (prev) *prev = current;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_pulse_event( HANDLE handle, LONG *prev )
+{
+    struct event *event;
+    struct msync *obj;
+    LONG current;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    /* This isn't really correct; an application could miss the write.
+     * Unfortunately we can't really do much better. Fortunately this is rarely
+     * used (and publicly deprecated). */
+    if (!(current = __atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST )))
+        signal_all( obj );
+
+    /* Try to give other threads a chance to wake up. Hopefully erring on this
+     * side is the better thing to do... */
+    sched_yield();
+
+    __atomic_store_n( &event->signaled, 0, __ATOMIC_SEQ_CST );
+
+    if (prev) *prev = current;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_query_event( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct event *event;
+    struct msync *obj;
+    EVENT_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    out->EventState = event->signaled;
+    out->EventType = (obj->type == MSYNC_AUTO_EVENT ? SynchronizationEvent : NotificationEvent);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial )
+{
+    TRACE("name %s, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial);
+
+    return create_msync( MSYNC_MUTEX, handle, access, attr,
+        initial ? GetCurrentThreadId() : 0, initial ? 1 : 0 );
+}
+
+NTSTATUS msync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_msync( MSYNC_MUTEX, handle, access, attr );
+}
+
+NTSTATUS msync_release_mutex( HANDLE handle, LONG *prev )
+{
+    struct mutex *mutex;
+    struct msync *obj;
+    NTSTATUS ret;
+
+    TRACE("%p, %p.\n", handle, prev);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    if (mutex->tid != GetCurrentThreadId()) return STATUS_MUTANT_NOT_OWNED;
+
+    if (prev) *prev = mutex->count;
+
+    if (!--mutex->count)
+    {
+        __atomic_store_n( &mutex->tid, 0, __ATOMIC_SEQ_CST );
+        signal_all( obj );
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS msync_query_mutex( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct msync *obj;
+    struct mutex *mutex;
+    MUTANT_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    out->CurrentCount = 1 - mutex->count;
+    out->OwnedByCaller = (mutex->tid == GetCurrentThreadId());
+    out->AbandonedState = (mutex->tid == ~0);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+static NTSTATUS do_single_wait( struct msync *obj, ULONGLONG *end, BOOLEAN alertable )
+{
+    NTSTATUS status;
+    struct msync *wait_objs[2];
+    
+    wait_objs[0] = obj;
+    
+    if (alertable)
+    {
+        struct msync apc_obj;
+        int *apc_addr = ntdll_get_thread_data()->msync_apc_addr;
+
+        apc_obj.type = MSYNC_AUTO_EVENT;
+        apc_obj.shm = (void *)apc_addr;
+        apc_obj.shm_idx = ntdll_get_thread_data()->msync_apc_idx;
+
+        if (__atomic_load_n( apc_addr, __ATOMIC_SEQ_CST ))
+            return STATUS_USER_APC;
+
+        wait_objs[1] = &apc_obj;
+
+        status = msync_wait_multiple( wait_objs, 2, end );
+        
+        if (__atomic_load_n( apc_addr, __ATOMIC_SEQ_CST ))
+            return STATUS_USER_APC;
+    }
+    else
+    {
+        status = msync_wait_multiple( wait_objs, 1, end );
+    }
+    return status;
+}
+
+static NTSTATUS __msync_wait_objects( DWORD count, const HANDLE *handles,
+    BOOLEAN wait_any, BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    static const LARGE_INTEGER zero = {0};
+    
+    struct msync *objs[MAXIMUM_WAIT_OBJECTS + 1];
+    struct msync apc_obj;
+    int has_msync = 0, has_server = 0;
+    BOOL msgwait = FALSE;
+    LONGLONG timeleft;
+    LARGE_INTEGER now;
+    DWORD waitcount;
+    ULONGLONG end;
+    int i, ret;
+
+    /* Grab the APC idx if we don't already have it. */
+    if (alertable && !ntdll_get_thread_data()->msync_apc_addr)
+    {
+        unsigned int idx = 0;
+        SERVER_START_REQ( get_msync_apc_idx )
+        {
+            if (!(ret = wine_server_call( req )))
+                idx = reply->shm_idx;
+        }
+        SERVER_END_REQ;
+
+        if (idx)
+        {
+            struct event *apc_event = get_shm( idx );
+            ntdll_get_thread_data()->msync_apc_addr = &apc_event->signaled;
+            ntdll_get_thread_data()->msync_apc_idx = idx;
+        }
+    }
+
+    NtQuerySystemTime( &now );
+    if (timeout)
+    {
+        if (timeout->QuadPart == TIMEOUT_INFINITE)
+            timeout = NULL;
+        else if (timeout->QuadPart > 0)
+            end = timeout->QuadPart;
+        else
+            end = now.QuadPart - timeout->QuadPart;
+    }
+
+    for (i = 0; i < count; i++)
+    {
+        ret = get_object( handles[i], &objs[i] );
+        if (ret == STATUS_SUCCESS)
+            has_msync = 1;
+        else if (ret == STATUS_NOT_IMPLEMENTED)
+            has_server = 1;
+        else
+            return ret;
+    }
+
+    if (count && objs[count - 1] && objs[count - 1]->type == MSYNC_QUEUE)
+        msgwait = TRUE;
+
+    if (has_msync && has_server)
+        FIXME("Can't wait on msync and server objects at the same time!\n");
+    else if (has_server)
+        return STATUS_NOT_IMPLEMENTED;
+
+    if (TRACE_ON(msync))
+    {
+        TRACE("Waiting for %s of %d handles:", wait_any ? "any" : "all", count);
+        for (i = 0; i < count; i++)
+            TRACE(" %p", handles[i]);
+
+        if (msgwait)
+            TRACE(" or driver events");
+        if (alertable)
+            TRACE(", alertable");
+
+        if (!timeout)
+            TRACE(", timeout = INFINITE.\n");
+        else
+        {
+            timeleft = update_timeout( end );
+            TRACE(", timeout = %ld.%07ld sec.\n",
+                (long) (timeleft / TICKSPERSEC), (long) (timeleft % TICKSPERSEC));
+        }
+    }
+
+    if (wait_any || count <= 1)
+    {
+        while (1)
+        {
+            /* Try to grab anything. */
+
+            if (alertable)
+            {
+                apc_obj.type = MSYNC_AUTO_EVENT;
+                /* We must check this first! The server may set an event that
+                 * we're waiting on, but we need to return STATUS_USER_APC. */
+                if (__atomic_load_n( ntdll_get_thread_data()->msync_apc_addr, __ATOMIC_SEQ_CST ))
+                    goto userapc;
+            }
+
+            for (i = 0; i < count; i++)
+            {
+                struct msync *obj = objs[i];
+
+                if (obj)
+                {
+                    if (!obj->type) /* gcc complains if we put this in the switch */
+                    {
+                        /* Someone probably closed an object while waiting on it. */
+                        WARN("Handle %p has type 0; was it closed?\n", handles[i]);
+                        return STATUS_INVALID_HANDLE;
+                    }
+
+                    switch (obj->type)
+                    {
+                    case MSYNC_SEMAPHORE:
+                    {
+                        struct semaphore *semaphore = obj->shm;
+                        int current;
+
+                        current = __atomic_load_n(&semaphore->count, __ATOMIC_ACQUIRE);
+                        if (current && __atomic_compare_exchange_n(&semaphore->count, &current, current - 1, 0, __ATOMIC_RELEASE, __ATOMIC_RELAXED))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            return i;
+                        }
+                        break;
+                    }
+                    case MSYNC_MUTEX:
+                    {
+                        struct mutex *mutex = obj->shm;
+                        int tid;
+
+                        if (mutex->tid == GetCurrentThreadId())
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            mutex->count++;
+                            return i;
+                        }
+
+                        tid = 0;
+                        if (__atomic_compare_exchange_n(&mutex->tid, &tid, GetCurrentThreadId(), 0, __ATOMIC_ACQ_REL, __ATOMIC_RELAXED))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            mutex->count = 1;
+                            return i;
+                        }
+                        else if (tid == ~0 && __atomic_compare_exchange_n(&mutex->tid, &tid, GetCurrentThreadId(), 0, __ATOMIC_ACQ_REL, __ATOMIC_RELAXED))
+                        {
+                            TRACE("Woken up by abandoned mutex %p [%d].\n", handles[i], i);
+                            mutex->count = 1;
+                            return STATUS_ABANDONED_WAIT_0 + i;
+                        }
+
+                        break;
+                    }
+                    case MSYNC_AUTO_EVENT:
+                    case MSYNC_AUTO_SERVER:
+                    {
+                        struct event *event = obj->shm;
+                        int signaled = 1;
+
+                        if (__atomic_compare_exchange_n(&event->signaled, &signaled, 0, 0, __ATOMIC_ACQ_REL, __ATOMIC_RELAXED))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            return i;
+                        }
+
+                        break;
+                    }
+                    case MSYNC_MANUAL_EVENT:
+                    case MSYNC_MANUAL_SERVER:
+                    case MSYNC_QUEUE:
+                    {
+                        struct event *event = obj->shm;
+
+                        if (__atomic_load_n(&event->signaled, __ATOMIC_ACQUIRE))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            return i;
+                        }
+                        break;
+                    }
+                    default:
+                        ERR("Invalid type %#x for handle %p.\n", obj->type, handles[i]);
+                        assert(0);
+                    }
+                }
+            }
+
+            if (alertable)
+            {
+                /* We already checked if it was signaled; don't bother doing it again. */
+                apc_obj.shm = (void *)ntdll_get_thread_data()->msync_apc_addr;
+                apc_obj.shm_idx = ntdll_get_thread_data()->msync_apc_idx;
+                objs[i] = &apc_obj;
+                i++;
+            }
+            waitcount = i;
+
+            /* Looks like everything is contended, so wait. */
+
+            if (timeout && !timeout->QuadPart)
+            {
+                /* Unlike esync, we already know that we've timed out, so we
+                 * can avoid a syscall. */
+                TRACE("Wait timed out.\n");
+                return STATUS_TIMEOUT;
+            }
+            
+            ret = msync_wait_multiple( objs, waitcount, timeout ? &end : NULL );
+
+            if (ret == STATUS_TIMEOUT)
+            {
+                TRACE("Wait timed out.\n");
+                return STATUS_TIMEOUT;
+            }
+        } /* while (1) */
+    }
+    else
+    {
+        /* Wait-all is a little trickier to implement correctly. Fortunately,
+         * it's not as common.
+         *
+         * The idea is basically just to wait in sequence on every object in the
+         * set. Then when we're done, try to grab them all in a tight loop. If
+         * that fails, release any resources we've grabbed (and yes, we can
+         * reliably do thisit's just mutexes and semaphores that we have to
+         * put back, and in both cases we just put back 1), and if any of that
+         * fails we start over.
+         *
+         * What makes this inherently bad is that we might temporarily grab a
+         * resource incorrectly. Hopefully it'll be quick (and hey, it won't
+         * block on wineserver) so nobody will notice. Besides, consider: if
+         * object A becomes signaled but someone grabs it before we can grab it
+         * and everything else, then they could just as well have grabbed it
+         * before it became signaled. Similarly if object A was signaled and we
+         * were blocking on object B, then B becomes available and someone grabs
+         * A before we can, then they might have grabbed A before B became
+         * signaled. In either case anyone who tries to wait on A or B will be
+         * waiting for an instant while we put things back. */
+
+        NTSTATUS status = STATUS_SUCCESS;
+
+        while (1)
+        {
+            BOOL abandoned;
+
+tryagain:
+            abandoned = FALSE;
+
+            /* First step: try to wait on each object in sequence. */
+
+            for (i = 0; i < count; i++)
+            {
+                struct msync *obj = objs[i];
+
+                if (obj && obj->type == MSYNC_MUTEX)
+                {
+                    struct mutex *mutex = obj->shm;
+
+                    if (mutex->tid == GetCurrentThreadId())
+                        continue;
+
+                    while (__atomic_load_n( &mutex->tid, __ATOMIC_SEQ_CST ))
+                    {
+                        status = do_single_wait( obj, timeout ? &end : NULL, alertable );
+                        if (status != STATUS_PENDING)
+                            break;
+                    }
+                }
+                else if (obj)
+                {
+                    /* this works for semaphores too */
+                    struct event *event = obj->shm;
+
+                    while (!__atomic_load_n( &event->signaled, __ATOMIC_SEQ_CST ))
+                    {
+                        status = do_single_wait( obj, timeout ? &end : NULL, alertable );
+                        if (status != STATUS_PENDING)
+                            break;
+                    }
+                }
+
+                if (status == STATUS_TIMEOUT)
+                {
+                    TRACE("Wait timed out.\n");
+                    return STATUS_TIMEOUT;
+                }
+                else if (status == STATUS_USER_APC)
+                    goto userapc;
+            }
+
+            /* If we got here and we haven't timed out, that means all of the
+             * handles were signaled. Check to make sure they still are. */
+            for (i = 0; i < count; i++)
+            {
+                struct msync *obj = objs[i];
+
+                if (obj && obj->type == MSYNC_MUTEX)
+                {
+                    struct mutex *mutex = obj->shm;
+                    int tid = __atomic_load_n( &mutex->tid, __ATOMIC_SEQ_CST );
+
+                    if (tid && tid != ~0 && tid != GetCurrentThreadId())
+                        goto tryagain;
+                }
+                else if (obj)
+                {
+                    struct event *event = obj->shm;
+
+                    if (!__atomic_load_n( &event->signaled, __ATOMIC_SEQ_CST ))
+                        goto tryagain;
+                }
+            }
+
+            /* Yep, still signaled. Now quick, grab everything. */
+            for (i = 0; i < count; i++)
+            {
+                struct msync *obj = objs[i];
+                if (!obj) continue;
+                switch (obj->type)
+                {
+                case MSYNC_MUTEX:
+                {
+                    struct mutex *mutex = obj->shm;
+                    int tid = __atomic_load_n( &mutex->tid, __ATOMIC_SEQ_CST );
+                    if (tid == GetCurrentThreadId())
+                        break;
+                    if (tid && tid != ~0)
+                        goto tooslow;
+                    if (__sync_val_compare_and_swap( &mutex->tid, tid, GetCurrentThreadId() ) != tid)
+                        goto tooslow;
+                    if (tid == ~0)
+                        abandoned = TRUE;
+                    break;
+                }
+                case MSYNC_SEMAPHORE:
+                {
+                    struct semaphore *semaphore = obj->shm;
+                    int current;
+
+                    if (!(current = __atomic_load_n( &semaphore->count, __ATOMIC_SEQ_CST ))
+                            || __sync_val_compare_and_swap( &semaphore->count, current, current - 1 ) != current)
+                        goto tooslow;
+                    break;
+                }
+                case MSYNC_AUTO_EVENT:
+                case MSYNC_AUTO_SERVER:
+                {
+                    struct event *event = obj->shm;
+                    if (!__sync_val_compare_and_swap( &event->signaled, 1, 0 ))
+                        goto tooslow;
+                    break;
+                }
+                default:
+                    /* If a manual-reset event changed between there and
+                     * here, it's shouldn't be a problem. */
+                    break;
+                }
+            }
+
+            /* If we got here, we successfully waited on every object.
+             * Make sure to let ourselves know that we grabbed the mutexes. */
+            for (i = 0; i < count; i++)
+            {
+                if (objs[i] && objs[i]->type == MSYNC_MUTEX)
+                {
+                    struct mutex *mutex = objs[i]->shm;
+                    mutex->count++;
+                }
+            }
+
+            if (abandoned)
+            {
+                TRACE("Wait successful, but some object(s) were abandoned.\n");
+                return STATUS_ABANDONED;
+            }
+            TRACE("Wait successful.\n");
+            return STATUS_SUCCESS;
+
+tooslow:
+            for (--i; i >= 0; i--)
+            {
+                struct msync *obj = objs[i];
+                if (!obj) continue;
+                switch (obj->type)
+                {
+                case MSYNC_MUTEX:
+                {
+                    struct mutex *mutex = obj->shm;
+                    /* HACK: This won't do the right thing with abandoned
+                     * mutexes, but fixing it is probably more trouble than
+                     * it's worth. */
+                    __atomic_store_n( &mutex->tid, 0, __ATOMIC_SEQ_CST );
+                    break;
+                }
+                case MSYNC_SEMAPHORE:
+                {
+                    struct semaphore *semaphore = obj->shm;
+                    __sync_fetch_and_add( &semaphore->count, 1 );
+                    break;
+                }
+                case MSYNC_AUTO_EVENT:
+                case MSYNC_AUTO_SERVER:
+                {
+                    struct event *event = obj->shm;
+                    __atomic_store_n( &event->signaled, 1, __ATOMIC_SEQ_CST );
+                    break;
+                }
+                default:
+                    /* doesn't need to be put back */
+                    break;
+                }
+            }
+        } /* while (1) */
+    } /* else (wait-all) */
+
+    assert(0);  /* shouldn't reach here... */
+
+userapc:
+    TRACE("Woken up by user APC.\n");
+
+    /* We have to make a server call anyway to get the APC to execute, so just
+     * delegate down to server_wait(). */
+    ret = server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, &zero );
+
+    /* This can happen if we received a system APC, and the APC fd was woken up
+     * before we got SIGUSR1. poll() doesn't return EINTR in that case. The
+     * right thing to do seems to be to return STATUS_USER_APC anyway. */
+    if (ret == STATUS_TIMEOUT) ret = STATUS_USER_APC;
+    return ret;
+}
+
+/* Like esync, we need to let the server know when we are doing a message wait,
+ * and when we are done with one, so that all of the code surrounding hung
+ * queues works, and we also need this for WaitForInputIdle().
+ *
+ * Unlike esync, we can't wait on the queue fd itself locally. Instead we let
+ * the server do that for us, the way it normally does. This could actually
+ * work for esync too, and that might be better. */
+static void server_set_msgwait( int in_msgwait )
+{
+    SERVER_START_REQ( msync_msgwait )
+    {
+        req->in_msgwait = in_msgwait;
+        wine_server_call( req );
+    }
+    SERVER_END_REQ;
+}
+
+/* This is a very thin wrapper around the proper implementation above. The
+ * purpose is to make sure the server knows when we are doing a message wait.
+ * This is separated into a wrapper function since there are at least a dozen
+ * exit paths from msync_wait_objects(). */
+NTSTATUS msync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    BOOL msgwait = FALSE;
+    struct msync *obj;
+    NTSTATUS ret;
+
+    if (count && !get_object( handles[count - 1], &obj ) && obj->type == MSYNC_QUEUE)
+    {
+        msgwait = TRUE;
+        server_set_msgwait( 1 );
+    }
+
+    ret = __msync_wait_objects( count, handles, wait_any, alertable, timeout );
+
+    if (msgwait)
+        server_set_msgwait( 0 );
+
+    return ret;
+}
+
+NTSTATUS msync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
+    const LARGE_INTEGER *timeout )
+{
+    struct msync *obj;
+    NTSTATUS ret;
+
+    if ((ret = get_object( signal, &obj ))) return ret;
+
+    switch (obj->type)
+    {
+    case MSYNC_SEMAPHORE:
+        ret = msync_release_semaphore( signal, 1, NULL );
+        break;
+    case MSYNC_AUTO_EVENT:
+    case MSYNC_MANUAL_EVENT:
+        ret = msync_set_event( signal, NULL );
+        break;
+    case MSYNC_MUTEX:
+        ret = msync_release_mutex( signal, NULL );
+        break;
+    default:
+        return STATUS_OBJECT_TYPE_MISMATCH;
+    }
+    if (ret) return ret;
+
diff --git a/wine/dlls/ntdll/unix/msync.h b/wine/dlls/ntdll/unix/msync.h
new file mode 100644
index 000000000..9d0538297
--- /dev/null
+++ b/wine/dlls/ntdll/unix/msync.h
@@ -0,0 +1,50 @@
+/*
+ * mach semaphore-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ * Copyright (C) 2023 Marc-Aurel Zent
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+extern int do_msync(void) DECLSPEC_HIDDEN;
+extern void msync_init(void) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_close( HANDLE handle ) DECLSPEC_HIDDEN;
+
+extern NTSTATUS msync_create_semaphore(HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, LONG initial, LONG max) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_release_semaphore( HANDLE handle, ULONG count, ULONG *prev ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE type, BOOLEAN initial ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_set_event( HANDLE handle, LONG *prev ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_reset_event( HANDLE handle, LONG *prev ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_pulse_event( HANDLE handle, LONG *prev ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_query_event( HANDLE handle, void *info, ULONG *ret_len ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_release_mutex( HANDLE handle, LONG *prev ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_query_mutex( HANDLE handle, void *info, ULONG *ret_len ) DECLSPEC_HIDDEN;
+
+extern NTSTATUS msync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                                    BOOLEAN alertable, const LARGE_INTEGER *timeout ) DECLSPEC_HIDDEN;
+extern NTSTATUS msync_signal_and_wait( HANDLE signal, HANDLE wait,
+    BOOLEAN alertable, const LARGE_INTEGER *timeout ) DECLSPEC_HIDDEN;
diff --git a/wine/dlls/ntdll/unix/server.c b/wine/dlls/ntdll/unix/server.c
index 0cbc7848f..6fd22b34d 100644
--- a/wine/dlls/ntdll/unix/server.c
+++ b/wine/dlls/ntdll/unix/server.c
@@ -80,6 +80,7 @@
 #include "wine/debug.h"
 #include "unix_private.h"
 #include "esync.h"
+#include "msync.h"
 #include "ddk/wdm.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(server);
@@ -1796,6 +1797,9 @@ NTSTATUS WINAPI NtClose( HANDLE handle )
      * retrieve it again */
     fd = remove_fd_from_cache( handle );
 
+    if (do_msync())
+        msync_close( handle );
+    
     if (do_esync())
         esync_close( handle );
 
diff --git a/wine/dlls/ntdll/unix/sync.c b/wine/dlls/ntdll/unix/sync.c
index f3867abc8..f3918e7d5 100644
--- a/wine/dlls/ntdll/unix/sync.c
+++ b/wine/dlls/ntdll/unix/sync.c
@@ -65,6 +65,7 @@
 #include "wine/debug.h"
 #include "unix_private.h"
 #include "esync.h"
+#include "msync.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(sync);
 
@@ -119,7 +120,6 @@ static inline int futex_wait( const int *addr, int val, struct timespec *timeout
             long tv_sec;
             long tv_nsec;
         } timeout32 = { timeout->tv_sec, timeout->tv_nsec };
-
         return syscall( __NR_futex, addr, FUTEX_WAIT | futex_private, val, &timeout32, 0, 0 );
     }
 #endif
@@ -274,6 +274,9 @@ NTSTATUS WINAPI NtCreateSemaphore( HANDLE *handle, ACCESS_MASK access, const OBJ
     if (max <= 0 || initial < 0 || initial > max) return STATUS_INVALID_PARAMETER;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
+    if (do_msync())
+        return msync_create_semaphore( handle, access, attr, initial, max );
+
     if (do_esync())
         return esync_create_semaphore( handle, access, attr, initial, max );
 
@@ -301,6 +304,9 @@ NTSTATUS WINAPI NtOpenSemaphore( HANDLE *handle, ACCESS_MASK access, const OBJEC
     NTSTATUS ret;
 
     *handle = 0;
+    
+    if (do_msync())
+        return msync_open_semaphore( handle, access, attr );
 
     if (do_esync())
         return esync_open_semaphore( handle, access, attr );
@@ -341,6 +347,9 @@ NTSTATUS WINAPI NtQuerySemaphore( HANDLE handle, SEMAPHORE_INFORMATION_CLASS cla
 
     if (len != sizeof(SEMAPHORE_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
+    if (do_msync())
+        return msync_query_semaphore( handle, info, ret_len );
+
     if (do_esync())
         return esync_query_semaphore( handle, info, ret_len );
 
@@ -366,6 +375,9 @@ NTSTATUS WINAPI NtReleaseSemaphore( HANDLE handle, ULONG count, ULONG *previous
 {
     NTSTATUS ret;
 
+    if (do_msync())
+        return msync_release_semaphore( handle, count, previous );
+
     if (do_esync())
         return esync_release_semaphore( handle, count, previous );
 
@@ -395,6 +407,9 @@ NTSTATUS WINAPI NtCreateEvent( HANDLE *handle, ACCESS_MASK access, const OBJECT_
 
     *handle = 0;
     if (type != NotificationEvent && type != SynchronizationEvent) return STATUS_INVALID_PARAMETER;
+    
+    if (do_msync())
+        return msync_create_event( handle, access, attr, type, state );
 
     if (do_esync())
         return esync_create_event( handle, access, attr, type, state );
@@ -427,6 +442,9 @@ NTSTATUS WINAPI NtOpenEvent( HANDLE *handle, ACCESS_MASK access, const OBJECT_AT
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_msync())
+        return msync_open_event( handle, access, attr );
+    
     if (do_esync())
         return esync_open_event( handle, access, attr );
 
@@ -453,6 +471,9 @@ NTSTATUS WINAPI NtSetEvent( HANDLE handle, LONG *prev_state )
     /* This comment is a dummy to make sure this patch applies in the right place. */
     NTSTATUS ret;
 
+    if (do_msync())
+        return msync_set_event( handle, prev_state );
+    
     if (do_esync())
         return esync_set_event( handle );
 
@@ -475,6 +496,9 @@ NTSTATUS WINAPI NtResetEvent( HANDLE handle, LONG *prev_state )
 {
     /* This comment is a dummy to make sure this patch applies in the right place. */
     NTSTATUS ret;
+    
+    if (do_msync())
+        return msync_reset_event( handle, prev_state );
 
     if (do_esync())
         return esync_reset_event( handle );
@@ -508,6 +532,9 @@ NTSTATUS WINAPI NtPulseEvent( HANDLE handle, LONG *prev_state )
 {
     NTSTATUS ret;
 
+    if (do_msync())
+        return msync_pulse_event( handle, prev_state );
+
     if (do_esync())
         return esync_pulse_event( handle );
 
@@ -543,6 +570,9 @@ NTSTATUS WINAPI NtQueryEvent( HANDLE handle, EVENT_INFORMATION_CLASS class,
 
     if (len != sizeof(EVENT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
+    if (do_msync())
+        return msync_query_event( handle, info, ret_len );
+
     if (do_esync())
         return esync_query_event( handle, info, ret_len );
 
@@ -572,7 +602,10 @@ NTSTATUS WINAPI NtCreateMutant( HANDLE *handle, ACCESS_MASK access, const OBJECT
     struct object_attributes *objattr;
 
     *handle = 0;
-
+    
+    if (do_msync())
+        return msync_create_mutex( handle, access, attr, owned );
+    
     if (do_esync())
         return esync_create_mutex( handle, access, attr, owned );
 
@@ -603,6 +636,9 @@ NTSTATUS WINAPI NtOpenMutant( HANDLE *handle, ACCESS_MASK access, const OBJECT_A
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_msync())
+        return msync_open_mutex( handle, access, attr );
+    
     if (do_esync())
         return esync_open_mutex( handle, access, attr );
 
@@ -628,6 +664,9 @@ NTSTATUS WINAPI NtReleaseMutant( HANDLE handle, LONG *prev_count )
 {
     NTSTATUS ret;
 
+    if (do_msync())
+        return msync_release_mutex( handle, prev_count );
+
     if (do_esync())
         return esync_release_mutex( handle, prev_count );
 
@@ -661,6 +700,9 @@ NTSTATUS WINAPI NtQueryMutant( HANDLE handle, MUTANT_INFORMATION_CLASS class,
 
     if (len != sizeof(MUTANT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
+    if (do_msync())
+        return msync_query_mutex( handle, info, ret_len );
+
     if (do_esync())
         return esync_query_mutex( handle, info, ret_len );
 
@@ -1470,6 +1512,13 @@ NTSTATUS WINAPI NtWaitForMultipleObjects( DWORD count, const HANDLE *handles, BO
 
     if (!count || count > MAXIMUM_WAIT_OBJECTS) return STATUS_INVALID_PARAMETER_1;
 
+    if (do_msync())
+    {
+        NTSTATUS ret = msync_wait_objects( count, handles, wait_any, alertable, timeout );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+            return ret;
+    }
+
     if (do_esync())
     {
         NTSTATUS ret = esync_wait_objects( count, handles, wait_any, alertable, timeout );
@@ -1502,6 +1551,9 @@ NTSTATUS WINAPI NtSignalAndWaitForSingleObject( HANDLE signal, HANDLE wait,
     select_op_t select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
 
+    if (do_msync())
+        return msync_signal_and_wait( signal, wait, alertable, timeout );
+
     if (do_esync())
         return esync_signal_and_wait( signal, wait, alertable, timeout );
 
@@ -1535,7 +1587,24 @@ NTSTATUS WINAPI NtYieldExecution(void)
 NTSTATUS WINAPI NtDelayExecution( BOOLEAN alertable, const LARGE_INTEGER *timeout )
 {
     /* if alertable, we need to query the server */
-    if (alertable) return server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, timeout );
+    if (alertable)
+    {
+        if (do_msync())
+        {
+            NTSTATUS ret = msync_wait_objects( 0, NULL, TRUE, TRUE, timeout );
+            if (ret != STATUS_NOT_IMPLEMENTED)
+                return ret;
+        }
+
+        if (do_esync())
+        {
+            NTSTATUS ret = esync_wait_objects( 0, NULL, TRUE, TRUE, timeout );
+            if (ret != STATUS_NOT_IMPLEMENTED)
+                return ret;
+        }
+
+        return server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, timeout );
+    }
 
     if (!timeout || timeout->QuadPart == TIMEOUT_INFINITE)  /* sleep forever */
     {
diff --git a/wine/dlls/ntdll/unix/unix_private.h b/wine/dlls/ntdll/unix/unix_private.h
index 37018fb82..f5f410ae8 100644
--- a/wine/dlls/ntdll/unix/unix_private.h
+++ b/wine/dlls/ntdll/unix/unix_private.h
@@ -64,6 +64,8 @@ struct ntdll_thread_data
     void              *cpu_data[16];  /* reserved for CPU-specific data */
     void              *kernel_stack;  /* stack for thread startup and kernel syscalls */
     int                esync_apc_fd;  /* fd to wait on for user APCs */
+    int               *msync_apc_addr;
+    unsigned int       msync_apc_idx;
     int                request_fd;    /* fd for sending server requests */
     int                reply_fd;      /* fd for receiving server replies */
     int                wait_fd[2];    /* fd for sleeping server requests */
diff --git a/wine/dlls/ntdll/unix/virtual.c b/wine/dlls/ntdll/unix/virtual.c
index 19486a26a..8ead2cc99 100644
--- a/wine/dlls/ntdll/unix/virtual.c
+++ b/wine/dlls/ntdll/unix/virtual.c
@@ -3002,6 +3002,8 @@ static TEB *init_teb( void *ptr, BOOL is_wow )
     teb->StaticUnicodeString.MaximumLength = sizeof(teb->StaticUnicodeBuffer);
     thread_data = (struct ntdll_thread_data *)&teb->GdiTebBatch;
     thread_data->esync_apc_fd = -1;
+    thread_data->msync_apc_addr = NULL;
+    thread_data->msync_apc_idx = 0;
     thread_data->request_fd = -1;
     thread_data->reply_fd   = -1;
     thread_data->wait_fd[0] = -1;
diff --git a/wine/dlls/ntdll/unix/virtual.c.orig b/wine/dlls/ntdll/unix/virtual.c.orig
new file mode 100644
index 000000000..19486a26a
--- /dev/null
+++ b/wine/dlls/ntdll/unix/virtual.c.orig
@@ -0,0 +1,5271 @@
+/*
+ * Win32 virtual memory functions
+ *
+ * Copyright 1997, 2002, 2020 Alexandre Julliard
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#if 0
+#pragma makedep unix
+#endif
+
+#include "config.h"
+
+#include <assert.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <stdarg.h>
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <signal.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#ifdef HAVE_SYS_SYSINFO_H
+# include <sys/sysinfo.h>
+#endif
+#ifdef HAVE_SYS_SYSCTL_H
+# include <sys/sysctl.h>
+#endif
+#ifdef HAVE_SYS_PARAM_H
+# include <sys/param.h>
+#endif
+#ifdef HAVE_SYS_QUEUE_H
+# include <sys/queue.h>
+#endif
+#ifdef HAVE_SYS_USER_H
+# include <sys/user.h>
+#endif
+#ifdef HAVE_LIBPROCSTAT_H
+# include <libprocstat.h>
+#endif
+#include <unistd.h>
+#include <dlfcn.h>
+#ifdef HAVE_VALGRIND_VALGRIND_H
+# include <valgrind/valgrind.h>
+#endif
+#if defined(__APPLE__)
+# include <mach/mach_init.h>
+# include <mach/mach_vm.h>
+# include <mach-o/dyld.h> /* CrossOver Hack #16371 */
+#endif
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winnt.h"
+#include "winternl.h"
+#include "wine/list.h"
+#include "wine/rbtree.h"
+#include "unix_private.h"
+#include "wine/debug.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(virtual);
+WINE_DECLARE_DEBUG_CHANNEL(module);
+
+struct preload_info
+{
+    void  *addr;
+    size_t size;
+};
+
+struct reserved_area
+{
+    struct list entry;
+    void       *base;
+    size_t      size;
+};
+
+static struct list reserved_areas = LIST_INIT(reserved_areas);
+
+struct builtin_module
+{
+    struct list  entry;
+    unsigned int refcount;
+    void        *handle;
+    void        *module;
+    void        *unix_handle;
+};
+
+static struct list builtin_modules = LIST_INIT( builtin_modules );
+
+struct file_view
+{
+    struct wine_rb_entry entry;  /* entry in global view tree */
+    void         *base;          /* base address */
+    size_t        size;          /* size in bytes */
+    unsigned int  protect;       /* protection for all pages at allocation time and SEC_* flags */
+};
+
+/* per-page protection flags */
+#define VPROT_READ       0x01
+#define VPROT_WRITE      0x02
+#define VPROT_EXEC       0x04
+#define VPROT_WRITECOPY  0x08
+#define VPROT_GUARD      0x10
+#define VPROT_COMMITTED  0x20
+#define VPROT_WRITEWATCH 0x40
+/* per-mapping protection flags */
+#define VPROT_SYSTEM     0x0200  /* system view (underlying mmap not under our control) */
+
+/* Conversion from VPROT_* to Win32 flags */
+static const BYTE VIRTUAL_Win32Flags[16] =
+{
+    PAGE_NOACCESS,              /* 0 */
+    PAGE_READONLY,              /* READ */
+    PAGE_READWRITE,             /* WRITE */
+    PAGE_READWRITE,             /* READ | WRITE */
+    PAGE_EXECUTE,               /* EXEC */
+    PAGE_EXECUTE_READ,          /* READ | EXEC */
+    PAGE_EXECUTE_READWRITE,     /* WRITE | EXEC */
+    PAGE_EXECUTE_READWRITE,     /* READ | WRITE | EXEC */
+    PAGE_WRITECOPY,             /* WRITECOPY */
+    PAGE_WRITECOPY,             /* READ | WRITECOPY */
+    PAGE_WRITECOPY,             /* WRITE | WRITECOPY */
+    PAGE_WRITECOPY,             /* READ | WRITE | WRITECOPY */
+    PAGE_EXECUTE_WRITECOPY,     /* EXEC | WRITECOPY */
+    PAGE_EXECUTE_WRITECOPY,     /* READ | EXEC | WRITECOPY */
+    PAGE_EXECUTE_WRITECOPY,     /* WRITE | EXEC | WRITECOPY */
+    PAGE_EXECUTE_WRITECOPY      /* READ | WRITE | EXEC | WRITECOPY */
+};
+
+static struct wine_rb_tree views_tree;
+static pthread_mutex_t virtual_mutex;
+
+static const UINT page_shift = 12;
+static const UINT_PTR page_mask = 0xfff;
+static const UINT_PTR granularity_mask = 0xffff;
+
+/* Note: these are Windows limits, you cannot change them. */
+#ifdef __i386__
+static void *address_space_start = (void *)0x110000; /* keep DOS area clear */
+#else
+static void *address_space_start = (void *)0x10000;
+#endif
+
+#ifdef __aarch64__
+static void *address_space_limit = (void *)0xffffffff0000;  /* top of the total available address space */
+#elif defined(_WIN64)
+static void *address_space_limit = (void *)0x7fffffff0000;
+#else
+static void *address_space_limit = (void *)0xc0000000;
+#endif
+
+#ifdef _WIN64
+static void *user_space_limit    = (void *)0x7fffffff0000;  /* top of the user address space */
+static void *working_set_limit   = (void *)0x7fffffff0000;  /* top of the current working set */
+#else
+static void *user_space_limit    = (void *)0x7fff0000;
+static void *working_set_limit   = (void *)0x7fff0000;
+#endif
+
+/* CW HACK 17634 */
+static BOOL large_address_space_active = FALSE;
+
+struct _KUSER_SHARED_DATA *user_shared_data = (void *)0x7ffe0000;
+
+/* TEB allocation blocks */
+static void *teb_block;
+static void **next_free_teb;
+static int teb_block_pos;
+static struct list teb_list = LIST_INIT( teb_list );
+
+#define ROUND_ADDR(addr,mask) ((void *)((UINT_PTR)(addr) & ~(UINT_PTR)(mask)))
+#define ROUND_SIZE(addr,size) (((SIZE_T)(size) + ((UINT_PTR)(addr) & page_mask) + page_mask) & ~page_mask)
+
+#define VIRTUAL_DEBUG_DUMP_VIEW(view) do { if (TRACE_ON(virtual)) dump_view(view); } while (0)
+
+#ifndef MAP_NORESERVE
+#define MAP_NORESERVE 0
+#endif
+
+#ifdef _WIN64  /* on 64-bit the page protection bytes use a 2-level table */
+static const size_t pages_vprot_shift = 20;
+static const size_t pages_vprot_mask = (1 << 20) - 1;
+static size_t pages_vprot_size;
+static BYTE **pages_vprot;
+#else  /* on 32-bit we use a simple array with one byte per page */
+static BYTE *pages_vprot;
+#endif
+
+static struct file_view *view_block_start, *view_block_end, *next_free_view;
+static const size_t view_block_size = 0x100000;
+static void *preload_reserve_start;
+static void *preload_reserve_end;
+static BOOL force_exec_prot;  /* whether to force PROT_EXEC on all PROT_READ mmaps */
+
+struct range_entry
+{
+    void *base;
+    void *end;
+};
+
+static struct range_entry *free_ranges;
+static struct range_entry *free_ranges_end;
+
+
+static inline BOOL is_beyond_limit( const void *addr, size_t size, const void *limit )
+{
+    return (addr >= limit || (const char *)addr + size > (const char *)limit);
+}
+
+/* mmap() anonymous memory at a fixed address */
+void *anon_mmap_fixed( void *start, size_t size, int prot, int flags )
+{
+    return mmap( start, size, prot, MAP_PRIVATE | MAP_ANON | MAP_FIXED | flags, -1, 0 );
+}
+
+/* allocate anonymous mmap() memory at any address */
+void *anon_mmap_alloc( size_t size, int prot )
+{
+    return mmap( NULL, size, prot, MAP_PRIVATE | MAP_ANON, -1, 0 );
+}
+
+
+static void mmap_add_reserved_area( void *addr, SIZE_T size )
+{
+    struct reserved_area *area;
+    struct list *ptr;
+
+    if (!((char *)addr + size)) size--;  /* avoid wrap-around */
+
+    LIST_FOR_EACH( ptr, &reserved_areas )
+    {
+        area = LIST_ENTRY( ptr, struct reserved_area, entry );
+        if (area->base > addr)
+        {
+            /* try to merge with the next one */
+            if ((char *)addr + size == (char *)area->base)
+            {
+                area->base = addr;
+                area->size += size;
+                return;
+            }
+            break;
+        }
+        else if ((char *)area->base + area->size == (char *)addr)
+        {
+            /* merge with the previous one */
+            area->size += size;
+
+            /* try to merge with the next one too */
+            if ((ptr = list_next( &reserved_areas, ptr )))
+            {
+                struct reserved_area *next = LIST_ENTRY( ptr, struct reserved_area, entry );
+                if ((char *)addr + size == (char *)next->base)
+                {
+                    area->size += next->size;
+                    list_remove( &next->entry );
+                    free( next );
+                }
+            }
+            return;
+        }
+    }
+
+    if ((area = malloc( sizeof(*area) )))
+    {
+        area->base = addr;
+        area->size = size;
+        list_add_before( ptr, &area->entry );
+    }
+}
+
+static void mmap_remove_reserved_area( void *addr, SIZE_T size )
+{
+    struct reserved_area *area;
+    struct list *ptr;
+
+    if (!((char *)addr + size)) size--;  /* avoid wrap-around */
+
+    ptr = list_head( &reserved_areas );
+    /* find the first area covering address */
+    while (ptr)
+    {
+        area = LIST_ENTRY( ptr, struct reserved_area, entry );
+        if ((char *)area->base >= (char *)addr + size) break;  /* outside the range */
+        if ((char *)area->base + area->size > (char *)addr)  /* overlaps range */
+        {
+            if (area->base >= addr)
+            {
+                if ((char *)area->base + area->size > (char *)addr + size)
+                {
+                    /* range overlaps beginning of area only -> shrink area */
+                    area->size -= (char *)addr + size - (char *)area->base;
+                    area->base = (char *)addr + size;
+                    break;
+                }
+                else
+                {
+                    /* range contains the whole area -> remove area completely */
+                    ptr = list_next( &reserved_areas, ptr );
+                    list_remove( &area->entry );
+                    free( area );
+                    continue;
+                }
+            }
+            else
+            {
+                if ((char *)area->base + area->size > (char *)addr + size)
+                {
+                    /* range is in the middle of area -> split area in two */
+                    struct reserved_area *new_area = malloc( sizeof(*new_area) );
+                    if (new_area)
+                    {
+                        new_area->base = (char *)addr + size;
+                        new_area->size = (char *)area->base + area->size - (char *)new_area->base;
+                        list_add_after( ptr, &new_area->entry );
+                    }
+                    else size = (char *)area->base + area->size - (char *)addr;
+                    area->size = (char *)addr - (char *)area->base;
+                    break;
+                }
+                else
+                {
+                    /* range overlaps end of area only -> shrink area */
+                    area->size = (char *)addr - (char *)area->base;
+                }
+            }
+        }
+        ptr = list_next( &reserved_areas, ptr );
+    }
+}
+
+static int mmap_is_in_reserved_area( void *addr, SIZE_T size )
+{
+    struct reserved_area *area;
+    struct list *ptr;
+
+    LIST_FOR_EACH( ptr, &reserved_areas )
+    {
+        area = LIST_ENTRY( ptr, struct reserved_area, entry );
+        if (area->base > addr) break;
+        if ((char *)area->base + area->size <= (char *)addr) continue;
+        /* area must contain block completely */
+        if ((char *)area->base + area->size < (char *)addr + size) return -1;
+        return 1;
+    }
+    return 0;
+}
+
+static int mmap_enum_reserved_areas( int (*enum_func)(void *base, SIZE_T size, void *arg),
+                                     void *arg, int top_down )
+{
+    int ret = 0;
+    struct list *ptr;
+
+    if (top_down)
+    {
+        for (ptr = reserved_areas.prev; ptr != &reserved_areas; ptr = ptr->prev)
+        {
+            struct reserved_area *area = LIST_ENTRY( ptr, struct reserved_area, entry );
+            if ((ret = enum_func( area->base, area->size, arg ))) break;
+        }
+    }
+    else
+    {
+        for (ptr = reserved_areas.next; ptr != &reserved_areas; ptr = ptr->next)
+        {
+            struct reserved_area *area = LIST_ENTRY( ptr, struct reserved_area, entry );
+            if ((ret = enum_func( area->base, area->size, arg ))) break;
+        }
+    }
+    return ret;
+}
+
+static void *anon_mmap_tryfixed( void *start, size_t size, int prot, int flags )
+{
+    void *ptr;
+
+#ifdef MAP_FIXED_NOREPLACE
+    ptr = mmap( start, size, prot, MAP_FIXED_NOREPLACE | MAP_PRIVATE | MAP_ANON | flags, -1, 0 );
+#elif defined(MAP_TRYFIXED)
+    ptr = mmap( start, size, prot, MAP_TRYFIXED | MAP_PRIVATE | MAP_ANON | flags, -1, 0 );
+#elif defined(__FreeBSD__) || defined(__FreeBSD_kernel__)
+    ptr = mmap( start, size, prot, MAP_FIXED | MAP_EXCL | MAP_PRIVATE | MAP_ANON | flags, -1, 0 );
+    if (ptr == MAP_FAILED && errno == EINVAL) errno = EEXIST;
+#elif defined(__APPLE__)
+    mach_vm_address_t result = (mach_vm_address_t)start;
+    kern_return_t ret = mach_vm_map( mach_task_self(), &result, size, 0, VM_FLAGS_FIXED,
+                                     MEMORY_OBJECT_NULL, 0, 0, prot, VM_PROT_ALL, VM_INHERIT_COPY );
+
+    if (!ret)
+    {
+        if ((ptr = anon_mmap_fixed( start, size, prot, flags )) == MAP_FAILED)
+            mach_vm_deallocate( mach_task_self(), result, size );
+    }
+    else
+    {
+        errno = (ret == KERN_NO_SPACE ? EEXIST : ENOMEM);
+        ptr = MAP_FAILED;
+    }
+#else
+    ptr = mmap( start, size, prot, MAP_PRIVATE | MAP_ANON | flags, -1, 0 );
+#endif
+    if (ptr != MAP_FAILED && ptr != start)
+    {
+        if (is_beyond_limit( ptr, size, user_space_limit ))
+        {
+            anon_mmap_fixed( ptr, size, PROT_NONE, MAP_NORESERVE );
+            mmap_add_reserved_area( ptr, size );
+        }
+        else munmap( ptr, size );
+        ptr = MAP_FAILED;
+        errno = EEXIST;
+    }
+    return ptr;
+}
+
+static void reserve_area( void *addr, void *end )
+{
+#ifdef __APPLE__
+
+#ifdef __i386__
+    static const mach_vm_address_t max_address = VM_MAX_ADDRESS;
+#else
+    static const mach_vm_address_t max_address = MACH_VM_MAX_ADDRESS;
+#endif
+    mach_vm_address_t address = (mach_vm_address_t)addr;
+    mach_vm_address_t end_address = (mach_vm_address_t)end;
+
+    if (!end_address || max_address < end_address)
+        end_address = max_address;
+
+    while (address < end_address)
+    {
+        mach_vm_address_t hole_address = address;
+        kern_return_t ret;
+        mach_vm_size_t size;
+        vm_region_basic_info_data_64_t info;
+        mach_msg_type_number_t count = VM_REGION_BASIC_INFO_COUNT_64;
+        mach_port_t dummy_object_name = MACH_PORT_NULL;
+
+        /* find the mapped region at or above the current address. */
+        ret = mach_vm_region(mach_task_self(), &address, &size, VM_REGION_BASIC_INFO_64,
+                             (vm_region_info_t)&info, &count, &dummy_object_name);
+        if (ret != KERN_SUCCESS)
+        {
+            address = max_address;
+            size = 0;
+        }
+
+        if (end_address < address)
+            address = end_address;
+        if (hole_address < address)
+        {
+            /* found a hole, attempt to reserve it. */
+            size_t hole_size = address - hole_address;
+            mach_vm_address_t alloc_address = hole_address;
+
+            ret = mach_vm_map( mach_task_self(), &alloc_address, hole_size, 0, VM_FLAGS_FIXED,
+                               MEMORY_OBJECT_NULL, 0, 0, PROT_NONE, VM_PROT_ALL, VM_INHERIT_COPY );
+            if (!ret) mmap_add_reserved_area( (void*)hole_address, hole_size );
+            else if (ret == KERN_NO_SPACE)
+            {
+                /* something filled (part of) the hole before we could.
+                   go back and look again. */
+                address = hole_address;
+                continue;
+            }
+        }
+        address += size;
+    }
+#else
+    void *ptr;
+    size_t size = (char *)end - (char *)addr;
+
+    if (!size) return;
+
+    if ((ptr = anon_mmap_tryfixed( addr, size, PROT_NONE, MAP_NORESERVE )) != MAP_FAILED)
+    {
+        mmap_add_reserved_area( addr, size );
+        return;
+    }
+    size = (size / 2) & ~granularity_mask;
+    if (size)
+    {
+        reserve_area( addr, (char *)addr + size );
+        reserve_area( (char *)addr + size, end );
+    }
+#endif /* __APPLE__ */
+}
+
+
+static void mmap_init( const struct preload_info *preload_info )
+{
+#ifndef _WIN64
+#ifndef __APPLE__
+    char stack;
+    char * const stack_ptr = &stack;
+#endif
+    char *user_space_limit = (char *)0x7ffe0000;
+    int i;
+
+    if (preload_info)
+    {
+        /* check for a reserved area starting at the user space limit */
+        /* to avoid wasting time trying to allocate it again */
+        for (i = 0; preload_info[i].size; i++)
+        {
+            if ((char *)preload_info[i].addr > user_space_limit) break;
+            if ((char *)preload_info[i].addr + preload_info[i].size > user_space_limit)
+            {
+                user_space_limit = (char *)preload_info[i].addr + preload_info[i].size;
+                break;
+            }
+        }
+    }
+    else reserve_area( (void *)0x00010000, (void *)0x40000000 );
+
+
+#ifndef __APPLE__
+    if (stack_ptr >= user_space_limit)
+    {
+        char *end = 0;
+        char *base = stack_ptr - ((unsigned int)stack_ptr & granularity_mask) - (granularity_mask + 1);
+        if (base > user_space_limit) reserve_area( user_space_limit, base );
+        base = stack_ptr - ((unsigned int)stack_ptr & granularity_mask) + (granularity_mask + 1);
+#if defined(linux) || defined(__FreeBSD__) || defined (__FreeBSD_kernel__) || defined(__DragonFly__)
+        /* Heuristic: assume the stack is near the end of the address */
+        /* space, this avoids a lot of futile allocation attempts */
+        end = (char *)(((unsigned long)base + 0x0fffffff) & 0xf0000000);
+#endif
+        reserve_area( base, end );
+    }
+    else
+#endif
+        reserve_area( user_space_limit, 0 );
+
+#else
+
+    if (preload_info) return;
+    /* if we don't have a preloader, try to reserve the space now */
+    reserve_area( (void *)0x000000010000, (void *)0x000068000000 );
+    reserve_area( (void *)0x00007ff00000, (void *)0x00007fff0000 );
+    reserve_area( (void *)0x7ffffe000000, (void *)0x7fffffff0000 );
+
+#endif
+}
+
+
+/***********************************************************************
+ *           get_wow_user_space_limit
+ */
+static void *get_wow_user_space_limit(void)
+{
+#ifdef _WIN64
+    if ((main_image_info.ImageCharacteristics & IMAGE_FILE_LARGE_ADDRESS_AWARE) || large_address_space_active) return (void *)0xc0000000;
+    return (void *)0x7fff0000;
+#endif
+    return user_space_limit;
+}
+
+
+/***********************************************************************
+ *           add_builtin_module
+ */
+static void add_builtin_module( void *module, void *handle )
+{
+    struct builtin_module *builtin;
+
+    if (!(builtin = malloc( sizeof(*builtin) ))) return;
+    builtin->handle      = handle;
+    builtin->module      = module;
+    builtin->refcount    = 1;
+    builtin->unix_handle = NULL;
+    list_add_tail( &builtin_modules, &builtin->entry );
+}
+
+
+/***********************************************************************
+ *           release_builtin_module
+ */
+void release_builtin_module( void *module )
+{
+    struct builtin_module *builtin;
+
+    LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+    {
+        if (builtin->module != module) continue;
+        if (!--builtin->refcount)
+        {
+            list_remove( &builtin->entry );
+            if (builtin->handle) dlclose( builtin->handle );
+            if (builtin->unix_handle) dlclose( builtin->unix_handle );
+            free( builtin );
+        }
+        break;
+    }
+}
+
+
+/***********************************************************************
+ *           get_builtin_so_handle
+ */
+void *get_builtin_so_handle( void *module )
+{
+    sigset_t sigset;
+    void *ret = NULL;
+    struct builtin_module *builtin;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+    {
+        if (builtin->module != module) continue;
+        ret = builtin->handle;
+        if (ret) builtin->refcount++;
+        break;
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return ret;
+}
+
+
+/***********************************************************************
+ *           get_builtin_unix_funcs
+ */
+static NTSTATUS get_builtin_unix_funcs( void *module, BOOL wow, void **funcs )
+{
+    const char *ptr_name = wow ? "__wine_unix_call_wow64_funcs" : "__wine_unix_call_funcs";
+    sigset_t sigset;
+    NTSTATUS status = STATUS_DLL_NOT_FOUND;
+    struct builtin_module *builtin;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+    {
+        if (builtin->module != module) continue;
+        if (builtin->unix_handle)
+        {
+            *funcs = dlsym( builtin->unix_handle, ptr_name );
+            status = *funcs ? STATUS_SUCCESS : STATUS_ENTRYPOINT_NOT_FOUND;
+        }
+        break;
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *           load_builtin_unixlib
+ */
+NTSTATUS load_builtin_unixlib( void *module, const char *name )
+{
+    void *handle;
+    sigset_t sigset;
+    NTSTATUS status = STATUS_DLL_NOT_FOUND;
+    struct builtin_module *builtin;
+
+    if (!(handle = dlopen( name, RTLD_NOW ))) return status;
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+    {
+        if (builtin->module != module) continue;
+        if (!builtin->unix_handle)
+        {
+            builtin->unix_handle = handle;
+            status = STATUS_SUCCESS;
+        }
+        else status = STATUS_IMAGE_ALREADY_LOADED;
+        break;
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    if (status) dlclose( handle );
+    return status;
+}
+
+
+/***********************************************************************
+ *           fixup_builtin_so_32on64_sels
+ *
+ * Each hybrid Winelib .so has its own copy of the selectors, set them here.
+ *
+ * For Winelib .dll.so's, these are set from dlopen_dll().
+ * But when running a hybrid Winelib .exe.so, signal_init_process()
+ * (which sets up the code segments) is called after dlopen_dll().
+ *
+ * This function is called from signal_init_process to cover a .exe.so
+ * which was already loaded.
+ */
+void fixup_builtin_so_32on64_sels(void)
+{
+#if defined(__APPLE__) && defined(__x86_64__)
+    sigset_t sigset;
+    struct builtin_module *builtin;
+    unsigned short *cs32, *cs64, *ds32;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+    {
+        if (!builtin->handle)
+            continue;
+
+        cs32 = dlsym( builtin->handle, "wine_32on64_cs32" );
+        cs64 = dlsym( builtin->handle, "wine_32on64_cs64" );
+        ds32 = dlsym( builtin->handle, "wine_32on64_ds32" );
+
+        if (cs32) *cs32 = cs32_sel;
+        if (cs64) *cs64 = cs64_sel;
+        if (ds32) *ds32 = ds32_sel;
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+#endif
+}
+
+
+/***********************************************************************
+ *           free_ranges_lower_bound
+ *
+ * Returns the first range whose end is not less than addr, or end if there's none.
+ */
+static struct range_entry *free_ranges_lower_bound( void *addr )
+{
+    struct range_entry *begin = free_ranges;
+    struct range_entry *end = free_ranges_end;
+    struct range_entry *mid;
+
+    while (begin < end)
+    {
+        mid = begin + (end - begin) / 2;
+        if (mid->end < addr)
+            begin = mid + 1;
+        else
+            end = mid;
+    }
+
+    return begin;
+}
+
+
+/***********************************************************************
+ *           free_ranges_insert_view
+ *
+ * Updates the free_ranges after a new view has been created.
+ */
+static void free_ranges_insert_view( struct file_view *view )
+{
+    void *view_base = ROUND_ADDR( view->base, granularity_mask );
+    void *view_end = ROUND_ADDR( (char *)view->base + view->size + granularity_mask, granularity_mask );
+    struct range_entry *range = free_ranges_lower_bound( view_base );
+    struct range_entry *next = range + 1;
+
+    /* free_ranges initial value is such that the view is either inside range or before another one. */
+    assert( range != free_ranges_end );
+    assert( range->end > view_base || next != free_ranges_end );
+
+    /* this happens because virtual_alloc_thread_stack shrinks a view, then creates another one on top,
+     * or because AT_ROUND_TO_PAGE was used with NtMapViewOfSection to force 4kB aligned mapping. */
+    if ((range->end > view_base && range->base >= view_end) ||
+        (range->end == view_base && next->base >= view_end))
+    {
+        /* on Win64, assert that it's correctly aligned so we're not going to be in trouble later */
+#ifdef _WIN64
+        assert( view->base == view_base );
+#endif
+        WARN( "range %p - %p is already mapped\n", view_base, view_end );
+        return;
+    }
+
+    /* this should never happen */
+    if (range->base > view_base || range->end < view_end)
+        ERR( "range %p - %p is already partially mapped\n", view_base, view_end );
+    assert( range->base <= view_base && range->end >= view_end );
+
+    /* need to split the range in two */
+    if (range->base < view_base && range->end > view_end)
+    {
+        memmove( next + 1, next, (free_ranges_end - next) * sizeof(struct range_entry) );
+        free_ranges_end += 1;
+        if ((char *)free_ranges_end - (char *)free_ranges > view_block_size)
+            ERR( "Free range sequence is full, trouble ahead!\n" );
+        assert( (char *)free_ranges_end - (char *)free_ranges <= view_block_size );
+
+        next->base = view_end;
+        next->end = range->end;
+        range->end = view_base;
+    }
+    else
+    {
+        /* otherwise we just have to shrink it */
+        if (range->base < view_base)
+            range->end = view_base;
+        else
+            range->base = view_end;
+
+        if (range->base < range->end) return;
+
+        /* and possibly remove it if it's now empty */
+        memmove( range, next, (free_ranges_end - next) * sizeof(struct range_entry) );
+        free_ranges_end -= 1;
+        assert( free_ranges_end - free_ranges > 0 );
+    }
+}
+
+
+/***********************************************************************
+ *           free_ranges_remove_view
+ *
+ * Updates the free_ranges after a view has been destroyed.
+ */
+static void free_ranges_remove_view( struct file_view *view )
+{
+    void *view_base = ROUND_ADDR( view->base, granularity_mask );
+    void *view_end = ROUND_ADDR( (char *)view->base + view->size + granularity_mask, granularity_mask );
+    struct range_entry *range = free_ranges_lower_bound( view_base );
+    struct range_entry *next = range + 1;
+
+    /* It's possible to use AT_ROUND_TO_PAGE on 32bit with NtMapViewOfSection to force 4kB alignment,
+     * and this breaks our assumptions. Look at the views around to check if the range is still in use. */
+#ifndef _WIN64
+    struct file_view *prev_view = RB_ENTRY_VALUE( rb_prev( &view->entry ), struct file_view, entry );
+    struct file_view *next_view = RB_ENTRY_VALUE( rb_next( &view->entry ), struct file_view, entry );
+    void *prev_view_base = prev_view ? ROUND_ADDR( prev_view->base, granularity_mask ) : NULL;
+    void *prev_view_end = prev_view ? ROUND_ADDR( (char *)prev_view->base + prev_view->size + granularity_mask, granularity_mask ) : NULL;
+    void *next_view_base = next_view ? ROUND_ADDR( next_view->base, granularity_mask ) : NULL;
+    void *next_view_end = next_view ? ROUND_ADDR( (char *)next_view->base + next_view->size + granularity_mask, granularity_mask ) : NULL;
+
+    if ((prev_view_base < view_end && prev_view_end > view_base) ||
+        (next_view_base < view_end && next_view_end > view_base))
+    {
+        WARN( "range %p - %p is still mapped\n", view_base, view_end );
+        return;
+    }
+#endif
+
+    /* free_ranges initial value is such that the view is either inside range or before another one. */
+    assert( range != free_ranges_end );
+    assert( range->end > view_base || next != free_ranges_end );
+
+    /* this should never happen, but we can safely ignore it */
+    if (range->base <= view_base && range->end >= view_end)
+    {
+        WARN( "range %p - %p is already unmapped\n", view_base, view_end );
+        return;
+    }
+
+    /* this should never happen */
+    if (range->base < view_end && range->end > view_base)
+        ERR( "range %p - %p is already partially unmapped\n", view_base, view_end );
+    assert( range->end <= view_base || range->base >= view_end );
+
+    /* merge with next if possible */
+    if (range->end == view_base && next->base == view_end)
+    {
+        range->end = next->end;
+        memmove( next, next + 1, (free_ranges_end - next - 1) * sizeof(struct range_entry) );
+        free_ranges_end -= 1;
+        assert( free_ranges_end - free_ranges > 0 );
+    }
+    /* or try growing the range */
+    else if (range->end == view_base)
+        range->end = view_end;
+    else if (range->base == view_end)
+        range->base = view_base;
+    /* otherwise create a new one */
+    else
+    {
+        memmove( range + 1, range, (free_ranges_end - range) * sizeof(struct range_entry) );
+        free_ranges_end += 1;
+        if ((char *)free_ranges_end - (char *)free_ranges > view_block_size)
+            ERR( "Free range sequence is full, trouble ahead!\n" );
+        assert( (char *)free_ranges_end - (char *)free_ranges <= view_block_size );
+
+        range->base = view_base;
+        range->end = view_end;
+    }
+}
+
+
+static inline int is_view_valloc( const struct file_view *view )
+{
+    return !(view->protect & (SEC_FILE | SEC_RESERVE | SEC_COMMIT));
+}
+
+/***********************************************************************
+ *           get_page_vprot
+ *
+ * Return the page protection byte.
+ */
+static BYTE get_page_vprot( const void *addr )
+{
+    size_t idx = (size_t)addr >> page_shift;
+
+#ifdef _WIN64
+    if ((idx >> pages_vprot_shift) >= pages_vprot_size) return 0;
+    if (!pages_vprot[idx >> pages_vprot_shift]) return 0;
+    return pages_vprot[idx >> pages_vprot_shift][idx & pages_vprot_mask];
+#else
+    return pages_vprot[idx];
+#endif
+}
+
+
+/***********************************************************************
+ *           get_vprot_range_size
+ *
+ * Return the size of the region with equal masked vprot byte.
+ * Also return the protections for the first page.
+ * The function assumes that base and size are page aligned,
+ * base + size does not wrap around and the range is within view so
+ * vprot bytes are allocated for the range. */
+static SIZE_T get_vprot_range_size( char *base, SIZE_T size, BYTE mask, BYTE *vprot )
+{
+    static const UINT_PTR word_from_byte = (UINT_PTR)0x101010101010101;
+    static const UINT_PTR index_align_mask = sizeof(UINT_PTR) - 1;
+    SIZE_T curr_idx, start_idx, end_idx, aligned_start_idx;
+    UINT_PTR vprot_word, mask_word;
+    const BYTE *vprot_ptr;
+
+    TRACE("base %p, size %p, mask %#x.\n", base, (void *)size, mask);
+
+    curr_idx = start_idx = (size_t)base >> page_shift;
+    end_idx = start_idx + (size >> page_shift);
+
+    aligned_start_idx = (start_idx + index_align_mask) & ~index_align_mask;
+    if (aligned_start_idx > end_idx) aligned_start_idx = end_idx;
+
+#ifdef _WIN64
+    vprot_ptr = pages_vprot[curr_idx >> pages_vprot_shift] + (curr_idx & pages_vprot_mask);
+#else
+    vprot_ptr = pages_vprot + curr_idx;
+#endif
+    *vprot = *vprot_ptr;
+
+    /* Page count page table is at least the multiples of sizeof(UINT_PTR)
+     * so we don't have to worry about crossing the boundary on unaligned idx values. */
+
+    for (; curr_idx < aligned_start_idx; ++curr_idx, ++vprot_ptr)
+        if ((*vprot ^ *vprot_ptr) & mask) return (curr_idx - start_idx) << page_shift;
+
+    vprot_word = word_from_byte * *vprot;
+    mask_word = word_from_byte * mask;
+    for (; curr_idx < end_idx; curr_idx += sizeof(UINT_PTR), vprot_ptr += sizeof(UINT_PTR))
+    {
+#ifdef _WIN64
+        if (!(curr_idx & pages_vprot_mask)) vprot_ptr = pages_vprot[curr_idx >> pages_vprot_shift];
+#endif
+        if ((vprot_word ^ *(UINT_PTR *)vprot_ptr) & mask_word)
+        {
+            for (; curr_idx < end_idx; ++curr_idx, ++vprot_ptr)
+                if ((*vprot ^ *vprot_ptr) & mask) break;
+            return (curr_idx - start_idx) << page_shift;
+        }
+    }
+    return size;
+}
+
+/***********************************************************************
+ *           set_page_vprot
+ *
+ * Set a range of page protection bytes.
+ */
+static void set_page_vprot( const void *addr, size_t size, BYTE vprot )
+{
+    size_t idx = (size_t)addr >> page_shift;
+    size_t end = ((size_t)addr + size + page_mask) >> page_shift;
+
+#ifdef _WIN64
+    while (idx >> pages_vprot_shift != end >> pages_vprot_shift)
+    {
+        size_t dir_size = pages_vprot_mask + 1 - (idx & pages_vprot_mask);
+        memset( pages_vprot[idx >> pages_vprot_shift] + (idx & pages_vprot_mask), vprot, dir_size );
+        idx += dir_size;
+    }
+    memset( pages_vprot[idx >> pages_vprot_shift] + (idx & pages_vprot_mask), vprot, end - idx );
+#else
+    memset( pages_vprot + idx, vprot, end - idx );
+#endif
+}
+
+
+/***********************************************************************
+ *           set_page_vprot_bits
+ *
+ * Set or clear bits in a range of page protection bytes.
+ */
+static void set_page_vprot_bits( const void *addr, size_t size, BYTE set, BYTE clear )
+{
+    size_t idx = (size_t)addr >> page_shift;
+    size_t end = ((size_t)addr + size + page_mask) >> page_shift;
+
+#ifdef _WIN64
+    for ( ; idx < end; idx++)
+    {
+        BYTE *ptr = pages_vprot[idx >> pages_vprot_shift] + (idx & pages_vprot_mask);
+        *ptr = (*ptr & ~clear) | set;
+    }
+#else
+    for ( ; idx < end; idx++) pages_vprot[idx] = (pages_vprot[idx] & ~clear) | set;
+#endif
+}
+
+
+/***********************************************************************
+ *           alloc_pages_vprot
+ *
+ * Allocate the page protection bytes for a given range.
+ */
+static BOOL alloc_pages_vprot( const void *addr, size_t size )
+{
+#ifdef _WIN64
+    size_t idx = (size_t)addr >> page_shift;
+    size_t end = ((size_t)addr + size + page_mask) >> page_shift;
+    size_t i;
+    void *ptr;
+
+    assert( end <= pages_vprot_size << pages_vprot_shift );
+    for (i = idx >> pages_vprot_shift; i < (end + pages_vprot_mask) >> pages_vprot_shift; i++)
+    {
+        if (pages_vprot[i]) continue;
+        if ((ptr = anon_mmap_alloc( pages_vprot_mask + 1, PROT_READ | PROT_WRITE )) == MAP_FAILED)
+            return FALSE;
+        pages_vprot[i] = ptr;
+    }
+#endif
+    return TRUE;
+}
+
+
+/***********************************************************************
+ *           compare_view
+ *
+ * View comparison function used for the rb tree.
+ */
+static int compare_view( const void *addr, const struct wine_rb_entry *entry )
+{
+    struct file_view *view = WINE_RB_ENTRY_VALUE( entry, struct file_view, entry );
+
+    if (addr < view->base) return -1;
+    if (addr > view->base) return 1;
+    return 0;
+}
+
+
+/***********************************************************************
+ *           get_prot_str
+ */
+static const char *get_prot_str( BYTE prot )
+{
+    static char buffer[6];
+    buffer[0] = (prot & VPROT_COMMITTED) ? 'c' : '-';
+    buffer[1] = (prot & VPROT_GUARD) ? 'g' : ((prot & VPROT_WRITEWATCH) ? 'H' : '-');
+    buffer[2] = (prot & VPROT_READ) ? 'r' : '-';
+    buffer[3] = (prot & VPROT_WRITECOPY) ? 'W' : ((prot & VPROT_WRITE) ? 'w' : '-');
+    buffer[4] = (prot & VPROT_EXEC) ? 'x' : '-';
+    buffer[5] = 0;
+    return buffer;
+}
+
+
+/***********************************************************************
+ *           get_unix_prot
+ *
+ * Convert page protections to protection for mmap/mprotect.
+ */
+static int get_unix_prot( BYTE vprot )
+{
+    int prot = 0;
+    if ((vprot & VPROT_COMMITTED) && !(vprot & VPROT_GUARD))
+    {
+        if (vprot & VPROT_READ) prot |= PROT_READ;
+        if (vprot & VPROT_WRITE) prot |= PROT_WRITE | PROT_READ;
+        if (vprot & VPROT_WRITECOPY) prot |= PROT_WRITE | PROT_READ;
+        if (vprot & VPROT_EXEC) prot |= PROT_EXEC | PROT_READ;
+        if (vprot & VPROT_WRITEWATCH) prot &= ~PROT_WRITE;
+    }
+    if (!prot) prot = PROT_NONE;
+    return prot;
+}
+
+
+/***********************************************************************
+ *           dump_view
+ */
+static void dump_view( struct file_view *view )
+{
+    UINT i, count;
+    char *addr = view->base;
+    BYTE prot = get_page_vprot( addr );
+
+    TRACE( "View: %p - %p", addr, addr + view->size - 1 );
+    if (view->protect & VPROT_SYSTEM)
+        TRACE( " (builtin image)\n" );
+    else if (view->protect & SEC_IMAGE)
+        TRACE( " (image)\n" );
+    else if (view->protect & SEC_FILE)
+        TRACE( " (file)\n" );
+    else if (view->protect & (SEC_RESERVE | SEC_COMMIT))
+        TRACE( " (anonymous)\n" );
+    else
+        TRACE( " (valloc)\n");
+
+    for (count = i = 1; i < view->size >> page_shift; i++, count++)
+    {
+        BYTE next = get_page_vprot( addr + (count << page_shift) );
+        if (next == prot) continue;
+        TRACE( "      %p - %p %s\n",
+                 addr, addr + (count << page_shift) - 1, get_prot_str(prot) );
+        addr += (count << page_shift);
+        prot = next;
+        count = 0;
+    }
+    if (count)
+        TRACE( "      %p - %p %s\n",
+                 addr, addr + (count << page_shift) - 1, get_prot_str(prot) );
+}
+
+
+/***********************************************************************
+ *           VIRTUAL_Dump
+ */
+#ifdef WINE_VM_DEBUG
+static void VIRTUAL_Dump(void)
+{
+    sigset_t sigset;
+    struct file_view *view;
+
+    TRACE( "Dump of all virtual memory views:\n" );
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    WINE_RB_FOR_EACH_ENTRY( view, &views_tree, struct file_view, entry )
+    {
+        dump_view( view );
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+}
+#endif
+
+
+/***********************************************************************
+ *           find_view
+ *
+ * Find the view containing a given address. virtual_mutex must be held by caller.
+ *
+ * PARAMS
+ *      addr  [I] Address
+ *
+ * RETURNS
+ *	View: Success
+ *	NULL: Failure
+ */
+static struct file_view *find_view( const void *addr, size_t size )
+{
+    struct wine_rb_entry *ptr = views_tree.root;
+
+    if ((const char *)addr + size < (const char *)addr) return NULL; /* overflow */
+
+    while (ptr)
+    {
+        struct file_view *view = WINE_RB_ENTRY_VALUE( ptr, struct file_view, entry );
+
+        if (view->base > addr) ptr = ptr->left;
+        else if ((const char *)view->base + view->size <= (const char *)addr) ptr = ptr->right;
+        else if ((const char *)view->base + view->size < (const char *)addr + size) break;  /* size too large */
+        else return view;
+    }
+    return NULL;
+}
+
+
+/***********************************************************************
+ *           get_zero_bits_mask
+ */
+static inline UINT_PTR get_zero_bits_mask( ULONG_PTR zero_bits )
+{
+    unsigned int shift;
+
+    if (zero_bits == 0) return ~(UINT_PTR)0;
+
+    if (zero_bits < 32) shift = 32 + zero_bits;
+    else
+    {
+        shift = 63;
+#ifdef _WIN64
+        if (zero_bits >> 32) { shift -= 32; zero_bits >>= 32; }
+#endif
+        if (zero_bits >> 16) { shift -= 16; zero_bits >>= 16; }
+        if (zero_bits >> 8) { shift -= 8; zero_bits >>= 8; }
+        if (zero_bits >> 4) { shift -= 4; zero_bits >>= 4; }
+        if (zero_bits >> 2) { shift -= 2; zero_bits >>= 2; }
+        if (zero_bits >> 1) { shift -= 1; }
+    }
+    return (UINT_PTR)((~(UINT64)0) >> shift);
+}
+
+
+/***********************************************************************
+ *           is_write_watch_range
+ */
+static inline BOOL is_write_watch_range( const void *addr, size_t size )
+{
+    struct file_view *view = find_view( addr, size );
+    return view && (view->protect & VPROT_WRITEWATCH);
+}
+
+
+/***********************************************************************
+ *           find_view_range
+ *
+ * Find the first view overlapping at least part of the specified range.
+ * virtual_mutex must be held by caller.
+ */
+static struct file_view *find_view_range( const void *addr, size_t size )
+{
+    struct wine_rb_entry *ptr = views_tree.root;
+
+    while (ptr)
+    {
+        struct file_view *view = WINE_RB_ENTRY_VALUE( ptr, struct file_view, entry );
+
+        if ((const char *)view->base >= (const char *)addr + size) ptr = ptr->left;
+        else if ((const char *)view->base + view->size <= (const char *)addr) ptr = ptr->right;
+        else return view;
+    }
+    return NULL;
+}
+
+
+/***********************************************************************
+ *           find_view_inside_range
+ *
+ * Find first (resp. last, if top_down) view inside a range.
+ * virtual_mutex must be held by caller.
+ */
+static struct wine_rb_entry *find_view_inside_range( void **base_ptr, void **end_ptr, int top_down )
+{
+    struct wine_rb_entry *first = NULL, *ptr = views_tree.root;
+    void *base = *base_ptr, *end = *end_ptr;
+
+    /* find the first (resp. last) view inside the range */
+    while (ptr)
+    {
+        struct file_view *view = WINE_RB_ENTRY_VALUE( ptr, struct file_view, entry );
+        if ((char *)view->base + view->size >= (char *)end)
+        {
+            end = min( end, view->base );
+            ptr = ptr->left;
+        }
+        else if (view->base <= base)
+        {
+            base = max( (char *)base, (char *)view->base + view->size );
+            ptr = ptr->right;
+        }
+        else
+        {
+            first = ptr;
+            ptr = top_down ? ptr->right : ptr->left;
+        }
+    }
+
+    *base_ptr = base;
+    *end_ptr = end;
+    return first;
+}
+
+
+/***********************************************************************
+ *           try_map_free_area
+ *
+ * Try mmaping some expected free memory region, eventually stepping and
+ * retrying inside it, and return where it actually succeeded, or NULL.
+ */
+static void* try_map_free_area( void *base, void *end, ptrdiff_t step,
+                                void *start, size_t size, int unix_prot )
+{
+    void *ptr;
+
+    while (start && base <= start && (char*)start + size <= (char*)end)
+    {
+        if ((ptr = anon_mmap_tryfixed( start, size, unix_prot, 0 )) != MAP_FAILED) return start;
+        TRACE( "Found free area is already mapped, start %p.\n", start );
+        if (errno != EEXIST)
+        {
+            ERR( "mmap() error %s, range %p-%p, unix_prot %#x.\n",
+                 strerror(errno), start, (char *)start + size, unix_prot );
+            return NULL;
+        }
+        if ((step > 0 && (char *)end - (char *)start < step) ||
+            (step < 0 && (char *)start - (char *)base < -step) ||
+            step == 0)
+            break;
+        start = (char *)start + step;
+    }
+
+    return NULL;
+}
+
+
+/***********************************************************************
+ *           map_free_area
+ *
+ * Find a free area between views inside the specified range and map it.
+ * virtual_mutex must be held by caller.
+ */
+static void *map_free_area( void *base, void *end, size_t size, int top_down, int unix_prot )
+{
+    struct wine_rb_entry *first = find_view_inside_range( &base, &end, top_down );
+    ptrdiff_t step = top_down ? -(granularity_mask + 1) : (granularity_mask + 1);
+    void *start;
+
+    if (top_down)
+    {
+        start = ROUND_ADDR( (char *)end - size, granularity_mask );
+        if (start >= end || start < base) return NULL;
+
+        while (first)
+        {
+            struct file_view *view = WINE_RB_ENTRY_VALUE( first, struct file_view, entry );
+            if ((start = try_map_free_area( (char *)view->base + view->size, (char *)start + size, step,
+                                            start, size, unix_prot ))) break;
+            start = ROUND_ADDR( (char *)view->base - size, granularity_mask );
+            /* stop if remaining space is not large enough */
+            if (!start || start >= end || start < base) return NULL;
+            first = rb_prev( first );
+        }
+    }
+    else
+    {
+        start = ROUND_ADDR( (char *)base + granularity_mask, granularity_mask );
+        if (!start || start >= end || (char *)end - (char *)start < size) return NULL;
+
+        while (first)
+        {
+            struct file_view *view = WINE_RB_ENTRY_VALUE( first, struct file_view, entry );
+            if ((start = try_map_free_area( start, view->base, step,
+                                            start, size, unix_prot ))) break;
+            start = ROUND_ADDR( (char *)view->base + view->size + granularity_mask, granularity_mask );
+            /* stop if remaining space is not large enough */
+            if (!start || start >= end || (char *)end - (char *)start < size) return NULL;
+            first = rb_next( first );
+        }
+    }
+
+    if (!first)
+        return try_map_free_area( base, end, step, start, size, unix_prot );
+
+    return start;
+}
+
+
+/***********************************************************************
+ *           find_reserved_free_area
+ *
+ * Find a free area between views inside the specified range.
+ * virtual_mutex must be held by caller.
+ * The range must be inside the preloader reserved range.
+ */
+static void *find_reserved_free_area( void *base, void *end, size_t size, int top_down )
+{
+    struct range_entry *range;
+    void *start;
+
+    base = ROUND_ADDR( (char *)base + granularity_mask, granularity_mask );
+    end = (char *)ROUND_ADDR( (char *)end - size, granularity_mask ) + size;
+
+    if (top_down)
+    {
+        start = (char *)end - size;
+        range = free_ranges_lower_bound( start );
+        assert(range != free_ranges_end && range->end >= start);
+
+        if ((char *)range->end - (char *)start < size) start = ROUND_ADDR( (char *)range->end - size, granularity_mask );
+        do
+        {
+            if (start >= end || start < base || (char *)end - (char *)start < size) return NULL;
+            if (start < range->end && start >= range->base && (char *)range->end - (char *)start >= size) break;
+            if (--range < free_ranges) return NULL;
+            start = ROUND_ADDR( (char *)range->end - size, granularity_mask );
+        }
+        while (1);
+    }
+    else
+    {
+        start = base;
+        range = free_ranges_lower_bound( start );
+        assert(range != free_ranges_end && range->end >= start);
+
+        if (start < range->base) start = ROUND_ADDR( (char *)range->base + granularity_mask, granularity_mask );
+        do
+        {
+            if (start >= end || start < base || (char *)end - (char *)start < size) return NULL;
+            if (start < range->end && start >= range->base && (char *)range->end - (char *)start >= size) break;
+            if (++range == free_ranges_end) return NULL;
+            start = ROUND_ADDR( (char *)range->base + granularity_mask, granularity_mask );
+        }
+        while (1);
+    }
+    return start;
+}
+
+
+/***********************************************************************
+ *           add_reserved_area
+ *
+ * Add a reserved area to the list maintained by libwine.
+ * virtual_mutex must be held by caller.
+ */
+static void add_reserved_area( void *addr, size_t size )
+{
+    TRACE( "adding %p-%p\n", addr, (char *)addr + size );
+
+    if (addr < user_space_limit)
+    {
+        /* unmap the part of the area that is below the limit */
+        assert( (char *)addr + size > (char *)user_space_limit );
+        munmap( addr, (char *)user_space_limit - (char *)addr );
+        size -= (char *)user_space_limit - (char *)addr;
+        addr = user_space_limit;
+    }
+    /* blow away existing mappings */
+    anon_mmap_fixed( addr, size, PROT_NONE, MAP_NORESERVE );
+    mmap_add_reserved_area( addr, size );
+}
+
+
+/***********************************************************************
+ *           remove_reserved_area
+ *
+ * Remove a reserved area from the list maintained by libwine.
+ * virtual_mutex must be held by caller.
+ */
+static void remove_reserved_area( void *addr, size_t size )
+{
+    struct file_view *view;
+
+    TRACE( "removing %p-%p\n", addr, (char *)addr + size );
+    mmap_remove_reserved_area( addr, size );
+
+    /* unmap areas not covered by an existing view */
+    WINE_RB_FOR_EACH_ENTRY( view, &views_tree, struct file_view, entry )
+    {
+        if ((char *)view->base >= (char *)addr + size) break;
+        if ((char *)view->base + view->size <= (char *)addr) continue;
+        if (view->base > addr) munmap( addr, (char *)view->base - (char *)addr );
+        if ((char *)view->base + view->size > (char *)addr + size) return;
+        size = (char *)addr + size - ((char *)view->base + view->size);
+        addr = (char *)view->base + view->size;
+    }
+    munmap( addr, size );
+}
+
+
+struct area_boundary
+{
+    void  *base;
+    size_t size;
+    void  *boundary;
+};
+
+/***********************************************************************
+ *           get_area_boundary_callback
+ *
+ * Get lowest boundary address between reserved area and non-reserved area
+ * in the specified region. If no boundaries are found, result is NULL.
+ * virtual_mutex must be held by caller.
+ */
+static int get_area_boundary_callback( void *start, SIZE_T size, void *arg )
+{
+    struct area_boundary *area = arg;
+    void *end = (char *)start + size;
+
+    area->boundary = NULL;
+    if (area->base >= end) return 0;
+    if ((char *)start >= (char *)area->base + area->size) return 1;
+    if (area->base >= start)
+    {
+        if ((char *)area->base + area->size > (char *)end)
+        {
+            area->boundary = end;
+            return 1;
+        }
+        return 0;
+    }
+    area->boundary = start;
+    return 1;
+}
+
+
+/***********************************************************************
+ *           unmap_area
+ *
+ * Unmap an area, or simply replace it by an empty mapping if it is
+ * in a reserved area. virtual_mutex must be held by caller.
+ */
+static inline void unmap_area( void *addr, size_t size )
+{
+    switch (mmap_is_in_reserved_area( addr, size ))
+    {
+    case -1: /* partially in a reserved area */
+    {
+        struct area_boundary area;
+        size_t lower_size;
+        area.base = addr;
+        area.size = size;
+        mmap_enum_reserved_areas( get_area_boundary_callback, &area, 0 );
+        assert( area.boundary );
+        lower_size = (char *)area.boundary - (char *)addr;
+        unmap_area( addr, lower_size );
+        unmap_area( area.boundary, size - lower_size );
+        break;
+    }
+    case 1:  /* in a reserved area */
+        anon_mmap_fixed( addr, size, PROT_NONE, MAP_NORESERVE );
+        break;
+    default:
+    case 0:  /* not in a reserved area */
+        if (is_beyond_limit( addr, size, user_space_limit ))
+            add_reserved_area( addr, size );
+        else
+            munmap( addr, size );
+        break;
+    }
+}
+
+
+/***********************************************************************
+ *           alloc_view
+ *
+ * Allocate a new view. virtual_mutex must be held by caller.
+ */
+static struct file_view *alloc_view(void)
+{
+    if (next_free_view)
+    {
+        struct file_view *ret = next_free_view;
+        next_free_view = *(struct file_view **)ret;
+        return ret;
+    }
+    if (view_block_start == view_block_end)
+    {
+        void *ptr = anon_mmap_alloc( view_block_size, PROT_READ | PROT_WRITE );
+        if (ptr == MAP_FAILED) return NULL;
+        view_block_start = ptr;
+        view_block_end = view_block_start + view_block_size / sizeof(*view_block_start);
+    }
+    return view_block_start++;
+}
+
+
+/***********************************************************************
+ *           delete_view
+ *
+ * Deletes a view. virtual_mutex must be held by caller.
+ */
+static void delete_view( struct file_view *view ) /* [in] View */
+{
+    if (!(view->protect & VPROT_SYSTEM)) unmap_area( view->base, view->size );
+    set_page_vprot( view->base, view->size, 0 );
+    if (mmap_is_in_reserved_area( view->base, view->size ))
+        free_ranges_remove_view( view );
+    wine_rb_remove( &views_tree, &view->entry );
+    *(struct file_view **)view = next_free_view;
+    next_free_view = view;
+}
+
+
+/***********************************************************************
+ *           create_view
+ *
+ * Create a view. virtual_mutex must be held by caller.
+ */
+static NTSTATUS create_view( struct file_view **view_ret, void *base, size_t size, unsigned int vprot )
+{
+    struct file_view *view;
+    int unix_prot = get_unix_prot( vprot );
+
+    assert( !((UINT_PTR)base & page_mask) );
+    assert( !(size & page_mask) );
+
+    /* Check for overlapping views. This can happen if the previous view
+     * was a system view that got unmapped behind our back. In that case
+     * we recover by simply deleting it. */
+
+    while ((view = find_view_range( base, size )))
+    {
+        TRACE( "overlapping view %p-%p for %p-%p\n",
+               view->base, (char *)view->base + view->size, base, (char *)base + size );
+        assert( view->protect & VPROT_SYSTEM );
+        delete_view( view );
+    }
+
+    if (!alloc_pages_vprot( base, size )) return STATUS_NO_MEMORY;
+
+    /* Create the view structure */
+
+    if (!(view = alloc_view()))
+    {
+        FIXME( "out of memory for %p-%p\n", base, (char *)base + size );
+        return STATUS_NO_MEMORY;
+    }
+
+    view->base    = base;
+    view->size    = size;
+    view->protect = vprot;
+    set_page_vprot( base, size, vprot );
+
+    wine_rb_put( &views_tree, view->base, &view->entry );
+    if (mmap_is_in_reserved_area( view->base, view->size ))
+        free_ranges_insert_view( view );
+
+    *view_ret = view;
+
+    if (force_exec_prot && (unix_prot & PROT_READ) && !(unix_prot & PROT_EXEC))
+    {
+        TRACE( "forcing exec permission on %p-%p\n", base, (char *)base + size - 1 );
+        mprotect( base, size, unix_prot | PROT_EXEC );
+    }
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           get_win32_prot
+ *
+ * Convert page protections to Win32 flags.
+ */
+static DWORD get_win32_prot( BYTE vprot, unsigned int map_prot )
+{
+    DWORD ret = VIRTUAL_Win32Flags[vprot & 0x0f];
+    if (vprot & VPROT_GUARD) ret |= PAGE_GUARD;
+    if (map_prot & SEC_NOCACHE) ret |= PAGE_NOCACHE;
+    return ret;
+}
+
+
+/***********************************************************************
+ *           get_vprot_flags
+ *
+ * Build page protections from Win32 flags.
+ */
+static NTSTATUS get_vprot_flags( DWORD protect, unsigned int *vprot, BOOL image )
+{
+    switch(protect & 0xff)
+    {
+    case PAGE_READONLY:
+        *vprot = VPROT_READ;
+        break;
+    case PAGE_READWRITE:
+        if (image)
+            *vprot = VPROT_READ | VPROT_WRITECOPY;
+        else
+            *vprot = VPROT_READ | VPROT_WRITE;
+        break;
+    case PAGE_WRITECOPY:
+        *vprot = VPROT_READ | VPROT_WRITECOPY;
+        break;
+    case PAGE_EXECUTE:
+        *vprot = VPROT_EXEC;
+        break;
+    case PAGE_EXECUTE_READ:
+        *vprot = VPROT_EXEC | VPROT_READ;
+        break;
+    case PAGE_EXECUTE_READWRITE:
+        if (image)
+            *vprot = VPROT_EXEC | VPROT_READ | VPROT_WRITECOPY;
+        else
+            *vprot = VPROT_EXEC | VPROT_READ | VPROT_WRITE;
+        break;
+    case PAGE_EXECUTE_WRITECOPY:
+        *vprot = VPROT_EXEC | VPROT_READ | VPROT_WRITECOPY;
+        break;
+    case PAGE_NOACCESS:
+        *vprot = 0;
+        break;
+    default:
+        return STATUS_INVALID_PAGE_PROTECTION;
+    }
+    if (protect & PAGE_GUARD) *vprot |= VPROT_GUARD;
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           mprotect_exec
+ *
+ * Wrapper for mprotect, adds PROT_EXEC if forced by force_exec_prot
+ */
+static inline int mprotect_exec( void *base, size_t size, int unix_prot )
+{
+    if (force_exec_prot && (unix_prot & PROT_READ) && !(unix_prot & PROT_EXEC))
+    {
+        TRACE( "forcing exec permission on %p-%p\n", base, (char *)base + size - 1 );
+        if (!mprotect( base, size, unix_prot | PROT_EXEC )) return 0;
+        /* exec + write may legitimately fail, in that case fall back to write only */
+        if (!(unix_prot & PROT_WRITE)) return -1;
+    }
+
+    return mprotect( base, size, unix_prot );
+}
+
+
+/***********************************************************************
+ *           mprotect_range
+ *
+ * Call mprotect on a page range, applying the protections from the per-page byte.
+ */
+static void mprotect_range( void *base, size_t size, BYTE set, BYTE clear )
+{
+    size_t i, count;
+    char *addr = ROUND_ADDR( base, page_mask );
+    int prot, next;
+
+    size = ROUND_SIZE( base, size );
+    prot = get_unix_prot( (get_page_vprot( addr ) & ~clear ) | set );
+    for (count = i = 1; i < size >> page_shift; i++, count++)
+    {
+        next = get_unix_prot( (get_page_vprot( addr + (count << page_shift) ) & ~clear) | set );
+        if (next == prot) continue;
+        mprotect_exec( addr, count << page_shift, prot );
+        addr += count << page_shift;
+        prot = next;
+        count = 0;
+    }
+    if (count) mprotect_exec( addr, count << page_shift, prot );
+}
+
+
+static void *wine_mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset)
+{
+#if defined(__APPLE__) && defined(__x86_64__)
+    // We use __x86_64__ and needs_wow64() as a proxy for Catalina-and-later,
+    // where mapping files with execute permissions can make Gatekeeper prompt the
+    // user.
+    if (!(flags & MAP_ANON) && fd >= 0 && prot & PROT_EXEC && needs_wow64())
+    {
+        void *ret = mmap(addr, len, prot & ~PROT_EXEC, flags, fd, offset);
+
+        if (ret != MAP_FAILED && mprotect(ret, len, prot))
+            WARN("failed to mprotect region: %d\n", errno);
+        return ret;
+    }
+#endif
+    return mmap(addr, len, prot, flags, fd, offset);
+}
+
+
+/***********************************************************************
+ *           set_vprot
+ *
+ * Change the protection of a range of pages.
+ */
+static BOOL set_vprot( struct file_view *view, void *base, size_t size, BYTE vprot )
+{
+    int unix_prot = get_unix_prot(vprot);
+
+    if (view->protect & VPROT_WRITEWATCH)
+    {
+        /* each page may need different protections depending on write watch flag */
+        set_page_vprot_bits( base, size, vprot & ~VPROT_WRITEWATCH, ~vprot & ~VPROT_WRITEWATCH );
+        mprotect_range( base, size, 0, 0 );
+        return TRUE;
+    }
+    if (mprotect_exec( base, size, unix_prot )) return FALSE;
+    set_page_vprot( base, size, vprot );
+    return TRUE;
+}
+
+
+/***********************************************************************
+ *           set_protection
+ *
+ * Set page protections on a range of pages
+ */
+static NTSTATUS set_protection( struct file_view *view, void *base, SIZE_T size, ULONG protect )
+{
+    unsigned int vprot;
+    NTSTATUS status;
+
+    if ((status = get_vprot_flags( protect, &vprot, view->protect & SEC_IMAGE ))) return status;
+    if (is_view_valloc( view ))
+    {
+        if (vprot & VPROT_WRITECOPY) return STATUS_INVALID_PAGE_PROTECTION;
+    }
+    else
+    {
+        BYTE access = vprot & (VPROT_READ | VPROT_WRITE | VPROT_EXEC);
+        if ((view->protect & access) != access) return STATUS_INVALID_PAGE_PROTECTION;
+    }
+
+    if (!set_vprot( view, base, size, vprot | VPROT_COMMITTED )) return STATUS_ACCESS_DENIED;
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           update_write_watches
+ */
+static void update_write_watches( void *base, size_t size, size_t accessed_size )
+{
+    TRACE( "updating watch %p-%p-%p\n", base, (char *)base + accessed_size, (char *)base + size );
+    /* clear write watch flag on accessed pages */
+    set_page_vprot_bits( base, accessed_size, 0, VPROT_WRITEWATCH );
+    /* restore page protections on the entire range */
+    mprotect_range( base, size, 0, 0 );
+}
+
+
+/***********************************************************************
+ *           reset_write_watches
+ *
+ * Reset write watches in a memory range.
+ */
+static void reset_write_watches( void *base, SIZE_T size )
+{
+    set_page_vprot_bits( base, size, VPROT_WRITEWATCH, 0 );
+    mprotect_range( base, size, 0, 0 );
+}
+
+
+/***********************************************************************
+ *           unmap_extra_space
+ *
+ * Release the extra memory while keeping the range starting on the granularity boundary.
+ */
+static inline void *unmap_extra_space( void *ptr, size_t total_size, size_t wanted_size )
+{
+    if ((ULONG_PTR)ptr & granularity_mask)
+    {
+        size_t extra = granularity_mask + 1 - ((ULONG_PTR)ptr & granularity_mask);
+        munmap( ptr, extra );
+        ptr = (char *)ptr + extra;
+        total_size -= extra;
+    }
+    if (total_size > wanted_size)
+        munmap( (char *)ptr + wanted_size, total_size - wanted_size );
+    return ptr;
+}
+
+
+struct alloc_area
+{
+    size_t size;
+    int    top_down;
+    void  *limit;
+    void  *result;
+};
+
+/***********************************************************************
+ *           alloc_reserved_area_callback
+ *
+ * Try to map some space inside a reserved area. Callback for mmap_enum_reserved_areas.
+ */
+static int alloc_reserved_area_callback( void *start, SIZE_T size, void *arg )
+{
+    struct alloc_area *alloc = arg;
+    void *end = (char *)start + size;
+
+    if (start < address_space_start) start = address_space_start;
+    if (is_beyond_limit( start, size, alloc->limit )) end = alloc->limit;
+    if (start >= end) return 0;
+
+    /* make sure we don't touch the preloader reserved range */
+    if (preload_reserve_end >= start)
+    {
+        if (preload_reserve_end >= end)
+        {
+            if (preload_reserve_start <= start) return 0;  /* no space in that area */
+            if (preload_reserve_start < end) end = preload_reserve_start;
+        }
+        else if (preload_reserve_start <= start) start = preload_reserve_end;
+        else
+        {
+            /* range is split in two by the preloader reservation, try first part */
+            if ((alloc->result = find_reserved_free_area( start, preload_reserve_start, alloc->size,
+                                                          alloc->top_down )))
+                return 1;
+            /* then fall through to try second part */
+            start = preload_reserve_end;
+        }
+    }
+    if ((alloc->result = find_reserved_free_area( start, end, alloc->size, alloc->top_down )))
+        return 1;
+
+    return 0;
+}
+
+/***********************************************************************
+ *           map_fixed_area
+ *
+ * mmap the fixed memory area.
+ * virtual_mutex must be held by caller.
+ */
+static NTSTATUS map_fixed_area( void *base, size_t size, unsigned int vprot )
+{
+    void *ptr;
+
+    switch (mmap_is_in_reserved_area( base, size ))
+    {
+    case -1: /* partially in a reserved area */
+    {
+        NTSTATUS status;
+        struct area_boundary area;
+        size_t lower_size;
+        area.base = base;
+        area.size = size;
+        mmap_enum_reserved_areas( get_area_boundary_callback, &area, 0 );
+        assert( area.boundary );
+        lower_size = (char *)area.boundary - (char *)base;
+        status = map_fixed_area( base, lower_size, vprot );
+        if (status == STATUS_SUCCESS)
+        {
+            status = map_fixed_area( area.boundary, size - lower_size, vprot);
+            if (status != STATUS_SUCCESS) unmap_area( base, lower_size );
+        }
+        return status;
+    }
+    case 0:  /* not in a reserved area, do a normal allocation */
+        if ((ptr = anon_mmap_tryfixed( base, size, get_unix_prot(vprot), 0 )) == MAP_FAILED)
+        {
+            if (errno == ENOMEM) return STATUS_NO_MEMORY;
+            if (errno == EEXIST) return STATUS_CONFLICTING_ADDRESSES;
+            return STATUS_INVALID_PARAMETER;
+        }
+        break;
+
+    default:
+    case 1:  /* in a reserved area, make sure the address is available */
+        if (find_view_range( base, size )) return STATUS_CONFLICTING_ADDRESSES;
+        /* replace the reserved area by our mapping */
+        if ((ptr = anon_mmap_fixed( base, size, get_unix_prot(vprot), 0 )) != base)
+            return STATUS_INVALID_PARAMETER;
+        break;
+    }
+    if (is_beyond_limit( ptr, size, working_set_limit )) working_set_limit = address_space_limit;
+    return STATUS_SUCCESS;
+}
+
+/***********************************************************************
+ *           map_view
+ *
+ * Create a view and mmap the corresponding memory area.
+ * virtual_mutex must be held by caller.
+ */
+static NTSTATUS map_view( struct file_view **view_ret, void *base, size_t size,
+                          int top_down, unsigned int vprot, ULONG_PTR zero_bits )
+{
+    void *ptr;
+    NTSTATUS status;
+
+    if (base)
+    {
+        if (is_beyond_limit( base, size, address_space_limit ))
+            return STATUS_WORKING_SET_LIMIT_RANGE;
+        if (is_beyond_limit( base, size, (void*)get_zero_bits_mask( zero_bits ) ))
+            return STATUS_CONFLICTING_ADDRESSES;
+        status = map_fixed_area( base, size, vprot );
+        if (status != STATUS_SUCCESS) return status;
+        ptr = base;
+    }
+    else
+    {
+        size_t view_size = size + granularity_mask + 1;
+        struct alloc_area alloc;
+
+        alloc.size = size;
+        alloc.top_down = top_down;
+        alloc.limit = (void*)(get_zero_bits_mask( zero_bits ) & (UINT_PTR)user_space_limit);
+
+        if (mmap_enum_reserved_areas( alloc_reserved_area_callback, &alloc, top_down ))
+        {
+            ptr = alloc.result;
+            TRACE( "got mem in reserved area %p-%p\n", ptr, (char *)ptr + size );
+            if (anon_mmap_fixed( ptr, size, get_unix_prot(vprot), 0 ) != ptr)
+                return STATUS_INVALID_PARAMETER;
+            goto done;
+        }
+
+        if (zero_bits)
+        {
+            if (!(ptr = map_free_area( address_space_start, alloc.limit, size,
+                                       top_down, get_unix_prot(vprot) )))
+                return STATUS_NO_MEMORY;
+            TRACE( "got mem with map_free_area %p-%p\n", ptr, (char *)ptr + size );
+            goto done;
+        }
+
+        for (;;)
+        {
+            if ((ptr = anon_mmap_alloc( view_size, get_unix_prot(vprot) )) == MAP_FAILED)
+            {
+                if (errno == ENOMEM) return STATUS_NO_MEMORY;
+                return STATUS_INVALID_PARAMETER;
+            }
+            TRACE( "got mem with anon mmap %p-%p\n", ptr, (char *)ptr + size );
+            /* if we got something beyond the user limit, unmap it and retry */
+            if (is_beyond_limit( ptr, view_size, user_space_limit )) add_reserved_area( ptr, view_size );
+            else break;
+        }
+        ptr = unmap_extra_space( ptr, view_size, size );
+    }
+done:
+    status = create_view( view_ret, ptr, size, vprot );
+    if (status != STATUS_SUCCESS) unmap_area( ptr, size );
+    return status;
+}
+
+
+/***********************************************************************
+ *           map_file_into_view
+ *
+ * Wrapper for mmap() to map a file into a view, falling back to read if mmap fails.
+ * virtual_mutex must be held by caller.
+ */
+static NTSTATUS map_file_into_view( struct file_view *view, int fd, size_t start, size_t size,
+                                    off_t offset, unsigned int vprot, BOOL removable )
+{
+    void *ptr;
+    int prot = get_unix_prot( vprot | VPROT_COMMITTED /* make sure it is accessible */ );
+    unsigned int flags = MAP_FIXED | ((vprot & VPROT_WRITECOPY) ? MAP_PRIVATE : MAP_SHARED);
+
+    assert( start < view->size );
+    assert( start + size <= view->size );
+
+    if (force_exec_prot && (vprot & VPROT_READ))
+    {
+        TRACE( "forcing exec permission on mapping %p-%p\n",
+               (char *)view->base + start, (char *)view->base + start + size - 1 );
+        prot |= PROT_EXEC;
+    }
+
+    /* only try mmap if media is not removable (or if we require write access) */
+    if (!removable || (flags & MAP_SHARED))
+    {
+try_again:
+        if (wine_mmap( (char *)view->base + start, size, prot, flags, fd, offset ) != MAP_FAILED)
+            goto done;
+
+        switch (errno)
+        {
+        case EINVAL:  /* file offset is not page-aligned, fall back to read() */
+            if (flags & MAP_SHARED) return STATUS_INVALID_PARAMETER;
+            break;
+        case ENOEXEC:
+        case ENODEV:  /* filesystem doesn't support mmap(), fall back to read() */
+            if (vprot & VPROT_WRITE)
+            {
+                ERR( "shared writable mmap not supported, broken filesystem?\n" );
+                return STATUS_NOT_SUPPORTED;
+            }
+            break;
+        case EACCES:
+        case EPERM:  /* noexec filesystem, fall back to read() */
+            if (flags & MAP_SHARED)
+            {
+                if (prot & PROT_EXEC)
+                {
+                    if (force_exec_prot && (vprot & (VPROT_WRITE|VPROT_EXEC)) == VPROT_WRITE)
+                    {
+                        /* exec + write may legitimately fail, in that case fall back to write only */
+                        prot &= ~PROT_EXEC;
+                        goto try_again;
+                    }
+                    ERR( "failed to set PROT_EXEC on file map, noexec filesystem?\n" );
+                }
+                return STATUS_ACCESS_DENIED;
+            }
+            if (prot & PROT_EXEC) WARN( "failed to set PROT_EXEC on file map, noexec filesystem?\n" );
+            break;
+        default:
+            return STATUS_NO_MEMORY;
+        }
+    }
+
+    /* Reserve the memory with an anonymous mmap */
+    ptr = anon_mmap_fixed( (char *)view->base + start, size, PROT_READ | PROT_WRITE, 0 );
+    if (ptr == MAP_FAILED) return STATUS_NO_MEMORY;
+    /* Now read in the file */
+    pread( fd, ptr, size, offset );
+    if (prot != (PROT_READ|PROT_WRITE)) mprotect( ptr, size, prot );  /* Set the right protection */
+done:
+    set_page_vprot( (char *)view->base + start, size, vprot );
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           get_committed_size
+ *
+ * Get the size of the committed range with equal masked vprot bytes starting at base.
+ * Also return the protections for the first page.
+ */
+static SIZE_T get_committed_size( struct file_view *view, void *base, BYTE *vprot, BYTE vprot_mask )
+{
+    SIZE_T offset, size;
+
+    base = ROUND_ADDR( base, page_mask );
+    offset = (char *)base - (char *)view->base;
+
+    if (view->protect & SEC_RESERVE)
+    {
+        size = 0;
+
+        *vprot = get_page_vprot( base );
+
+        SERVER_START_REQ( get_mapping_committed_range )
+        {
+            req->base   = wine_server_client_ptr( view->base );
+            req->offset = offset;
+            if (!wine_server_call( req ))
+            {
+                size = reply->size;
+                if (reply->committed)
+                {
+                    *vprot |= VPROT_COMMITTED;
+                    set_page_vprot_bits( base, size, VPROT_COMMITTED, 0 );
+                }
+            }
+        }
+        SERVER_END_REQ;
+
+        if (!size || !(vprot_mask & ~VPROT_COMMITTED)) return size;
+    }
+    else size = view->size - offset;
+
+    return get_vprot_range_size( base, size, vprot_mask, vprot );
+}
+
+
+/***********************************************************************
+ *           decommit_pages
+ *
+ * Decommit some pages of a given view.
+ * virtual_mutex must be held by caller.
+ */
+static NTSTATUS decommit_pages( struct file_view *view, size_t start, size_t size )
+{
+    if (!size) size = view->size;
+    if (anon_mmap_fixed( (char *)view->base + start, size, PROT_NONE, 0 ) != MAP_FAILED)
+    {
+        set_page_vprot_bits( (char *)view->base + start, size, 0, VPROT_COMMITTED );
+        return STATUS_SUCCESS;
+    }
+    return STATUS_NO_MEMORY;
+}
+
+
+/***********************************************************************
+ *           allocate_dos_memory
+ *
+ * Allocate the DOS memory range.
+ */
+static NTSTATUS allocate_dos_memory( struct file_view **view, unsigned int vprot )
+{
+    size_t size;
+    void *addr = NULL;
+    void * const low_64k = (void *)0x10000;
+    const size_t dosmem_size = 0x110000;
+    int unix_prot = get_unix_prot( vprot );
+
+    /* check for existing view */
+
+    if (find_view_range( 0, dosmem_size )) return STATUS_CONFLICTING_ADDRESSES;
+
+    /* check without the first 64K */
+
+    if (mmap_is_in_reserved_area( low_64k, dosmem_size - 0x10000 ) != 1)
+    {
+        addr = anon_mmap_tryfixed( low_64k, dosmem_size - 0x10000, unix_prot, 0 );
+        if (addr == MAP_FAILED) return map_view( view, NULL, dosmem_size, FALSE, vprot, 0 );
+    }
+
+    /* now try to allocate the low 64K too */
+
+    if (mmap_is_in_reserved_area( NULL, 0x10000 ) != 1)
+    {
+        addr = anon_mmap_tryfixed( (void *)page_size, 0x10000 - page_size, unix_prot, 0 );
+        if (addr != MAP_FAILED)
+        {
+            if (!anon_mmap_fixed( NULL, page_size, unix_prot, 0 ))
+            {
+                addr = NULL;
+                TRACE( "successfully mapped low 64K range\n" );
+            }
+            else TRACE( "failed to map page 0\n" );
+        }
+        else
+        {
+            addr = low_64k;
+            TRACE( "failed to map low 64K range\n" );
+        }
+    }
+
+    /* now reserve the whole range */
+
+    size = (char *)dosmem_size - (char *)addr;
+    anon_mmap_fixed( addr, size, unix_prot, 0 );
+    return create_view( view, addr, size, vprot );
+}
+
+
+/***********************************************************************
+ *           map_pe_header
+ *
+ * Map the header of a PE file into memory.
+ */
+static NTSTATUS map_pe_header( void *ptr, size_t size, int fd, BOOL *removable )
+{
+    if (!size) return STATUS_INVALID_IMAGE_FORMAT;
+
+    if (!*removable)
+    {
+        if (wine_mmap( ptr, size, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_FIXED|MAP_PRIVATE, fd, 0 ) != MAP_FAILED)
+            return STATUS_SUCCESS;
+
+        switch (errno)
+        {
+        case EPERM:
+        case EACCES:
+            WARN( "noexec file system, falling back to read\n" );
+            break;
+        case ENOEXEC:
+        case ENODEV:
+            WARN( "file system doesn't support mmap, falling back to read\n" );
+            break;
+        default:
+            return STATUS_NO_MEMORY;
+        }
+        *removable = TRUE;
+    }
+    pread( fd, ptr, size, 0 );
+    return STATUS_SUCCESS;  /* page protections will be updated later */
+}
+
+
+/***********************************************************************
+ *           map_image_into_view
+ *
+ * Map an executable (PE format) image into an existing view.
+ * virtual_mutex must be held by caller.
+ */
+static NTSTATUS map_image_into_view( struct file_view *view, const WCHAR *filename, int fd, void *orig_base,
+                                     SIZE_T header_size, ULONG image_flags, int shared_fd, BOOL removable )
+{
+    IMAGE_DOS_HEADER *dos;
+    IMAGE_NT_HEADERS *nt;
+    IMAGE_SECTION_HEADER sections[96];
+    IMAGE_SECTION_HEADER *sec;
+    IMAGE_DATA_DIRECTORY *imports;
+    NTSTATUS status = STATUS_CONFLICTING_ADDRESSES;
+    int i;
+    off_t pos;
+    struct stat st;
+    char *header_end, *header_start;
+    char *ptr = view->base;
+    SIZE_T total_size = view->size;
+
+    TRACE_(module)( "mapping PE file %s at %p-%p\n", debugstr_w(filename), ptr, ptr + total_size );
+
+    /* map the header */
+
+    fstat( fd, &st );
+    header_size = min( header_size, st.st_size );
+    if ((status = map_pe_header( view->base, header_size, fd, &removable ))) return status;
+
+    status = STATUS_INVALID_IMAGE_FORMAT;  /* generic error */
+    dos = (IMAGE_DOS_HEADER *)ptr;
+    nt = (IMAGE_NT_HEADERS *)(ptr + dos->e_lfanew);
+    header_end = ptr + ROUND_SIZE( 0, header_size );
+    memset( ptr + header_size, 0, header_end - (ptr + header_size) );
+    if ((char *)(nt + 1) > header_end) return status;
+    header_start = (char*)&nt->OptionalHeader+nt->FileHeader.SizeOfOptionalHeader;
+    if (nt->FileHeader.NumberOfSections > ARRAY_SIZE( sections )) return status;
+    if (header_start + sizeof(*sections) * nt->FileHeader.NumberOfSections > header_end) return status;
+    /* Some applications (e.g. the Steam version of Borderlands) map over the top of the section headers,
+     * copying the headers into local memory is necessary to properly load such applications. */
+    memcpy(sections, header_start, sizeof(*sections) * nt->FileHeader.NumberOfSections);
+    sec = sections;
+
+    imports = nt->OptionalHeader.DataDirectory + IMAGE_DIRECTORY_ENTRY_IMPORT;
+    if (!imports->Size || !imports->VirtualAddress) imports = NULL;
+
+    /* check for non page-aligned binary */
+
+    if (image_flags & IMAGE_FLAGS_ImageMappedFlat)
+    {
+        /* unaligned sections, this happens for native subsystem binaries */
+        /* in that case Windows simply maps in the whole file */
+
+        total_size = min( total_size, ROUND_SIZE( 0, st.st_size ));
+        if (map_file_into_view( view, fd, 0, total_size, 0, VPROT_COMMITTED | VPROT_READ | VPROT_WRITECOPY,
+                                removable ) != STATUS_SUCCESS) return status;
+
+        /* check that all sections are loaded at the right offset */
+        if (nt->OptionalHeader.FileAlignment != nt->OptionalHeader.SectionAlignment) return status;
+        for (i = 0; i < nt->FileHeader.NumberOfSections; i++)
+        {
+            if (sec[i].VirtualAddress != sec[i].PointerToRawData)
+                return status;  /* Windows refuses to load in that case too */
+        }
+
+        /* set the image protections */
+        set_vprot( view, ptr, total_size, VPROT_COMMITTED | VPROT_READ | VPROT_WRITECOPY | VPROT_EXEC );
+
+        /* no relocations are performed on non page-aligned binaries */
+        return STATUS_SUCCESS;
+    }
+
+
+    /* map all the sections */
+
+    for (i = pos = 0; i < nt->FileHeader.NumberOfSections; i++, sec++)
+    {
+        static const SIZE_T sector_align = 0x1ff;
+        SIZE_T map_size, file_start, file_size, end;
+
+        if (!sec->Misc.VirtualSize)
+            map_size = ROUND_SIZE( 0, sec->SizeOfRawData );
+        else
+            map_size = ROUND_SIZE( 0, sec->Misc.VirtualSize );
+
+        /* file positions are rounded to sector boundaries regardless of OptionalHeader.FileAlignment */
+        file_start = sec->PointerToRawData & ~sector_align;
+        file_size = (sec->SizeOfRawData + (sec->PointerToRawData & sector_align) + sector_align) & ~sector_align;
+        if (file_size > map_size) file_size = map_size;
+
+        /* a few sanity checks */
+        end = sec->VirtualAddress + ROUND_SIZE( sec->VirtualAddress, map_size );
+        if (sec->VirtualAddress > total_size || end > total_size || end < sec->VirtualAddress)
+        {
+            WARN_(module)( "%s section %.8s too large (%x+%lx/%lx)\n",
+                           debugstr_w(filename), sec->Name, sec->VirtualAddress, map_size, total_size );
+            return status;
+        }
+
+        if ((sec->Characteristics & IMAGE_SCN_MEM_SHARED) &&
+            (sec->Characteristics & IMAGE_SCN_MEM_WRITE))
+        {
+            TRACE_(module)( "%s mapping shared section %.8s at %p off %x (%x) size %lx (%lx) flags %x\n",
+                            debugstr_w(filename), sec->Name, ptr + sec->VirtualAddress,
+                            sec->PointerToRawData, (int)pos, file_size, map_size,
+                            sec->Characteristics );
+            if (map_file_into_view( view, shared_fd, sec->VirtualAddress, map_size, pos,
+                                    VPROT_COMMITTED | VPROT_READ | VPROT_WRITE, FALSE ) != STATUS_SUCCESS)
+            {
+                ERR_(module)( "Could not map %s shared section %.8s\n", debugstr_w(filename), sec->Name );
+                return status;
+            }
+
+            /* check if the import directory falls inside this section */
+            if (imports && imports->VirtualAddress >= sec->VirtualAddress &&
+                imports->VirtualAddress < sec->VirtualAddress + map_size)
+            {
+                UINT_PTR base = imports->VirtualAddress & ~page_mask;
+                UINT_PTR end = base + ROUND_SIZE( imports->VirtualAddress, imports->Size );
+                if (end > sec->VirtualAddress + map_size) end = sec->VirtualAddress + map_size;
+                if (end > base)
+                    map_file_into_view( view, shared_fd, base, end - base,
+                                        pos + (base - sec->VirtualAddress),
+                                        VPROT_COMMITTED | VPROT_READ | VPROT_WRITECOPY, FALSE );
+            }
+            pos += map_size;
+            continue;
+        }
+
+        TRACE_(module)( "mapping %s section %.8s at %p off %x size %x virt %x flags %x\n",
+                        debugstr_w(filename), sec->Name, ptr + sec->VirtualAddress,
+                        sec->PointerToRawData, sec->SizeOfRawData,
+                        sec->Misc.VirtualSize, sec->Characteristics );
+
+        if (!sec->PointerToRawData || !file_size) continue;
+
+        /* Note: if the section is not aligned properly map_file_into_view will magically
+         *       fall back to read(), so we don't need to check anything here.
+         */
+        end = file_start + file_size;
+        if (sec->PointerToRawData >= st.st_size ||
+            end > ((st.st_size + sector_align) & ~sector_align) ||
+            end < file_start ||
+            map_file_into_view( view, fd, sec->VirtualAddress, file_size, file_start,
+                                VPROT_COMMITTED | VPROT_READ | VPROT_WRITECOPY,
+                                removable ) != STATUS_SUCCESS)
+        {
+            ERR_(module)( "Could not map %s section %.8s, file probably truncated\n",
+                          debugstr_w(filename), sec->Name );
+            return status;
+        }
+
+        if (file_size & page_mask)
+        {
+            end = ROUND_SIZE( 0, file_size );
+            if (end > map_size) end = map_size;
+            TRACE_(module)("clearing %p - %p\n",
+                           ptr + sec->VirtualAddress + file_size,
+                           ptr + sec->VirtualAddress + end );
+            memset( ptr + sec->VirtualAddress + file_size, 0, end - file_size );
+        }
+    }
+
+    /* set the image protections */
+
+    set_vprot( view, ptr, ROUND_SIZE( 0, header_size ), VPROT_COMMITTED | VPROT_READ );
+
+    sec = sections;
+    for (i = 0; i < nt->FileHeader.NumberOfSections; i++, sec++)
+    {
+        SIZE_T size;
+        BYTE vprot = VPROT_COMMITTED;
+
+        if (sec->Misc.VirtualSize)
+            size = ROUND_SIZE( sec->VirtualAddress, sec->Misc.VirtualSize );
+        else
+            size = ROUND_SIZE( sec->VirtualAddress, sec->SizeOfRawData );
+
+        if (sec->Characteristics & IMAGE_SCN_MEM_READ)    vprot |= VPROT_READ;
+        if (sec->Characteristics & IMAGE_SCN_MEM_WRITE)   vprot |= VPROT_WRITECOPY;
+        if (sec->Characteristics & IMAGE_SCN_MEM_EXECUTE) vprot |= VPROT_EXEC;
+
+        if (!set_vprot( view, ptr + sec->VirtualAddress, size, vprot ) && (vprot & VPROT_EXEC))
+            ERR( "failed to set %08x protection on %s section %.8s, noexec filesystem?\n",
+                 sec->Characteristics, debugstr_w(filename), sec->Name );
+    }
+
+#ifdef VALGRIND_LOAD_PDB_DEBUGINFO
+    VALGRIND_LOAD_PDB_DEBUGINFO(fd, ptr, total_size, ptr - (char *)orig_base);
+#endif
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *             get_mapping_info
+ */
+static NTSTATUS get_mapping_info( HANDLE handle, ACCESS_MASK access, unsigned int *sec_flags,
+                                  mem_size_t *full_size, HANDLE *shared_file, pe_image_info_t **info )
+{
+    pe_image_info_t *image_info;
+    SIZE_T total, size = 1024;
+    NTSTATUS status;
+
+    for (;;)
+    {
+        if (!(image_info = malloc( size ))) return STATUS_NO_MEMORY;
+
+        SERVER_START_REQ( get_mapping_info )
+        {
+            req->handle = wine_server_obj_handle( handle );
+            req->access = access;
+            wine_server_set_reply( req, image_info, size );
+            status = wine_server_call( req );
+            *sec_flags   = reply->flags;
+            *full_size   = reply->size;
+            total        = reply->total;
+            *shared_file = wine_server_ptr_handle( reply->shared_file );
+        }
+        SERVER_END_REQ;
+        if (!status && total <= size - sizeof(WCHAR)) break;
+        free( image_info );
+        if (status) return status;
+        if (*shared_file) NtClose( *shared_file );
+        size = total + sizeof(WCHAR);
+    }
+
+    if (total)
+    {
+        WCHAR *filename = (WCHAR *)(image_info + 1);
+
+        assert( total >= sizeof(*image_info) );
+        total -= sizeof(*image_info);
+        filename[total / sizeof(WCHAR)] = 0;
+        *info = image_info;
+    }
+    else free( image_info );
+
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *             virtual_map_image
+ *
+ * Map a PE image section into memory.
+ */
+static NTSTATUS virtual_map_image( HANDLE mapping, ACCESS_MASK access, void **addr_ptr, SIZE_T *size_ptr,
+                                   ULONG_PTR zero_bits, HANDLE shared_file, ULONG alloc_type,
+                                   pe_image_info_t *image_info, WCHAR *filename, BOOL is_builtin )
+{
+    unsigned int vprot = SEC_IMAGE | SEC_FILE | VPROT_COMMITTED | VPROT_READ | VPROT_EXEC | VPROT_WRITECOPY;
+    int unix_fd = -1, needs_close;
+    int shared_fd = -1, shared_needs_close = 0;
+    SIZE_T size = image_info->map_size;
+    struct file_view *view;
+    NTSTATUS status;
+    sigset_t sigset;
+    void *base;
+
+    if ((status = server_get_unix_fd( mapping, 0, &unix_fd, &needs_close, NULL, NULL )))
+        return status;
+
+    if (shared_file && ((status = server_get_unix_fd( shared_file, FILE_READ_DATA|FILE_WRITE_DATA,
+                                                      &shared_fd, &shared_needs_close, NULL, NULL ))))
+    {
+        if (needs_close) close( unix_fd );
+        return status;
+    }
+
+    status = STATUS_INVALID_PARAMETER;
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    base = wine_server_get_ptr( image_info->base );
+    if ((ULONG_PTR)base != image_info->base) base = NULL;
+
+    if ((char *)base >= (char *)address_space_start)  /* make sure the DOS area remains free */
+        status = map_view( &view, base, size, alloc_type & MEM_TOP_DOWN, vprot, zero_bits );
+
+    if (status) status = map_view( &view, NULL, size, alloc_type & MEM_TOP_DOWN, vprot, zero_bits );
+    if (status) goto done;
+
+    status = map_image_into_view( view, filename, unix_fd, base, image_info->header_size,
+                                  image_info->image_flags, shared_fd, needs_close );
+    if (status == STATUS_SUCCESS)
+    {
+        SERVER_START_REQ( map_view )
+        {
+            req->mapping = wine_server_obj_handle( mapping );
+            req->access  = access;
+            req->base    = wine_server_client_ptr( view->base );
+            req->size    = size;
+            status = wine_server_call( req );
+        }
+        SERVER_END_REQ;
+    }
+    if (status >= 0)
+    {
+        if (is_builtin) add_builtin_module( view->base, NULL );
+        *addr_ptr = view->base;
+        *size_ptr = size;
+        VIRTUAL_DEBUG_DUMP_VIEW( view );
+    }
+    else delete_view( view );
+
+done:
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    if (needs_close) close( unix_fd );
+    if (shared_needs_close) close( shared_fd );
+    return status;
+}
+
+
+/***********************************************************************
+ *             virtual_map_section
+ *
+ * Map a file section into memory.
+ */
+static NTSTATUS virtual_map_section( HANDLE handle, PVOID *addr_ptr, ULONG_PTR zero_bits,
+                                     SIZE_T commit_size, const LARGE_INTEGER *offset_ptr, SIZE_T *size_ptr,
+                                     ULONG alloc_type, ULONG protect )
+{
+    NTSTATUS res;
+    mem_size_t full_size;
+    ACCESS_MASK access;
+    SIZE_T size;
+    pe_image_info_t *image_info = NULL;
+    WCHAR *filename;
+    void *base;
+    int unix_handle = -1, needs_close;
+    unsigned int vprot, sec_flags;
+    struct file_view *view;
+    HANDLE shared_file;
+    LARGE_INTEGER offset;
+    sigset_t sigset;
+
+    switch(protect)
+    {
+    case PAGE_NOACCESS:
+    case PAGE_READONLY:
+    case PAGE_WRITECOPY:
+        access = SECTION_MAP_READ;
+        break;
+    case PAGE_READWRITE:
+        access = SECTION_MAP_WRITE;
+        break;
+    case PAGE_EXECUTE:
+    case PAGE_EXECUTE_READ:
+    case PAGE_EXECUTE_WRITECOPY:
+        access = SECTION_MAP_READ | SECTION_MAP_EXECUTE;
+        break;
+    case PAGE_EXECUTE_READWRITE:
+        access = SECTION_MAP_WRITE | SECTION_MAP_EXECUTE;
+        break;
+    default:
+        return STATUS_INVALID_PAGE_PROTECTION;
+    }
+
+    res = get_mapping_info( handle, access, &sec_flags, &full_size, &shared_file, &image_info );
+    if (res) return res;
+
+    if (image_info)
+    {
+        filename = (WCHAR *)(image_info + 1);
+        /* check if we can replace that mapping with the builtin */
+        res = load_builtin( image_info, filename, addr_ptr, size_ptr, zero_bits );
+        if (res == STATUS_IMAGE_ALREADY_LOADED ||
+            is_beyond_limit( (void *)image_info->base, image_info->map_size, (void *)get_zero_bits_mask( zero_bits ) ))
+            res = virtual_map_image( handle, access, addr_ptr, size_ptr, zero_bits, shared_file,
+                                     alloc_type, image_info, filename, FALSE );
+        if (shared_file) NtClose( shared_file );
+        free( image_info );
+        return res;
+    }
+
+    base = *addr_ptr;
+    offset.QuadPart = offset_ptr ? offset_ptr->QuadPart : 0;
+    if (offset.QuadPart >= full_size) return STATUS_INVALID_PARAMETER;
+    if (*size_ptr)
+    {
+        size = *size_ptr;
+        if (size > full_size - offset.QuadPart) return STATUS_INVALID_VIEW_SIZE;
+    }
+    else
+    {
+        size = full_size - offset.QuadPart;
+        if (size != full_size - offset.QuadPart)  /* truncated */
+        {
+            WARN( "Files larger than 4Gb (%s) not supported on this platform\n",
+                  wine_dbgstr_longlong(full_size) );
+            return STATUS_INVALID_PARAMETER;
+        }
+    }
+    if (!(size = ROUND_SIZE( 0, size ))) return STATUS_INVALID_PARAMETER;  /* wrap-around */
+
+    get_vprot_flags( protect, &vprot, FALSE );
+    vprot |= sec_flags;
+    if (!(sec_flags & SEC_RESERVE)) vprot |= VPROT_COMMITTED;
+
+    if ((res = server_get_unix_fd( handle, 0, &unix_handle, &needs_close, NULL, NULL ))) return res;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    res = map_view( &view, base, size, alloc_type & MEM_TOP_DOWN, vprot, zero_bits );
+    if (res) goto done;
+
+    TRACE( "handle=%p size=%lx offset=%x%08x\n", handle, size, offset.u.HighPart, offset.u.LowPart );
+    res = map_file_into_view( view, unix_handle, 0, size, offset.QuadPart, vprot, needs_close );
+    if (res == STATUS_SUCCESS)
+    {
+        SERVER_START_REQ( map_view )
+        {
+            req->mapping = wine_server_obj_handle( handle );
+            req->access  = access;
+            req->base    = wine_server_client_ptr( view->base );
+            req->size    = size;
+            req->start   = offset.QuadPart;
+            res = wine_server_call( req );
+        }
+        SERVER_END_REQ;
+    }
+    else ERR( "mapping %p %lx %x%08x failed\n", view->base, size, offset.u.HighPart, offset.u.LowPart );
+
+    if (res >= 0)
+    {
+        *addr_ptr = view->base;
+        *size_ptr = size;
+        VIRTUAL_DEBUG_DUMP_VIEW( view );
+    }
+    else delete_view( view );
+
+done:
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    if (needs_close) close( unix_handle );
+    return res;
+}
+
+
+struct alloc_virtual_heap
+{
+    void  *base;
+    size_t size;
+};
+
+/* callback for mmap_enum_reserved_areas to allocate space for the virtual heap */
+static int alloc_virtual_heap( void *base, SIZE_T size, void *arg )
+{
+    struct alloc_virtual_heap *alloc = arg;
+    void *end = (char *)base + size;
+
+    if (is_beyond_limit( base, size, address_space_limit )) address_space_limit = (char *)base + size;
+    if (is_win64 && base < (void *)0x80000000) return 0;
+    if (preload_reserve_end >= end)
+    {
+        if (preload_reserve_start <= base) return 0;  /* no space in that area */
+        if (preload_reserve_start < end) end = preload_reserve_start;
+    }
+    else if (preload_reserve_end > base)
+    {
+        if (preload_reserve_start <= base) base = preload_reserve_end;
+        else if ((char *)end - (char *)preload_reserve_end >= alloc->size) base = preload_reserve_end;
+        else end = preload_reserve_start;
+    }
+    if ((char *)end - (char *)base < alloc->size) return 0;
+    alloc->base = anon_mmap_fixed( (char *)end - alloc->size, alloc->size, PROT_READ|PROT_WRITE, 0 );
+    return (alloc->base != MAP_FAILED);
+}
+
+/***********************************************************************
+ *           virtual_init
+ */
+void virtual_init(void)
+{
+    const struct preload_info **preload_info = dlsym( RTLD_DEFAULT, "wine_main_preload_info" );
+    const char *preload = getenv( "WINEPRELOADRESERVE" );
+    struct alloc_virtual_heap alloc_views;
+    size_t size;
+    int i;
+    pthread_mutexattr_t attr;
+
+    pthread_mutexattr_init( &attr );
+    pthread_mutexattr_settype( &attr, PTHREAD_MUTEX_RECURSIVE );
+    pthread_mutex_init( &virtual_mutex, &attr );
+    pthread_mutexattr_destroy( &attr );
+
+    if (preload_info && *preload_info)
+        for (i = 0; (*preload_info)[i].size; i++)
+            mmap_add_reserved_area( (*preload_info)[i].addr, (*preload_info)[i].size );
+
+    mmap_init( preload_info ? *preload_info : NULL );
+
+    if ((preload = getenv("WINEPRELOADRESERVE")))
+    {
+        unsigned long start, end;
+        if (sscanf( preload, "%lx-%lx", &start, &end ) == 2)
+        {
+            preload_reserve_start = (void *)start;
+            preload_reserve_end = (void *)end;
+            /* some apps start inside the DOS area */
+            if (preload_reserve_start)
+                address_space_start = min( address_space_start, preload_reserve_start );
+        }
+    }
+
+    /* try to find space in a reserved area for the views and pages protection table */
+#ifdef _WIN64
+    pages_vprot_size = ((size_t)address_space_limit >> page_shift >> pages_vprot_shift) + 1;
+    alloc_views.size = 2 * view_block_size + pages_vprot_size * sizeof(*pages_vprot);
+#else
+    alloc_views.size = 2 * view_block_size + (1U << (32 - page_shift));
+#endif
+    if (mmap_enum_reserved_areas( alloc_virtual_heap, &alloc_views, 1 ))
+        mmap_remove_reserved_area( alloc_views.base, alloc_views.size );
+    else
+        alloc_views.base = anon_mmap_alloc( alloc_views.size, PROT_READ | PROT_WRITE );
+
+    assert( alloc_views.base != MAP_FAILED );
+    view_block_start = alloc_views.base;
+    view_block_end = view_block_start + view_block_size / sizeof(*view_block_start);
+    free_ranges = (void *)((char *)alloc_views.base + view_block_size);
+    pages_vprot = (void *)((char *)alloc_views.base + 2 * view_block_size);
+    wine_rb_init( &views_tree, compare_view );
+
+    free_ranges[0].base = (void *)0;
+    free_ranges[0].end = (void *)~0;
+    free_ranges_end = free_ranges + 1;
+
+    /* make the DOS area accessible (except the low 64K) to hide bugs in broken apps like Excel 2003 */
+    size = (char *)address_space_start - (char *)0x10000;
+    if (size && mmap_is_in_reserved_area( (void*)0x10000, size ) == 1)
+        anon_mmap_fixed( (void *)0x10000, size, PROT_READ | PROT_WRITE, 0 );
+}
+
+
+/***********************************************************************
+ *           get_system_affinity_mask
+ */
+ULONG_PTR get_system_affinity_mask(void)
+{
+    ULONG num_cpus = peb->NumberOfProcessors;
+    if (num_cpus >= sizeof(ULONG_PTR) * 8) return ~(ULONG_PTR)0;
+    return ((ULONG_PTR)1 << num_cpus) - 1;
+}
+
+/***********************************************************************
+ *           virtual_get_system_info
+ */
+void virtual_get_system_info( SYSTEM_BASIC_INFORMATION *info, BOOL wow64 )
+{
+#if defined(HAVE_SYSINFO) \
+    && defined(HAVE_STRUCT_SYSINFO_TOTALRAM) && defined(HAVE_STRUCT_SYSINFO_MEM_UNIT)
+    struct sysinfo sinfo;
+
+    if (!sysinfo(&sinfo))
+    {
+        ULONG64 total = (ULONG64)sinfo.totalram * sinfo.mem_unit;
+        info->MmHighestPhysicalPage = max(1, total / page_size);
+    }
+#elif defined(_SC_PHYS_PAGES)
+    LONG64 phys_pages = sysconf( _SC_PHYS_PAGES );
+
+#ifdef __APPLE__
+    /* CrossOver Hack #20725: sysconf(_SC_PHYS_PAGES) fails with
+       ERANGE when run in 32-on-64 on macOS. */
+    if (phys_pages == -1 && errno == ERANGE)
+    {
+        static int mib[2] = { CTL_HW, HW_MEMSIZE };
+        uint64_t memsize;
+        size_t size = sizeof(memsize);
+        if (!sysctl(mib, 2, &memsize, &size, NULL, 0) && size == sizeof(memsize))
+            phys_pages = memsize / page_size;
+    }
+#endif
+
+    info->MmHighestPhysicalPage = max(1, phys_pages);
+#else
+    info->MmHighestPhysicalPage = 0x7fffffff / page_size;
+#endif
+
+    info->unknown                 = 0;
+    info->KeMaximumIncrement      = 0;  /* FIXME */
+    info->PageSize                = page_size;
+    info->MmLowestPhysicalPage    = 1;
+    info->MmNumberOfPhysicalPages = info->MmHighestPhysicalPage - info->MmLowestPhysicalPage;
+    info->AllocationGranularity   = granularity_mask + 1;
+    info->LowestUserAddress       = (void *)0x10000;
+    info->ActiveProcessorsAffinityMask = get_system_affinity_mask();
+    info->NumberOfProcessors      = peb->NumberOfProcessors;
+    if (wow64) info->HighestUserAddress = (char *)get_wow_user_space_limit() - 1;
+    else info->HighestUserAddress = (char *)user_space_limit - 1;
+}
+
+
+/***********************************************************************
+ *           virtual_map_builtin_module
+ */
+NTSTATUS virtual_map_builtin_module( HANDLE mapping, void **module, SIZE_T *size, SECTION_IMAGE_INFORMATION *info,
+                                     ULONG_PTR zero_bits, WORD machine, BOOL prefer_native )
+{
+    mem_size_t full_size;
+    unsigned int sec_flags;
+    HANDLE shared_file;
+    pe_image_info_t *image_info = NULL;
+    ACCESS_MASK access = SECTION_MAP_READ | SECTION_MAP_EXECUTE;
+    NTSTATUS status;
+    WCHAR *filename;
+
+    if ((status = get_mapping_info( mapping, access, &sec_flags, &full_size, &shared_file, &image_info )))
+        return status;
+
+    if (!image_info) return STATUS_INVALID_PARAMETER;
+
+    *module = NULL;
+    *size = 0;
+    filename = (WCHAR *)(image_info + 1);
+
+    if (!(image_info->image_flags & IMAGE_FLAGS_WineBuiltin)) /* ignore non-builtins */
+    {
+        WARN( "%s found in WINEDLLPATH but not a builtin, ignoring\n", debugstr_w(filename) );
+        status = STATUS_DLL_NOT_FOUND;
+    }
+    else if (machine && image_info->machine != machine && !needs_wow64() /* CW HACK 20810 */)
+    {
+        TRACE( "%s is for arch %04x, continuing search\n", debugstr_w(filename), image_info->machine );
+        status = STATUS_IMAGE_MACHINE_TYPE_MISMATCH;
+    }
+    else if (prefer_native && (image_info->dll_charact & IMAGE_DLLCHARACTERISTICS_PREFER_NATIVE))
+    {
+        TRACE( "%s has prefer-native flag, ignoring builtin\n", debugstr_w(filename) );
+        status = STATUS_IMAGE_ALREADY_LOADED;
+    }
+    else
+    {
+        status = virtual_map_image( mapping, SECTION_MAP_READ | SECTION_MAP_EXECUTE,
+                                    module, size, zero_bits, shared_file, 0, image_info, filename, TRUE );
+        virtual_fill_image_information( image_info, info );
+    }
+
+    if (shared_file) NtClose( shared_file );
+    free( image_info );
+    return status;
+}
+
+
+/***********************************************************************
+ *           virtual_create_builtin_view
+ */
+NTSTATUS virtual_create_builtin_view( void *module, const UNICODE_STRING *nt_name,
+                                      pe_image_info_t *info, void *so_handle )
+{
+    NTSTATUS status;
+    sigset_t sigset;
+    IMAGE_DOS_HEADER *dos = module;
+    IMAGE_NT_HEADERS *nt = (IMAGE_NT_HEADERS *)((char *)dos + dos->e_lfanew);
+    SIZE_T size = info->map_size;
+    IMAGE_SECTION_HEADER *sec;
+    struct file_view *view;
+    void *base = wine_server_get_ptr( info->base );
+    int i;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    status = create_view( &view, base, size, SEC_IMAGE | SEC_FILE | VPROT_SYSTEM |
+                          VPROT_COMMITTED | VPROT_READ | VPROT_WRITECOPY | VPROT_EXEC );
+    if (!status)
+    {
+        TRACE( "created %p-%p for %s\n", base, (char *)base + size, debugstr_us(nt_name) );
+
+        /* The PE header is always read-only, no write, no execute. */
+        set_page_vprot( base, page_size, VPROT_COMMITTED | VPROT_READ );
+
+        sec = (IMAGE_SECTION_HEADER *)((char *)&nt->OptionalHeader + nt->FileHeader.SizeOfOptionalHeader);
+        for (i = 0; i < nt->FileHeader.NumberOfSections; i++)
+        {
+            BYTE flags = VPROT_COMMITTED;
+
+            if (sec[i].Characteristics & IMAGE_SCN_MEM_EXECUTE) flags |= VPROT_EXEC;
+            if (sec[i].Characteristics & IMAGE_SCN_MEM_READ) flags |= VPROT_READ;
+            if (sec[i].Characteristics & IMAGE_SCN_MEM_WRITE) flags |= VPROT_WRITE;
+            set_page_vprot( (char *)base + sec[i].VirtualAddress, sec[i].Misc.VirtualSize, flags );
+        }
+
+        SERVER_START_REQ( map_view )
+        {
+            req->base = wine_server_client_ptr( view->base );
+            req->size = size;
+            wine_server_add_data( req, info, sizeof(*info) );
+            wine_server_add_data( req, nt_name->Buffer, nt_name->Length );
+            status = wine_server_call( req );
+        }
+        SERVER_END_REQ;
+
+        if (status >= 0)
+        {
+            add_builtin_module( view->base, so_handle );
+            VIRTUAL_DEBUG_DUMP_VIEW( view );
+            if (is_beyond_limit( base, size, working_set_limit )) working_set_limit = address_space_limit;
+        }
+        else delete_view( view );
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+    return status;
+}
+
+
+/* set some initial values in a new TEB */
+static TEB *init_teb( void *ptr, BOOL is_wow )
+{
+    struct ntdll_thread_data *thread_data;
+    TEB *teb;
+    TEB64 *teb64 = ptr;
+    TEB32 *teb32 = (TEB32 *)((char *)ptr + teb_offset);
+
+#ifdef _WIN64
+    teb = (TEB *)teb64;
+    teb32->Peb = PtrToUlong( (char *)peb + page_size );
+    teb32->Tib.Self = PtrToUlong( teb32 );
+    teb32->Tib.ExceptionList = ~0u;
+    teb32->ActivationContextStackPointer = PtrToUlong( &teb32->ActivationContextStack );
+    teb32->ActivationContextStack.FrameListCache.Flink =
+        teb32->ActivationContextStack.FrameListCache.Blink =
+            PtrToUlong( &teb32->ActivationContextStack.FrameListCache );
+    teb32->StaticUnicodeString.Buffer = PtrToUlong( teb32->StaticUnicodeBuffer );
+    teb32->StaticUnicodeString.MaximumLength = sizeof( teb32->StaticUnicodeBuffer );
+    teb32->GdiBatchCount = PtrToUlong( teb64 );
+    teb32->WowTebOffset  = -teb_offset;
+    if (is_wow) teb64->WowTebOffset = teb_offset;
+#else
+    teb = (TEB *)teb32;
+    teb64->Peb = PtrToUlong( (char *)peb - page_size );
+    teb64->Tib.Self = PtrToUlong( teb64 );
+    teb64->Tib.ExceptionList = PtrToUlong( teb32 );
+    teb64->ActivationContextStackPointer = PtrToUlong( &teb64->ActivationContextStack );
+    teb64->ActivationContextStack.FrameListCache.Flink =
+        teb64->ActivationContextStack.FrameListCache.Blink =
+            PtrToUlong( &teb64->ActivationContextStack.FrameListCache );
+    teb64->StaticUnicodeString.Buffer = PtrToUlong( teb64->StaticUnicodeBuffer );
+    teb64->StaticUnicodeString.MaximumLength = sizeof( teb64->StaticUnicodeBuffer );
+    teb64->WowTebOffset = teb_offset;
+    if (is_wow)
+    {
+        teb32->GdiBatchCount = PtrToUlong( teb64 );
+        teb32->WowTebOffset  = -teb_offset;
+    }
+#endif
+    teb->Peb = peb;
+    teb->Tib.Self = &teb->Tib;
+    teb->Tib.ExceptionList = (void *)~0ul;
+    teb->Tib.StackBase = (void *)~0ul;
+    teb->ActivationContextStackPointer = &teb->ActivationContextStack;
+    InitializeListHead( &teb->ActivationContextStack.FrameListCache );
+    teb->StaticUnicodeString.Buffer = teb->StaticUnicodeBuffer;
+    teb->StaticUnicodeString.MaximumLength = sizeof(teb->StaticUnicodeBuffer);
+    thread_data = (struct ntdll_thread_data *)&teb->GdiTebBatch;
+    thread_data->esync_apc_fd = -1;
+    thread_data->request_fd = -1;
+    thread_data->reply_fd   = -1;
+    thread_data->wait_fd[0] = -1;
+    thread_data->wait_fd[1] = -1;
+    list_add_head( &teb_list, &thread_data->entry );
+    return teb;
+}
+
+
+/***********************************************************************
+ *           virtual_alloc_first_teb
+ */
+TEB *virtual_alloc_first_teb(void)
+{
+    void *ptr;
+    NTSTATUS status;
+    SIZE_T data_size = page_size;
+    SIZE_T block_size = signal_stack_mask + 1;
+    SIZE_T total = 32 * block_size;
+
+    /* reserve space for shared user data */
+    status = NtAllocateVirtualMemory( NtCurrentProcess(), (void **)&user_shared_data, 0, &data_size,
+                                      MEM_RESERVE | MEM_COMMIT, PAGE_READONLY );
+    if (status)
+    {
+        ERR( "wine: failed to map the shared user data: %08x\n", status );
+        exit(1);
+    }
+
+    NtAllocateVirtualMemory( NtCurrentProcess(), &teb_block, is_win64 ? 0x7fffffff : 0, &total,
+                             MEM_RESERVE | MEM_TOP_DOWN, PAGE_READWRITE );
+    teb_block_pos = 30;
+    ptr = (char *)teb_block + 30 * block_size;
+    data_size = 2 * block_size;
+    NtAllocateVirtualMemory( NtCurrentProcess(), (void **)&ptr, 0, &data_size, MEM_COMMIT, PAGE_READWRITE );
+    peb = (PEB *)((char *)teb_block + 31 * block_size + (is_win64 ? 0 : page_size));
+    return init_teb( ptr, FALSE );
+}
+
+
+/***********************************************************************
+ *           virtual_alloc_teb
+ */
+NTSTATUS virtual_alloc_teb( TEB **ret_teb )
+{
+    sigset_t sigset;
+    TEB *teb;
+    void *ptr = NULL;
+    NTSTATUS status = STATUS_SUCCESS;
+    SIZE_T block_size = signal_stack_mask + 1;
+    BOOL is_wow = !!NtCurrentTeb()->WowTebOffset;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (next_free_teb)
+    {
+        ptr = next_free_teb;
+        next_free_teb = *(void **)ptr;
+        memset( ptr, 0, teb_size );
+    }
+    else
+    {
+        if (!teb_block_pos)
+        {
+            SIZE_T total = 32 * block_size;
+
+            if ((status = NtAllocateVirtualMemory( NtCurrentProcess(), &ptr, is_win64 && is_wow ? 0x7fffffff : 0,
+                                                   &total, MEM_RESERVE, PAGE_READWRITE )))
+            {
+                server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+                return status;
+            }
+            teb_block = ptr;
+            teb_block_pos = 32;
+        }
+        ptr = ((char *)teb_block + --teb_block_pos * block_size);
+        NtAllocateVirtualMemory( NtCurrentProcess(), (void **)&ptr, 0, &block_size,
+                                 MEM_COMMIT, PAGE_READWRITE );
+    }
+    *ret_teb = teb = init_teb( ptr, is_wow );
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if ((status = signal_alloc_thread( teb )))
+    {
+        server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+        *(void **)ptr = next_free_teb;
+        next_free_teb = ptr;
+        server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    }
+    return status;
+}
+
+
+/***********************************************************************
+ *           virtual_free_teb
+ */
+void virtual_free_teb( TEB *teb )
+{
+    struct ntdll_thread_data *thread_data = (struct ntdll_thread_data *)&teb->GdiTebBatch;
+    void *ptr;
+    SIZE_T size;
+    sigset_t sigset;
+    WOW_TEB *wow_teb = get_wow_teb( teb );
+
+    signal_free_thread( teb );
+    if (teb->DeallocationStack)
+    {
+        size = 0;
+        NtFreeVirtualMemory( GetCurrentProcess(), &teb->DeallocationStack, &size, MEM_RELEASE );
+    }
+    if (thread_data->kernel_stack)
+    {
+        size = 0;
+        NtFreeVirtualMemory( GetCurrentProcess(), &thread_data->kernel_stack, &size, MEM_RELEASE );
+    }
+    if (wow_teb && (ptr = ULongToPtr( wow_teb->DeallocationStack )))
+    {
+        size = 0;
+        NtFreeVirtualMemory( GetCurrentProcess(), &ptr, &size, MEM_RELEASE );
+    }
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    list_remove( &thread_data->entry );
+    ptr = teb;
+    if (!is_win64) ptr = (char *)ptr - teb_offset;
+    *(void **)ptr = next_free_teb;
+    next_free_teb = ptr;
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+}
+
+
+/***********************************************************************
+ *           virtual_clear_tls_index
+ */
+NTSTATUS virtual_clear_tls_index( ULONG index )
+{
+    struct ntdll_thread_data *thread_data;
+    sigset_t sigset;
+
+    if (index < TLS_MINIMUM_AVAILABLE)
+    {
+        server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+        LIST_FOR_EACH_ENTRY( thread_data, &teb_list, struct ntdll_thread_data, entry )
+        {
+            TEB *teb = CONTAINING_RECORD( thread_data, TEB, GdiTebBatch );
+#ifdef _WIN64
+            WOW_TEB *wow_teb = get_wow_teb( teb );
+            if (wow_teb) wow_teb->TlsSlots[index] = 0;
+            else
+#endif
+            teb->TlsSlots[index] = 0;
+        }
+        server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    }
+    else
+    {
+        index -= TLS_MINIMUM_AVAILABLE;
+        if (index >= 8 * sizeof(peb->TlsExpansionBitmapBits)) return STATUS_INVALID_PARAMETER;
+
+        server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+        LIST_FOR_EACH_ENTRY( thread_data, &teb_list, struct ntdll_thread_data, entry )
+        {
+            TEB *teb = CONTAINING_RECORD( thread_data, TEB, GdiTebBatch );
+#ifdef _WIN64
+            WOW_TEB *wow_teb = get_wow_teb( teb );
+            if (wow_teb)
+            {
+                if (wow_teb->TlsExpansionSlots)
+                    ((ULONG *)ULongToPtr( wow_teb->TlsExpansionSlots ))[index] = 0;
+            }
+            else
+#endif
+            if (teb->TlsExpansionSlots) teb->TlsExpansionSlots[index] = 0;
+        }
+        server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    }
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           virtual_alloc_thread_stack
+ */
+NTSTATUS virtual_alloc_thread_stack( INITIAL_TEB *stack, ULONG_PTR zero_bits, SIZE_T reserve_size,
+                                     SIZE_T commit_size, SIZE_T extra_size )
+{
+    struct file_view *view;
+    NTSTATUS status;
+    sigset_t sigset;
+    SIZE_T size;
+
+    if (!reserve_size) reserve_size = main_image_info.MaximumStackSize;
+    if (!commit_size) commit_size = main_image_info.CommittedStackSize;
+
+    size = max( reserve_size, commit_size );
+    if (size < 1024 * 1024) size = 1024 * 1024;  /* Xlib needs a large stack */
+    size = (size + 0xffff) & ~0xffff;  /* round to 64K boundary */
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if ((status = map_view( &view, NULL, size + extra_size, FALSE,
+                            VPROT_READ | VPROT_WRITE | VPROT_COMMITTED, zero_bits )) != STATUS_SUCCESS)
+        goto done;
+
+#ifdef VALGRIND_STACK_REGISTER
+    VALGRIND_STACK_REGISTER( view->base, (char *)view->base + view->size );
+#endif
+
+    /* setup no access guard page */
+    set_page_vprot( view->base, page_size, VPROT_COMMITTED );
+    set_page_vprot( (char *)view->base + page_size, page_size,
+                    VPROT_READ | VPROT_WRITE | VPROT_COMMITTED | VPROT_GUARD );
+    mprotect_range( view->base, 2 * page_size, 0, 0 );
+    VIRTUAL_DEBUG_DUMP_VIEW( view );
+
+    if (extra_size)
+    {
+        struct file_view *extra_view;
+
+        /* shrink the first view and create a second one for the extra size */
+        /* this allows the app to free the stack without freeing the thread start portion */
+        view->size -= extra_size;
+        status = create_view( &extra_view, (char *)view->base + view->size, extra_size,
+                              VPROT_READ | VPROT_WRITE | VPROT_COMMITTED );
+        if (status != STATUS_SUCCESS)
+        {
+            view->size += extra_size;
+            delete_view( view );
+            goto done;
+        }
+    }
+
+    /* note: limit is lower than base since the stack grows down */
+    stack->OldStackBase = 0;
+    stack->OldStackLimit = 0;
+    stack->DeallocationStack = view->base;
+    stack->StackBase = (char *)view->base + view->size;
+    stack->StackLimit = (char *)view->base + 2 * page_size;
+done:
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *           virtual_map_user_shared_data
+ */
+void virtual_map_user_shared_data(void)
+{
+    static const WCHAR nameW[] = {'\\','K','e','r','n','e','l','O','b','j','e','c','t','s',
+                                  '\\','_','_','w','i','n','e','_','u','s','e','r','_','s','h','a','r','e','d','_','d','a','t','a',0};
+    UNICODE_STRING name_str = { sizeof(nameW) - sizeof(WCHAR), sizeof(nameW), (WCHAR *)nameW };
+    OBJECT_ATTRIBUTES attr = { sizeof(attr), 0, &name_str };
+    NTSTATUS status;
+    HANDLE section;
+    int res, fd, needs_close;
+
+    if ((status = NtOpenSection( &section, SECTION_ALL_ACCESS, &attr )))
+    {
+        ERR( "failed to open the USD section: %08x\n", status );
+        exit(1);
+    }
+    if ((res = server_get_unix_fd( section, 0, &fd, &needs_close, NULL, NULL )) ||
+        (user_shared_data != wine_mmap( user_shared_data, page_size, PROT_READ, MAP_SHARED|MAP_FIXED, fd, 0 )))
+    {
+        ERR( "failed to remap the process USD: %d\n", res );
+        exit(1);
+    }
+    if (needs_close) close( fd );
+    NtClose( section );
+}
+
+
+struct thread_stack_info
+{
+    char  *start;
+    char  *limit;
+    char  *end;
+    SIZE_T guaranteed;
+    BOOL   is_wow;
+};
+
+/***********************************************************************
+ *           is_inside_thread_stack
+ */
+static BOOL is_inside_thread_stack( void *ptr, struct thread_stack_info *stack )
+{
+    TEB *teb = NtCurrentTeb();
+    WOW_TEB *wow_teb = get_wow_teb( teb );
+
+    stack->start = teb->DeallocationStack;
+    stack->limit = teb->Tib.StackLimit;
+    stack->end   = teb->Tib.StackBase;
+    stack->guaranteed = max( teb->GuaranteedStackBytes, page_size * (is_win64 ? 2 : 1) );
+    stack->is_wow = FALSE;
+    if ((char *)ptr > stack->start && (char *)ptr <= stack->end) return TRUE;
+
+    if (!wow_teb) return FALSE;
+    stack->start = ULongToPtr( wow_teb->DeallocationStack );
+    stack->limit = ULongToPtr( wow_teb->Tib.StackLimit );
+    stack->end   = ULongToPtr( wow_teb->Tib.StackBase );
+    stack->guaranteed = max( wow_teb->GuaranteedStackBytes, page_size * (is_win64 ? 1 : 2) );
+    stack->is_wow = TRUE;
+    return ((char *)ptr > stack->start && (char *)ptr <= stack->end);
+}
+
+
+/***********************************************************************
+ *           grow_thread_stack
+ */
+static NTSTATUS grow_thread_stack( char *page, struct thread_stack_info *stack_info )
+{
+    NTSTATUS ret = 0;
+
+    set_page_vprot_bits( page, page_size, 0, VPROT_GUARD );
+    mprotect_range( page, page_size, 0, 0 );
+    if (page >= stack_info->start + page_size + stack_info->guaranteed)
+    {
+        set_page_vprot_bits( page - page_size, page_size, VPROT_COMMITTED | VPROT_GUARD, 0 );
+        mprotect_range( page - page_size, page_size, 0, 0 );
+    }
+    else  /* inside guaranteed space -> overflow exception */
+    {
+        page = stack_info->start + page_size;
+        set_page_vprot_bits( page, stack_info->guaranteed, VPROT_COMMITTED, VPROT_GUARD );
+        mprotect_range( page, stack_info->guaranteed, 0, 0 );
+        ret = STATUS_STACK_OVERFLOW;
+    }
+    if (stack_info->is_wow)
+    {
+        WOW_TEB *wow_teb = get_wow_teb( NtCurrentTeb() );
+        wow_teb->Tib.StackLimit = PtrToUlong( page );
+    }
+    else NtCurrentTeb()->Tib.StackLimit = page;
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_handle_fault
+ */
+NTSTATUS virtual_handle_fault( void *addr, DWORD err, void *stack )
+{
+    NTSTATUS ret = STATUS_ACCESS_VIOLATION;
+    char *page = ROUND_ADDR( addr, page_mask );
+    BYTE vprot;
+
+    mutex_lock( &virtual_mutex );  /* no need for signal masking inside signal handler */
+    vprot = get_page_vprot( page );
+
+    /* CX HACK 20012: Work around Apple Silicon misreporting certain write faults as reads. */
+#ifdef __APPLE__
+    if (err == EXCEPTION_READ_FAULT &&
+        (vprot & VPROT_WRITEWATCH) &&
+        (get_unix_prot( vprot ) & PROT_READ))
+    {
+        FIXME("HACK: read fault @ %p is in a readable WRITEWATCH page; treating as a write\n", addr);
+        err = EXCEPTION_WRITE_FAULT;
+    }
+#endif
+
+    if (!is_inside_signal_stack( stack ) && (vprot & VPROT_GUARD))
+    {
+        struct thread_stack_info stack_info;
+        if (!is_inside_thread_stack( page, &stack_info ))
+        {
+            set_page_vprot_bits( page, page_size, 0, VPROT_GUARD );
+            mprotect_range( page, page_size, 0, 0 );
+            ret = STATUS_GUARD_PAGE_VIOLATION;
+        }
+        else ret = grow_thread_stack( page, &stack_info );
+    }
+    else if (err & EXCEPTION_WRITE_FAULT)
+    {
+        if (vprot & VPROT_WRITEWATCH)
+        {
+            set_page_vprot_bits( page, page_size, 0, VPROT_WRITEWATCH );
+            mprotect_range( page, page_size, 0, 0 );
+        }
+        /* ignore fault if page is writable now */
+        if (get_unix_prot( get_page_vprot( page )) & PROT_WRITE)
+        {
+            if ((vprot & VPROT_WRITEWATCH) || is_write_watch_range( page, page_size ))
+                ret = STATUS_SUCCESS;
+        }
+    }
+    mutex_unlock( &virtual_mutex );
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_setup_exception
+ */
+void *virtual_setup_exception( void *stack_ptr, size_t size, EXCEPTION_RECORD *rec )
+{
+    char *stack = stack_ptr;
+    struct thread_stack_info stack_info;
+
+    if (!is_inside_thread_stack( stack, &stack_info ))
+    {
+        if (is_inside_signal_stack( stack ))
+        {
+            ERR( "nested exception on signal stack in thread %04x addr %p stack %p\n",
+                 GetCurrentThreadId(), rec->ExceptionAddress, stack );
+            abort_thread(1);
+        }
+        WARN( "exception outside of stack limits in thread %04x addr %p stack %p (%p-%p-%p)\n",
+              GetCurrentThreadId(), rec->ExceptionAddress, stack, NtCurrentTeb()->DeallocationStack,
+              NtCurrentTeb()->Tib.StackLimit, NtCurrentTeb()->Tib.StackBase );
+        return stack - size;
+    }
+
+    stack -= size;
+
+    if (stack < stack_info.start + 4096)
+    {
+        /* stack overflow on last page, unrecoverable */
+        UINT diff = stack_info.start + 4096 - stack;
+        ERR( "stack overflow %u bytes in thread %04x addr %p stack %p (%p-%p-%p)\n",
+             diff, GetCurrentThreadId(), rec->ExceptionAddress, stack, stack_info.start,
+             stack_info.limit, stack_info.end );
+        abort_thread(1);
+    }
+    else if (stack < stack_info.limit)
+    {
+        mutex_lock( &virtual_mutex );  /* no need for signal masking inside signal handler */
+        if ((get_page_vprot( stack ) & VPROT_GUARD) &&
+            grow_thread_stack( ROUND_ADDR( stack, page_mask ), &stack_info ))
+        {
+            rec->ExceptionCode = STATUS_STACK_OVERFLOW;
+            rec->NumberParameters = 0;
+        }
+        mutex_unlock( &virtual_mutex );
+    }
+#if defined(VALGRIND_MAKE_MEM_UNDEFINED)
+    VALGRIND_MAKE_MEM_UNDEFINED( stack, size );
+#elif defined(VALGRIND_MAKE_WRITABLE)
+    VALGRIND_MAKE_WRITABLE( stack, size );
+#endif
+    return stack;
+}
+
+
+/***********************************************************************
+ *           check_write_access
+ *
+ * Check if the memory range is writable, temporarily disabling write watches if necessary.
+ */
+static NTSTATUS check_write_access( void *base, size_t size, BOOL *has_write_watch )
+{
+    size_t i;
+    char *addr = ROUND_ADDR( base, page_mask );
+
+    size = ROUND_SIZE( base, size );
+    for (i = 0; i < size; i += page_size)
+    {
+        BYTE vprot = get_page_vprot( addr + i );
+        if (vprot & VPROT_WRITEWATCH) *has_write_watch = TRUE;
+        if (!(get_unix_prot( vprot & ~VPROT_WRITEWATCH ) & PROT_WRITE))
+            return STATUS_INVALID_USER_BUFFER;
+    }
+    if (*has_write_watch)
+        mprotect_range( addr, size, 0, VPROT_WRITEWATCH );  /* temporarily enable write access */
+    return STATUS_SUCCESS;
+}
+
+
+/***********************************************************************
+ *           virtual_locked_server_call
+ */
+unsigned int virtual_locked_server_call( void *req_ptr )
+{
+    struct __server_request_info * const req = req_ptr;
+    sigset_t sigset;
+    void *addr = req->reply_data;
+    data_size_t size = req->u.req.request_header.reply_size;
+    BOOL has_write_watch = FALSE;
+    unsigned int ret = STATUS_ACCESS_VIOLATION;
+
+    if (!size) return wine_server_call( req_ptr );
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!(ret = check_write_access( addr, size, &has_write_watch )))
+    {
+        ret = server_call_unlocked( req );
+        if (has_write_watch) update_write_watches( addr, size, wine_server_reply_size( req ));
+    }
+    else memset( &req->u.reply, 0, sizeof(req->u.reply) );
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_locked_read
+ */
+ssize_t virtual_locked_read( int fd, void *addr, size_t size )
+{
+    sigset_t sigset;
+    BOOL has_write_watch = FALSE;
+    int err = EFAULT;
+
+    ssize_t ret = read( fd, addr, size );
+    if (ret != -1 || errno != EFAULT) return ret;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!check_write_access( addr, size, &has_write_watch ))
+    {
+        ret = read( fd, addr, size );
+        err = errno;
+        if (has_write_watch) update_write_watches( addr, size, max( 0, ret ));
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    errno = err;
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_locked_pread
+ */
+ssize_t virtual_locked_pread( int fd, void *addr, size_t size, off_t offset )
+{
+    sigset_t sigset;
+    BOOL has_write_watch = FALSE;
+    int err = EFAULT;
+
+    ssize_t ret = pread( fd, addr, size, offset );
+    if (ret != -1 || errno != EFAULT) return ret;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!check_write_access( addr, size, &has_write_watch ))
+    {
+        ret = pread( fd, addr, size, offset );
+        err = errno;
+        if (has_write_watch) update_write_watches( addr, size, max( 0, ret ));
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    errno = err;
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_locked_recvmsg
+ */
+ssize_t virtual_locked_recvmsg( int fd, struct msghdr *hdr, int flags )
+{
+    sigset_t sigset;
+    size_t i;
+    BOOL has_write_watch = FALSE;
+    int err = EFAULT;
+
+    ssize_t ret = recvmsg( fd, hdr, flags );
+    if (ret != -1 || errno != EFAULT) return ret;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    for (i = 0; i < hdr->msg_iovlen; i++)
+        if (check_write_access( hdr->msg_iov[i].iov_base, hdr->msg_iov[i].iov_len, &has_write_watch ))
+            break;
+    if (i == hdr->msg_iovlen)
+    {
+        ret = recvmsg( fd, hdr, flags );
+        err = errno;
+    }
+    if (has_write_watch)
+        while (i--) update_write_watches( hdr->msg_iov[i].iov_base, hdr->msg_iov[i].iov_len, 0 );
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    errno = err;
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_is_valid_code_address
+ */
+BOOL virtual_is_valid_code_address( const void *addr, SIZE_T size )
+{
+    struct file_view *view;
+    BOOL ret = FALSE;
+    sigset_t sigset;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if ((view = find_view( addr, size )))
+        ret = !(view->protect & VPROT_SYSTEM);  /* system views are not visible to the app */
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_check_buffer_for_read
+ *
+ * Check if a memory buffer can be read, triggering page faults if needed for DIB section access.
+ */
+BOOL virtual_check_buffer_for_read( const void *ptr, SIZE_T size )
+{
+    if (!size) return TRUE;
+    if (!ptr) return FALSE;
+
+    __TRY
+    {
+        volatile const char *p = ptr;
+        char dummy __attribute__((unused));
+        SIZE_T count = size;
+
+        while (count > page_size)
+        {
+            dummy = *p;
+            p += page_size;
+            count -= page_size;
+        }
+        dummy = p[0];
+        dummy = p[count - 1];
+    }
+    __EXCEPT
+    {
+        return FALSE;
+    }
+    __ENDTRY
+    return TRUE;
+}
+
+
+/***********************************************************************
+ *           virtual_check_buffer_for_write
+ *
+ * Check if a memory buffer can be written to, triggering page faults if needed for write watches.
+ */
+BOOL virtual_check_buffer_for_write( void *ptr, SIZE_T size )
+{
+    if (!size) return TRUE;
+    if (!ptr) return FALSE;
+
+    __TRY
+    {
+        volatile char *p = ptr;
+        SIZE_T count = size;
+
+        while (count > page_size)
+        {
+            *p |= 0;
+            p += page_size;
+            count -= page_size;
+        }
+        p[0] |= 0;
+        p[count - 1] |= 0;
+    }
+    __EXCEPT
+    {
+        return FALSE;
+    }
+    __ENDTRY
+    return TRUE;
+}
+
+
+/***********************************************************************
+ *           virtual_uninterrupted_read_memory
+ *
+ * Similar to NtReadVirtualMemory, but without wineserver calls. Moreover
+ * permissions are checked before accessing each page, to ensure that no
+ * exceptions can happen.
+ */
+SIZE_T virtual_uninterrupted_read_memory( const void *addr, void *buffer, SIZE_T size )
+{
+    struct file_view *view;
+    sigset_t sigset;
+    SIZE_T bytes_read = 0;
+
+    if (!size) return 0;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if ((view = find_view( addr, size )))
+    {
+        if (!(view->protect & VPROT_SYSTEM))
+        {
+            while (bytes_read < size && (get_unix_prot( get_page_vprot( addr )) & PROT_READ))
+            {
+                SIZE_T block_size = min( size - bytes_read, page_size - ((UINT_PTR)addr & page_mask) );
+                memcpy( buffer, addr, block_size );
+
+                addr   = (const void *)((const char *)addr + block_size);
+                buffer = (void *)((char *)buffer + block_size);
+                bytes_read += block_size;
+            }
+        }
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return bytes_read;
+}
+
+
+/***********************************************************************
+ *           virtual_uninterrupted_write_memory
+ *
+ * Similar to NtWriteVirtualMemory, but without wineserver calls. Moreover
+ * permissions are checked before accessing each page, to ensure that no
+ * exceptions can happen.
+ */
+NTSTATUS virtual_uninterrupted_write_memory( void *addr, const void *buffer, SIZE_T size )
+{
+    BOOL has_write_watch = FALSE;
+    sigset_t sigset;
+    NTSTATUS ret;
+
+    if (!size) return STATUS_SUCCESS;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!(ret = check_write_access( addr, size, &has_write_watch )))
+    {
+        memcpy( addr, buffer, size );
+        if (has_write_watch) update_write_watches( addr, size, size );
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return ret;
+}
+
+
+/***********************************************************************
+ *           virtual_set_force_exec
+ *
+ * Whether to force exec prot on all views.
+ */
+void virtual_set_force_exec( BOOL enable )
+{
+    struct file_view *view;
+    sigset_t sigset;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!force_exec_prot != !enable)  /* change all existing views */
+    {
+        force_exec_prot = enable;
+
+        WINE_RB_FOR_EACH_ENTRY( view, &views_tree, struct file_view, entry )
+        {
+            /* file mappings are always accessible */
+            BYTE commit = is_view_valloc( view ) ? 0 : VPROT_COMMITTED;
+
+            mprotect_range( view->base, view->size, commit, 0 );
+        }
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+}
+
+struct free_range
+{
+    char *base;
+    char *limit;
+};
+
+/* free reserved areas above the limit; callback for mmap_enum_reserved_areas */
+static int free_reserved_memory( void *base, SIZE_T size, void *arg )
+{
+    struct free_range *range = arg;
+
+    if ((char *)base >= range->limit) return 0;
+    if ((char *)base + size <= range->base) return 0;
+    if ((char *)base < range->base)
+    {
+        size -= range->base - (char *)base;
+        base = range->base;
+    }
+    if ((char *)base + size > range->limit) size = range->limit - (char *)base;
+    remove_reserved_area( base, size );
+    return 1;  /* stop enumeration since the list has changed */
+}
+
+/***********************************************************************
+ *           virtual_release_address_space
+ *
+ * Release some address space once we have loaded and initialized the app.
+ */
+static void virtual_release_address_space(void)
+{
+    struct free_range range;
+
+    range.base  = (char *)0x82000000;
+    range.limit = get_wow_user_space_limit();
+
+    if (range.limit > (char *)0xfffff000) return;  /* 64-bit limit, nothing to do */
+
+    if (range.limit > range.base)
+    {
+        while (mmap_enum_reserved_areas( free_reserved_memory, &range, 1 )) /* nothing */;
+#ifdef __APPLE__
+        /* On macOS, we still want to free some of low memory, for OpenGL resources */
+        range.base = (char *)0x40000000;
+#else
+        return;
+#endif
+    }
+    else range.base = (char *)0x20000000;
+
+#ifdef __APPLE__ /* CrossOver Hack #16371 */
+    {
+        char buf[1024], *p;
+        uint32_t size = sizeof(buf);
+        if (_NSGetExecutablePath(buf, &size) == 0)
+        {
+            if ((p = strrchr(buf, '/'))) ++p;
+            else p = buf;
+            if (!strcasestr(p, "preloader"))
+                range.base  = (char *)0x40001000;
+        }
+    }
+#endif
+
+    range.limit = (char *)0x7f000000;
+    while (mmap_enum_reserved_areas( free_reserved_memory, &range, 0 )) /* nothing */;
+}
+
+
+/***********************************************************************
+ *           virtual_set_large_address_space
+ *
+ * Enable use of a large address space when allowed by the application.
+ */
+void virtual_set_large_address_space(void)
+{
+    /* no large address space on win9x */
+    if (peb->OSPlatformId != VER_PLATFORM_WIN32_NT) return;
+
+    user_space_limit = working_set_limit = address_space_limit;
+    large_address_space_active = TRUE; /* CW HACK 17634 */
+}
+
+
+/***********************************************************************
+ *             NtAllocateVirtualMemory   (NTDLL.@)
+ *             ZwAllocateVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtAllocateVirtualMemory( HANDLE process, PVOID *ret, ULONG_PTR zero_bits,
+                                         SIZE_T *size_ptr, ULONG type, ULONG protect )
+{
+    void *base;
+    unsigned int vprot;
+    BOOL is_dos_memory = FALSE;
+    struct file_view *view;
+    sigset_t sigset;
+    SIZE_T size = *size_ptr;
+    NTSTATUS status = STATUS_SUCCESS;
+
+    TRACE("%p %p %08lx %x %08x\n", process, *ret, size, type, protect );
+
+    if (!size) return STATUS_INVALID_PARAMETER;
+    if (zero_bits > 21 && zero_bits < 32) return STATUS_INVALID_PARAMETER_3;
+    if (zero_bits > 32 && zero_bits < granularity_mask) return STATUS_INVALID_PARAMETER_3;
+#ifndef _WIN64
+    if (!is_wow64 && zero_bits >= 32) return STATUS_INVALID_PARAMETER_3;
+#endif
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_alloc.type         = APC_VIRTUAL_ALLOC;
+        call.virtual_alloc.addr         = wine_server_client_ptr( *ret );
+        call.virtual_alloc.size         = *size_ptr;
+        call.virtual_alloc.zero_bits    = zero_bits;
+        call.virtual_alloc.op_type      = type;
+        call.virtual_alloc.prot         = protect;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_alloc.status == STATUS_SUCCESS)
+        {
+            *ret      = wine_server_get_ptr( result.virtual_alloc.addr );
+            *size_ptr = result.virtual_alloc.size;
+        }
+        return result.virtual_alloc.status;
+    }
+
+    /* Round parameters to a page boundary */
+
+    if (is_beyond_limit( 0, size, working_set_limit )) return STATUS_WORKING_SET_LIMIT_RANGE;
+
+    if (*ret)
+    {
+        if (type & MEM_RESERVE) /* Round down to 64k boundary */
+            base = ROUND_ADDR( *ret, granularity_mask );
+        else
+            base = ROUND_ADDR( *ret, page_mask );
+        size = (((UINT_PTR)*ret + size + page_mask) & ~page_mask) - (UINT_PTR)base;
+
+        /* disallow low 64k, wrap-around and kernel space */
+        if (((char *)base < (char *)0x10000) ||
+            ((char *)base + size < (char *)base) ||
+            is_beyond_limit( base, size, address_space_limit ))
+        {
+            /* address 1 is magic to mean DOS area */
+            if (!base && *ret == (void *)1 && size == 0x110000) is_dos_memory = TRUE;
+            else return STATUS_INVALID_PARAMETER;
+        }
+    }
+    else
+    {
+        base = NULL;
+        size = (size + page_mask) & ~page_mask;
+    }
+
+    /* Compute the alloc type flags */
+
+    if (!(type & (MEM_COMMIT | MEM_RESERVE | MEM_RESET)) ||
+        (type & ~(MEM_COMMIT | MEM_RESERVE | MEM_TOP_DOWN | MEM_WRITE_WATCH | MEM_RESET)))
+    {
+        WARN("called with wrong alloc type flags (%08x) !\n", type);
+        return STATUS_INVALID_PARAMETER;
+    }
+
+    /* Reserve the memory */
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if ((type & MEM_RESERVE) || !base)
+    {
+        if (!(status = get_vprot_flags( protect, &vprot, FALSE )))
+        {
+            if (type & MEM_COMMIT) vprot |= VPROT_COMMITTED;
+            if (type & MEM_WRITE_WATCH) vprot |= VPROT_WRITEWATCH;
+            if (protect & PAGE_NOCACHE) vprot |= SEC_NOCACHE;
+
+            if (vprot & VPROT_WRITECOPY) status = STATUS_INVALID_PAGE_PROTECTION;
+            else if (is_dos_memory) status = allocate_dos_memory( &view, vprot );
+            else status = map_view( &view, base, size, type & MEM_TOP_DOWN, vprot, zero_bits );
+
+            if (status == STATUS_SUCCESS) base = view->base;
+        }
+    }
+    else if (type & MEM_RESET)
+    {
+        if (!(view = find_view( base, size ))) status = STATUS_NOT_MAPPED_VIEW;
+        else madvise( base, size, MADV_DONTNEED );
+    }
+    else  /* commit the pages */
+    {
+        if (!(view = find_view( base, size ))) status = STATUS_NOT_MAPPED_VIEW;
+        else if (view->protect & SEC_FILE) status = STATUS_ALREADY_COMMITTED;
+        else if (!(status = set_protection( view, base, size, protect )) && (view->protect & SEC_RESERVE))
+        {
+            SERVER_START_REQ( add_mapping_committed_range )
+            {
+                req->base   = wine_server_client_ptr( view->base );
+                req->offset = (char *)base - (char *)view->base;
+                req->size   = size;
+                wine_server_call( req );
+            }
+            SERVER_END_REQ;
+        }
+    }
+
+    if (!status) VIRTUAL_DEBUG_DUMP_VIEW( view );
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if (status == STATUS_SUCCESS)
+    {
+        *ret = base;
+        *size_ptr = size;
+    }
+    return status;
+}
+
+/***********************************************************************
+ *             NtAllocateVirtualMemoryEx   (NTDLL.@)
+ *             ZwAllocateVirtualMemoryEx   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtAllocateVirtualMemoryEx( HANDLE process, PVOID *ret, SIZE_T *size_ptr, ULONG type,
+                                           ULONG protect, MEM_EXTENDED_PARAMETER *parameters,
+                                           ULONG count )
+{
+    if (count && !parameters) return STATUS_INVALID_PARAMETER;
+
+    if (count) FIXME( "Ignoring %d extended parameters %p\n", count, parameters );
+
+    return NtAllocateVirtualMemory( process, ret, 0, size_ptr, type, protect );
+}
+
+
+/***********************************************************************
+ *             NtFreeVirtualMemory   (NTDLL.@)
+ *             ZwFreeVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtFreeVirtualMemory( HANDLE process, PVOID *addr_ptr, SIZE_T *size_ptr, ULONG type )
+{
+    struct file_view *view;
+    char *base;
+    sigset_t sigset;
+    NTSTATUS status = STATUS_SUCCESS;
+    LPVOID addr = *addr_ptr;
+    SIZE_T size = *size_ptr;
+
+    TRACE("%p %p %08lx %x\n", process, addr, size, type );
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_free.type      = APC_VIRTUAL_FREE;
+        call.virtual_free.addr      = wine_server_client_ptr( addr );
+        call.virtual_free.size      = size;
+        call.virtual_free.op_type   = type;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_free.status == STATUS_SUCCESS)
+        {
+            *addr_ptr = wine_server_get_ptr( result.virtual_free.addr );
+            *size_ptr = result.virtual_free.size;
+        }
+        return result.virtual_free.status;
+    }
+
+    /* Fix the parameters */
+
+    if (size) size = ROUND_SIZE( addr, size );
+    base = ROUND_ADDR( addr, page_mask );
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    /* avoid freeing the DOS area when a broken app passes a NULL pointer */
+    if (!base)
+    {
+        /* address 1 is magic to mean release reserved space */
+        if (addr == (void *)1 && !size && type == MEM_RELEASE) virtual_release_address_space();
+        else status = STATUS_INVALID_PARAMETER;
+    }
+    else if (!(view = find_view( base, size )) || !is_view_valloc( view ))
+    {
+        status = STATUS_INVALID_PARAMETER;
+    }
+    else if (type == MEM_RELEASE)
+    {
+        /* Free the pages */
+
+        if (size) status = STATUS_INVALID_PARAMETER;
+        else if (base != view->base) status = STATUS_FREE_VM_NOT_AT_BASE;
+        else
+        {
+            *addr_ptr = base;
+            *size_ptr = view->size;
+            delete_view( view );
+        }
+    }
+    else if (type == MEM_DECOMMIT)
+    {
+        if (!size && base != view->base) status = STATUS_FREE_VM_NOT_AT_BASE;
+        else status = decommit_pages( view, base - (char *)view->base, size );
+        if (status == STATUS_SUCCESS)
+        {
+            *addr_ptr = base;
+            *size_ptr = size;
+        }
+    }
+    else
+    {
+        WARN("called with wrong free type flags (%08x) !\n", type);
+        status = STATUS_INVALID_PARAMETER;
+    }
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtProtectVirtualMemory   (NTDLL.@)
+ *             ZwProtectVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtProtectVirtualMemory( HANDLE process, PVOID *addr_ptr, SIZE_T *size_ptr,
+                                        ULONG new_prot, ULONG *old_prot )
+{
+    struct file_view *view;
+    sigset_t sigset;
+    NTSTATUS status = STATUS_SUCCESS;
+    char *base;
+    BYTE vprot;
+    SIZE_T size = *size_ptr;
+    LPVOID addr = *addr_ptr;
+    DWORD old;
+
+    TRACE("%p %p %08lx %08x\n", process, addr, size, new_prot );
+
+    if (!old_prot)
+        return STATUS_ACCESS_VIOLATION;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_protect.type = APC_VIRTUAL_PROTECT;
+        call.virtual_protect.addr = wine_server_client_ptr( addr );
+        call.virtual_protect.size = size;
+        call.virtual_protect.prot = new_prot;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_protect.status == STATUS_SUCCESS)
+        {
+            *addr_ptr = wine_server_get_ptr( result.virtual_protect.addr );
+            *size_ptr = result.virtual_protect.size;
+            *old_prot = result.virtual_protect.prot;
+        }
+        return result.virtual_protect.status;
+    }
+
+    /* Fix the parameters */
+
+    size = ROUND_SIZE( addr, size );
+    base = ROUND_ADDR( addr, page_mask );
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if ((view = find_view( base, size )))
+    {
+        /* Make sure all the pages are committed */
+        if (get_committed_size( view, base, &vprot, VPROT_COMMITTED ) >= size && (vprot & VPROT_COMMITTED))
+        {
+            old = get_win32_prot( vprot, view->protect );
+            status = set_protection( view, base, size, new_prot );
+        }
+        else status = STATUS_NOT_COMMITTED;
+    }
+    else status = STATUS_INVALID_PARAMETER;
+
+    if (!status) VIRTUAL_DEBUG_DUMP_VIEW( view );
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if (status == STATUS_SUCCESS)
+    {
+        *addr_ptr = base;
+        *size_ptr = size;
+        *old_prot = old;
+    }
+    return status;
+}
+
+
+/* retrieve state for a free memory area; callback for mmap_enum_reserved_areas */
+static int get_free_mem_state_callback( void *start, SIZE_T size, void *arg )
+{
+    MEMORY_BASIC_INFORMATION *info = arg;
+    void *end = (char *)start + size;
+
+    if ((char *)info->BaseAddress + info->RegionSize <= (char *)start) return 0;
+
+    if (info->BaseAddress >= end)
+    {
+        if (info->AllocationBase < end) info->AllocationBase = end;
+        return 0;
+    }
+
+    if (info->BaseAddress >= start || start <= address_space_start)
+    {
+        /* it's a real free area */
+        info->State             = MEM_FREE;
+        info->Protect           = PAGE_NOACCESS;
+        info->AllocationBase    = 0;
+        info->AllocationProtect = 0;
+        info->Type              = 0;
+        if ((char *)info->BaseAddress + info->RegionSize > (char *)end)
+            info->RegionSize = (char *)end - (char *)info->BaseAddress;
+    }
+    else /* outside of the reserved area, pretend it's allocated */
+    {
+        info->RegionSize        = (char *)start - (char *)info->BaseAddress;
+#ifdef __i386__
+        info->State             = MEM_RESERVE;
+        info->Protect           = PAGE_NOACCESS;
+        info->AllocationProtect = PAGE_NOACCESS;
+        info->Type              = MEM_PRIVATE;
+#else
+        info->State             = MEM_FREE;
+        info->Protect           = PAGE_NOACCESS;
+        info->AllocationBase    = 0;
+        info->AllocationProtect = 0;
+        info->Type              = 0;
+#endif
+    }
+    return 1;
+}
+
+/* get basic information about a memory block */
+static NTSTATUS get_basic_memory_info( HANDLE process, LPCVOID addr,
+                                       MEMORY_BASIC_INFORMATION *info,
+                                       SIZE_T len, SIZE_T *res_len )
+{
+    struct file_view *view;
+    char *base, *alloc_base = 0, *alloc_end = working_set_limit;
+    struct wine_rb_entry *ptr;
+    sigset_t sigset;
+
+    if (len < sizeof(MEMORY_BASIC_INFORMATION))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    if (process != NtCurrentProcess())
+    {
+        NTSTATUS status;
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_query.type = APC_VIRTUAL_QUERY;
+        call.virtual_query.addr = wine_server_client_ptr( addr );
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_query.status == STATUS_SUCCESS)
+        {
+            info->BaseAddress       = wine_server_get_ptr( result.virtual_query.base );
+            info->AllocationBase    = wine_server_get_ptr( result.virtual_query.alloc_base );
+            info->RegionSize        = result.virtual_query.size;
+            info->Protect           = result.virtual_query.prot;
+            info->AllocationProtect = result.virtual_query.alloc_prot;
+            info->State             = (DWORD)result.virtual_query.state << 12;
+            info->Type              = (DWORD)result.virtual_query.alloc_type << 16;
+            if (info->RegionSize != result.virtual_query.size)  /* truncated */
+                return STATUS_INVALID_PARAMETER;  /* FIXME */
+            if (res_len) *res_len = sizeof(*info);
+        }
+        return result.virtual_query.status;
+    }
+
+    base = ROUND_ADDR( addr, page_mask );
+
+    if (is_beyond_limit( base, 1, working_set_limit )) return STATUS_INVALID_PARAMETER;
+
+    /* Find the view containing the address */
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    ptr = views_tree.root;
+    while (ptr)
+    {
+        view = WINE_RB_ENTRY_VALUE( ptr, struct file_view, entry );
+        if ((char *)view->base > base)
+        {
+            alloc_end = view->base;
+            ptr = ptr->left;
+        }
+        else if ((char *)view->base + view->size <= base)
+        {
+            alloc_base = (char *)view->base + view->size;
+            ptr = ptr->right;
+        }
+        else
+        {
+            alloc_base = view->base;
+            alloc_end = (char *)view->base + view->size;
+            break;
+        }
+    }
+
+    /* Fill the info structure */
+
+    info->AllocationBase = alloc_base;
+    info->BaseAddress    = base;
+    info->RegionSize     = alloc_end - base;
+
+    if (!ptr)
+    {
+        if (!mmap_enum_reserved_areas( get_free_mem_state_callback, info, 0 ))
+        {
+            /* not in a reserved area at all, pretend it's allocated */
+#ifdef __i386__
+            if (base >= (char *)address_space_start)
+            {
+                info->State             = MEM_RESERVE;
+                info->Protect           = PAGE_NOACCESS;
+                info->AllocationProtect = PAGE_NOACCESS;
+                info->Type              = MEM_PRIVATE;
+            }
+            else
+#endif
+            {
+                info->State             = MEM_FREE;
+                info->Protect           = PAGE_NOACCESS;
+                info->AllocationBase    = 0;
+                info->AllocationProtect = 0;
+                info->Type              = 0;
+            }
+        }
+    }
+    else
+    {
+        BYTE vprot;
+
+        info->RegionSize = get_committed_size( view, base, &vprot, ~VPROT_WRITEWATCH );
+        info->State = (vprot & VPROT_COMMITTED) ? MEM_COMMIT : MEM_RESERVE;
+        info->Protect = (vprot & VPROT_COMMITTED) ? get_win32_prot( vprot, view->protect ) : 0;
+        info->AllocationProtect = get_win32_prot( view->protect, view->protect );
+        if (view->protect & SEC_IMAGE) info->Type = MEM_IMAGE;
+        else if (view->protect & (SEC_FILE | SEC_RESERVE | SEC_COMMIT)) info->Type = MEM_MAPPED;
+        else info->Type = MEM_PRIVATE;
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if (res_len) *res_len = sizeof(*info);
+    return STATUS_SUCCESS;
+}
+
+static NTSTATUS get_working_set_ex( HANDLE process, LPCVOID addr,
+                                    MEMORY_WORKING_SET_EX_INFORMATION *info,
+                                    SIZE_T len, SIZE_T *res_len )
+{
+    FILE *f = NULL;
+    MEMORY_WORKING_SET_EX_INFORMATION *p;
+    sigset_t sigset;
+
+    if (process != NtCurrentProcess())
+    {
+        FIXME( "(process=%p,addr=%p) Unimplemented information class: MemoryWorkingSetExInformation\n", process, addr );
+        return STATUS_INVALID_INFO_CLASS;
+    }
+
+#if defined(HAVE_LIBPROCSTAT)
+    {
+        struct procstat *pstat;
+        unsigned int proc_count;
+        struct kinfo_proc *kip = NULL;
+        unsigned int vmentry_count = 0;
+        struct kinfo_vmentry *vmentries = NULL;
+
+        pstat = procstat_open_sysctl();
+        if (pstat)
+            kip = procstat_getprocs( pstat, KERN_PROC_PID, getpid(), &proc_count );
+        if (kip)
+            vmentries = procstat_getvmmap( pstat, kip, &vmentry_count );
+        if (vmentries == NULL)
+            WARN( "couldn't get process vmmap, errno %d\n", errno );
+
+        server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+        for (p = info; (UINT_PTR)(p + 1) <= (UINT_PTR)info + len; p++)
+        {
+             int i;
+             struct kinfo_vmentry *entry = NULL;
+             BYTE vprot;
+             struct file_view *view;
+
+             for (i = 0; i < vmentry_count && entry == NULL; i++)
+             {
+                 if (vmentries[i].kve_start <= (ULONG_PTR)p->VirtualAddress && (ULONG_PTR)p->VirtualAddress <= vmentries[i].kve_end)
+                     entry = &vmentries[i];
+             }
+             memset( &p->VirtualAttributes, 0, sizeof(p->VirtualAttributes) );
+             if ((view = find_view( p->VirtualAddress, 0 )) &&
+                 get_committed_size( view, p->VirtualAddress, &vprot, VPROT_COMMITTED ) &&
+                 (vprot & VPROT_COMMITTED))
+             {
+                 p->VirtualAttributes.Valid = !(vprot & VPROT_GUARD) && (vprot & 0x0f) && entry && entry->kve_type != KVME_TYPE_SWAP;
+                 p->VirtualAttributes.Shared = !is_view_valloc( view );
+                 if (p->VirtualAttributes.Shared && p->VirtualAttributes.Valid)
+                     p->VirtualAttributes.ShareCount = 1; /* FIXME */
+                 if (p->VirtualAttributes.Valid)
+                     p->VirtualAttributes.Win32Protection = get_win32_prot( vprot, view->protect );
+             }
+        }
+        server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+
+        if (vmentries)
+            procstat_freevmmap( pstat, vmentries );
+        if (kip)
+            procstat_freeprocs( pstat, kip );
+        if (pstat)
+            procstat_close( pstat );
+    }
+#else
+    f = fopen( "/proc/self/pagemap", "rb" );
+    if (!f)
+    {
+        static int once;
+        if (!once++) WARN( "unable to open /proc/self/pagemap\n" );
+    }
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    for (p = info; (UINT_PTR)(p + 1) <= (UINT_PTR)info + len; p++)
+    {
+        BYTE vprot;
+        UINT64 pagemap;
+        struct file_view *view;
+
+        memset( &p->VirtualAttributes, 0, sizeof(p->VirtualAttributes) );
+
+        /* If we don't have pagemap information, default to invalid. */
+        if (!f || fseek( f, ((UINT_PTR)p->VirtualAddress >> 12) * sizeof(pagemap), SEEK_SET ) == -1 ||
+                fread( &pagemap, sizeof(pagemap), 1, f ) != 1)
+        {
+            pagemap = 0;
+        }
+
+        if ((view = find_view( p->VirtualAddress, 0 )) &&
+            get_committed_size( view, p->VirtualAddress, &vprot, VPROT_COMMITTED ) &&
+            (vprot & VPROT_COMMITTED))
+        {
+            p->VirtualAttributes.Valid = !(vprot & VPROT_GUARD) && (vprot & 0x0f) && (pagemap >> 63);
+            p->VirtualAttributes.Shared = !is_view_valloc( view ) && ((pagemap >> 61) & 1);
+            if (p->VirtualAttributes.Shared && p->VirtualAttributes.Valid)
+                p->VirtualAttributes.ShareCount = 1; /* FIXME */
+            if (p->VirtualAttributes.Valid)
+                p->VirtualAttributes.Win32Protection = get_win32_prot( vprot, view->protect );
+        }
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+#endif
+
+    if (f)
+        fclose( f );
+    if (res_len)
+        *res_len = (UINT_PTR)p - (UINT_PTR)info;
+    return STATUS_SUCCESS;
+}
+
+static NTSTATUS get_memory_section_name( HANDLE process, LPCVOID addr,
+                                         MEMORY_SECTION_NAME *info, SIZE_T len, SIZE_T *ret_len )
+{
+    NTSTATUS status;
+
+    if (!info) return STATUS_ACCESS_VIOLATION;
+
+    SERVER_START_REQ( get_mapping_filename )
+    {
+        req->process = wine_server_obj_handle( process );
+        req->addr = wine_server_client_ptr( addr );
+        if (len > sizeof(*info) + sizeof(WCHAR))
+            wine_server_set_reply( req, info + 1, len - sizeof(*info) - sizeof(WCHAR) );
+        status = wine_server_call( req );
+        if (!status || status == STATUS_BUFFER_OVERFLOW)
+        {
+            if (ret_len) *ret_len = sizeof(*info) + reply->len + sizeof(WCHAR);
+            if (len < sizeof(*info)) status = STATUS_INFO_LENGTH_MISMATCH;
+            if (!status)
+            {
+                info->SectionFileName.Buffer = (WCHAR *)(info + 1);
+                info->SectionFileName.Length = reply->len;
+                info->SectionFileName.MaximumLength = reply->len + sizeof(WCHAR);
+                info->SectionFileName.Buffer[reply->len / sizeof(WCHAR)] = 0;
+            }
+        }
+    }
+    SERVER_END_REQ;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtQueryVirtualMemory   (NTDLL.@)
+ *             ZwQueryVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtQueryVirtualMemory( HANDLE process, LPCVOID addr,
+                                      MEMORY_INFORMATION_CLASS info_class,
+                                      PVOID buffer, SIZE_T len, SIZE_T *res_len )
+{
+    NTSTATUS status;
+
+    TRACE("(%p, %p, info_class=%d, %p, %ld, %p)\n",
+          process, addr, info_class, buffer, len, res_len);
+
+    switch(info_class)
+    {
+        case MemoryBasicInformation:
+            return get_basic_memory_info( process, addr, buffer, len, res_len );
+
+        case MemoryWorkingSetExInformation:
+            return get_working_set_ex( process, addr, buffer, len, res_len );
+
+        case MemoryMappedFilenameInformation:
+            return get_memory_section_name( process, addr, buffer, len, res_len );
+
+        case MemoryWineUnixFuncs:
+        case MemoryWineUnixWow64Funcs:
+            if (len != sizeof(unixlib_handle_t)) return STATUS_INFO_LENGTH_MISMATCH;
+            if (process == GetCurrentProcess())
+            {
+                void *module = (void *)addr;
+                void *funcs = NULL;
+
+                status = get_builtin_unix_funcs( module, info_class == MemoryWineUnixWow64Funcs, &funcs );
+                if (!status) *(unixlib_handle_t *)buffer = (UINT_PTR)funcs;
+                return status;
+            }
+            return STATUS_INVALID_HANDLE;
+
+        default:
+            FIXME("(%p,%p,info_class=%d,%p,%ld,%p) Unknown information class\n",
+                  process, addr, info_class, buffer, len, res_len);
+            return STATUS_INVALID_INFO_CLASS;
+    }
+}
+
+
+/***********************************************************************
+ *             NtLockVirtualMemory   (NTDLL.@)
+ *             ZwLockVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtLockVirtualMemory( HANDLE process, PVOID *addr, SIZE_T *size, ULONG unknown )
+{
+    NTSTATUS status = STATUS_SUCCESS;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_lock.type = APC_VIRTUAL_LOCK;
+        call.virtual_lock.addr = wine_server_client_ptr( *addr );
+        call.virtual_lock.size = *size;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_lock.status == STATUS_SUCCESS)
+        {
+            *addr = wine_server_get_ptr( result.virtual_lock.addr );
+            *size = result.virtual_lock.size;
+        }
+        return result.virtual_lock.status;
+    }
+
+    *size = ROUND_SIZE( *addr, *size );
+    *addr = ROUND_ADDR( *addr, page_mask );
+
+    if (mlock( *addr, *size )) status = STATUS_ACCESS_DENIED;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtUnlockVirtualMemory   (NTDLL.@)
+ *             ZwUnlockVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtUnlockVirtualMemory( HANDLE process, PVOID *addr, SIZE_T *size, ULONG unknown )
+{
+    NTSTATUS status = STATUS_SUCCESS;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_unlock.type = APC_VIRTUAL_UNLOCK;
+        call.virtual_unlock.addr = wine_server_client_ptr( *addr );
+        call.virtual_unlock.size = *size;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_unlock.status == STATUS_SUCCESS)
+        {
+            *addr = wine_server_get_ptr( result.virtual_unlock.addr );
+            *size = result.virtual_unlock.size;
+        }
+        return result.virtual_unlock.status;
+    }
+
+    *size = ROUND_SIZE( *addr, *size );
+    *addr = ROUND_ADDR( *addr, page_mask );
+
+    if (munlock( *addr, *size )) status = STATUS_ACCESS_DENIED;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtMapViewOfSection   (NTDLL.@)
+ *             ZwMapViewOfSection   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtMapViewOfSection( HANDLE handle, HANDLE process, PVOID *addr_ptr, ULONG_PTR zero_bits,
+                                    SIZE_T commit_size, const LARGE_INTEGER *offset_ptr, SIZE_T *size_ptr,
+                                    SECTION_INHERIT inherit, ULONG alloc_type, ULONG protect )
+{
+    NTSTATUS res;
+    SIZE_T mask = granularity_mask;
+    LARGE_INTEGER offset;
+
+    offset.QuadPart = offset_ptr ? offset_ptr->QuadPart : 0;
+
+    TRACE("handle=%p process=%p addr=%p off=%x%08x size=%lx access=%x\n",
+          handle, process, *addr_ptr, offset.u.HighPart, offset.u.LowPart, *size_ptr, protect );
+
+    /* Check parameters */
+    if (zero_bits > 21 && zero_bits < 32)
+        return STATUS_INVALID_PARAMETER_4;
+
+    /* If both addr_ptr and zero_bits are passed, they have match */
+    if (*addr_ptr && zero_bits && zero_bits < 32 &&
+        (((UINT_PTR)*addr_ptr) >> (32 - zero_bits)))
+        return STATUS_INVALID_PARAMETER_4;
+    if (*addr_ptr && zero_bits >= 32 &&
+        (((UINT_PTR)*addr_ptr) & ~zero_bits))
+        return STATUS_INVALID_PARAMETER_4;
+
+#ifndef _WIN64
+    if (!is_wow64)
+    {
+        if (zero_bits >= 32) return STATUS_INVALID_PARAMETER_4;
+        if (alloc_type & AT_ROUND_TO_PAGE)
+        {
+            *addr_ptr = ROUND_ADDR( *addr_ptr, page_mask );
+            mask = page_mask;
+        }
+    }
+#endif
+
+    if ((offset.u.LowPart & mask) || (*addr_ptr && ((UINT_PTR)*addr_ptr & mask)))
+        return STATUS_MAPPED_ALIGNMENT;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.map_view.type         = APC_MAP_VIEW;
+        call.map_view.handle       = wine_server_obj_handle( handle );
+        call.map_view.addr         = wine_server_client_ptr( *addr_ptr );
+        call.map_view.size         = *size_ptr;
+        call.map_view.offset       = offset.QuadPart;
+        call.map_view.zero_bits    = zero_bits;
+        call.map_view.alloc_type   = alloc_type;
+        call.map_view.prot         = protect;
+        res = server_queue_process_apc( process, &call, &result );
+        if (res != STATUS_SUCCESS) return res;
+
+        if ((NTSTATUS)result.map_view.status >= 0)
+        {
+            *addr_ptr = wine_server_get_ptr( result.map_view.addr );
+            *size_ptr = result.map_view.size;
+        }
+        return result.map_view.status;
+    }
+
+    return virtual_map_section( handle, addr_ptr, zero_bits, commit_size,
+                                offset_ptr, size_ptr, alloc_type, protect );
+}
+
+
+/***********************************************************************
+ *             NtUnmapViewOfSection   (NTDLL.@)
+ *             ZwUnmapViewOfSection   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtUnmapViewOfSection( HANDLE process, PVOID addr )
+{
+    struct file_view *view;
+    NTSTATUS status = STATUS_NOT_MAPPED_VIEW;
+    sigset_t sigset;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.unmap_view.type = APC_UNMAP_VIEW;
+        call.unmap_view.addr = wine_server_client_ptr( addr );
+        status = server_queue_process_apc( process, &call, &result );
+        if (status == STATUS_SUCCESS) status = result.unmap_view.status;
+        return status;
+    }
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if ((view = find_view( addr, 0 )) && !is_view_valloc( view ))
+    {
+        if (view->protect & VPROT_SYSTEM)
+        {
+            struct builtin_module *builtin;
+
+            LIST_FOR_EACH_ENTRY( builtin, &builtin_modules, struct builtin_module, entry )
+            {
+                if (builtin->module != view->base) continue;
+                if (builtin->refcount > 1)
+                {
+                    TRACE( "not freeing in-use builtin %p\n", view->base );
+                    builtin->refcount--;
+                    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+                    return STATUS_SUCCESS;
+                }
+            }
+        }
+
+        SERVER_START_REQ( unmap_view )
+        {
+            req->base = wine_server_client_ptr( view->base );
+            status = wine_server_call( req );
+        }
+        SERVER_END_REQ;
+        if (!status)
+        {
+            if (view->protect & SEC_IMAGE) release_builtin_module( view->base );
+            delete_view( view );
+        }
+        else FIXME( "failed to unmap %p %x\n", view->base, status );
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/******************************************************************************
+ *             virtual_fill_image_information
+ *
+ * Helper for NtQuerySection.
+ */
+void virtual_fill_image_information( const pe_image_info_t *pe_info, SECTION_IMAGE_INFORMATION *info )
+{
+    info->TransferAddress             = wine_server_get_ptr( pe_info->base + pe_info->entry_point );
+    info->ZeroBits                    = pe_info->zerobits;
+    info->MaximumStackSize            = pe_info->stack_size;
+    info->CommittedStackSize          = pe_info->stack_commit;
+    info->SubSystemType               = pe_info->subsystem;
+    info->MinorSubsystemVersion       = pe_info->subsystem_minor;
+    info->MajorSubsystemVersion       = pe_info->subsystem_major;
+    info->MajorOperatingSystemVersion = pe_info->osversion_major;
+    info->MinorOperatingSystemVersion = pe_info->osversion_minor;
+    info->ImageCharacteristics        = pe_info->image_charact;
+    info->DllCharacteristics          = pe_info->dll_charact;
+    info->Machine                     = pe_info->machine;
+    info->ImageContainsCode           = pe_info->contains_code;
+    info->ImageFlags                  = pe_info->image_flags;
+    info->LoaderFlags                 = pe_info->loader_flags;
+    info->ImageFileSize               = pe_info->file_size;
+    info->CheckSum                    = pe_info->checksum;
+#ifndef _WIN64 /* don't return 64-bit values to 32-bit processes */
+    if (is_machine_64bit( pe_info->machine ))
+    {
+        info->TransferAddress = (void *)0x81231234;  /* sic */
+        info->MaximumStackSize = 0x100000;
+        info->CommittedStackSize = 0x10000;
+    }
+#endif
+}
+
+/******************************************************************************
+ *             NtQuerySection   (NTDLL.@)
+ *             ZwQuerySection   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtQuerySection( HANDLE handle, SECTION_INFORMATION_CLASS class, void *ptr,
+                                SIZE_T size, SIZE_T *ret_size )
+{
+    NTSTATUS status;
+    pe_image_info_t image_info;
+
+    switch (class)
+    {
+    case SectionBasicInformation:
+        if (size < sizeof(SECTION_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
+        break;
+    case SectionImageInformation:
+        if (size < sizeof(SECTION_IMAGE_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
+        break;
+    default:
+	FIXME( "class %u not implemented\n", class );
+	return STATUS_NOT_IMPLEMENTED;
+    }
+    if (!ptr) return STATUS_ACCESS_VIOLATION;
+
+    SERVER_START_REQ( get_mapping_info )
+    {
+        req->handle = wine_server_obj_handle( handle );
+        req->access = SECTION_QUERY;
+        wine_server_set_reply( req, &image_info, sizeof(image_info) );
+        if (!(status = wine_server_call( req )))
+        {
+            if (class == SectionBasicInformation)
+            {
+                SECTION_BASIC_INFORMATION *info = ptr;
+                info->Attributes    = reply->flags;
+                info->BaseAddress   = NULL;
+                info->Size.QuadPart = reply->size;
+                if (ret_size) *ret_size = sizeof(*info);
+            }
+            else if (reply->flags & SEC_IMAGE)
+            {
+                SECTION_IMAGE_INFORMATION *info = ptr;
+                virtual_fill_image_information( &image_info, info );
+                if (ret_size) *ret_size = sizeof(*info);
+            }
+            else status = STATUS_SECTION_NOT_IMAGE;
+        }
+    }
+    SERVER_END_REQ;
+
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtFlushVirtualMemory   (NTDLL.@)
+ *             ZwFlushVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtFlushVirtualMemory( HANDLE process, LPCVOID *addr_ptr,
+                                      SIZE_T *size_ptr, ULONG unknown )
+{
+    struct file_view *view;
+    NTSTATUS status = STATUS_SUCCESS;
+    sigset_t sigset;
+    void *addr = ROUND_ADDR( *addr_ptr, page_mask );
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_flush.type = APC_VIRTUAL_FLUSH;
+        call.virtual_flush.addr = wine_server_client_ptr( addr );
+        call.virtual_flush.size = *size_ptr;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_flush.status == STATUS_SUCCESS)
+        {
+            *addr_ptr = wine_server_get_ptr( result.virtual_flush.addr );
+            *size_ptr = result.virtual_flush.size;
+        }
+        return result.virtual_flush.status;
+    }
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+    if (!(view = find_view( addr, *size_ptr ))) status = STATUS_INVALID_PARAMETER;
+    else
+    {
+        if (!*size_ptr) *size_ptr = view->size;
+        *addr_ptr = addr;
+#ifdef MS_ASYNC
+        if (msync( addr, *size_ptr, MS_ASYNC )) status = STATUS_NOT_MAPPED_DATA;
+#endif
+    }
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtGetWriteWatch   (NTDLL.@)
+ *             ZwGetWriteWatch   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtGetWriteWatch( HANDLE process, ULONG flags, PVOID base, SIZE_T size, PVOID *addresses,
+                                 ULONG_PTR *count, ULONG *granularity )
+{
+    NTSTATUS status = STATUS_SUCCESS;
+    sigset_t sigset;
+
+    size = ROUND_SIZE( base, size );
+    base = ROUND_ADDR( base, page_mask );
+
+    if (!count || !granularity) return STATUS_ACCESS_VIOLATION;
+    if (!*count || !size) return STATUS_INVALID_PARAMETER;
+    if (flags & ~WRITE_WATCH_FLAG_RESET) return STATUS_INVALID_PARAMETER;
+
+    if (!addresses) return STATUS_ACCESS_VIOLATION;
+
+    TRACE( "%p %x %p-%p %p %lu\n", process, flags, base, (char *)base + size,
+           addresses, *count );
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if (is_write_watch_range( base, size ))
+    {
+        ULONG_PTR pos = 0;
+        char *addr = base;
+        char *end = addr + size;
+
+        while (pos < *count && addr < end)
+        {
+            if (!(get_page_vprot( addr ) & VPROT_WRITEWATCH)) addresses[pos++] = addr;
+            addr += page_size;
+        }
+        if (flags & WRITE_WATCH_FLAG_RESET) reset_write_watches( base, addr - (char *)base );
+        *count = pos;
+        *granularity = page_size;
+    }
+    else status = STATUS_INVALID_PARAMETER;
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtResetWriteWatch   (NTDLL.@)
+ *             ZwResetWriteWatch   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtResetWriteWatch( HANDLE process, PVOID base, SIZE_T size )
+{
+    NTSTATUS status = STATUS_SUCCESS;
+    sigset_t sigset;
+
+    size = ROUND_SIZE( base, size );
+    base = ROUND_ADDR( base, page_mask );
+
+    TRACE( "%p %p-%p\n", process, base, (char *)base + size );
+
+    if (!size) return STATUS_INVALID_PARAMETER;
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    if (is_write_watch_range( base, size ))
+        reset_write_watches( base, size );
+    else
+        status = STATUS_INVALID_PARAMETER;
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtReadVirtualMemory   (NTDLL.@)
+ *             ZwReadVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtReadVirtualMemory( HANDLE process, const void *addr, void *buffer,
+                                     SIZE_T size, SIZE_T *bytes_read )
+{
+    NTSTATUS status;
+
+    if (virtual_check_buffer_for_write( buffer, size ))
+    {
+        SERVER_START_REQ( read_process_memory )
+        {
+            req->handle = wine_server_obj_handle( process );
+            req->addr   = wine_server_client_ptr( addr );
+            wine_server_set_reply( req, buffer, size );
+            if ((status = wine_server_call( req ))) size = 0;
+        }
+        SERVER_END_REQ;
+    }
+    else
+    {
+        status = STATUS_ACCESS_VIOLATION;
+        size = 0;
+    }
+    if (bytes_read) *bytes_read = size;
+    return status;
+}
+
+#ifdef __APPLE__
+static int is_apple_silicon(void)
+{
+    static int apple_silicon_status, did_check = 0;
+    if (!did_check)
+    {
+        /* returns 0 for native process or on error, 1 for translated */
+        int ret = 0;
+        size_t size = sizeof(ret);
+        if (sysctlbyname( "sysctl.proc_translated", &ret, &size, NULL, 0 ) == -1)
+            apple_silicon_status = 0;
+        else
+            apple_silicon_status = ret;
+
+        did_check = 1;
+    }
+
+    return apple_silicon_status;
+}
+
+/* CW HACK 18947
+ * If mach_vm_write() is used to modify code cross-process (which is how we implement
+ * NtWriteVirtualMemory), Rosetta won't notice the change and will execute the "old" code.
+ *
+ * To work around this, after the write completes,
+ * toggle the executable bit (from inside the target process) on/off for any executable
+ * pages that were modified, to force Rosetta to re-translate it.
+ */
+static void toggle_executable_pages_for_rosetta( HANDLE process, void *addr, SIZE_T size )
+{
+    MEMORY_BASIC_INFORMATION info;
+    NTSTATUS status;
+    SIZE_T ret;
+
+    if (!is_apple_silicon())
+        return;
+
+    status = NtQueryVirtualMemory( process, addr, MemoryBasicInformation, &info, sizeof(info), &ret );
+
+    if (!status && (info.AllocationProtect & 0xf0))
+    {
+        DWORD origprot, noexec;
+        noexec = info.AllocationProtect & ~0xf0;
+        if (!noexec) noexec = PAGE_NOACCESS;
+
+        NtProtectVirtualMemory( process, &addr, &size, noexec, &origprot );
+        NtProtectVirtualMemory( process, &addr, &size, origprot, &noexec );
+    }
+}
+#endif
+
+/***********************************************************************
+ *             NtWriteVirtualMemory   (NTDLL.@)
+ *             ZwWriteVirtualMemory   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtWriteVirtualMemory( HANDLE process, void *addr, const void *buffer,
+                                      SIZE_T size, SIZE_T *bytes_written )
+{
+    NTSTATUS status;
+
+    if (virtual_check_buffer_for_read( buffer, size ))
+    {
+        SERVER_START_REQ( write_process_memory )
+        {
+            req->handle     = wine_server_obj_handle( process );
+            req->addr       = wine_server_client_ptr( addr );
+            wine_server_add_data( req, buffer, size );
+            if ((status = wine_server_call( req ))) size = 0;
+        }
+        SERVER_END_REQ;
+
+#ifdef __APPLE__
+        toggle_executable_pages_for_rosetta( process, addr, size );
+#endif
+    }
+    else
+    {
+        status = STATUS_PARTIAL_COPY;
+        size = 0;
+    }
+    if (bytes_written) *bytes_written = size;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtAreMappedFilesTheSame   (NTDLL.@)
+ *             ZwAreMappedFilesTheSame   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtAreMappedFilesTheSame(PVOID addr1, PVOID addr2)
+{
+    struct file_view *view1, *view2;
+    NTSTATUS status;
+    sigset_t sigset;
+
+    TRACE("%p %p\n", addr1, addr2);
+
+    server_enter_uninterrupted_section( &virtual_mutex, &sigset );
+
+    view1 = find_view( addr1, 0 );
+    view2 = find_view( addr2, 0 );
+
+    if (!view1 || !view2)
+        status = STATUS_INVALID_ADDRESS;
+    else if (is_view_valloc( view1 ) || is_view_valloc( view2 ))
+        status = STATUS_CONFLICTING_ADDRESSES;
+    else if (view1 == view2)
+        status = STATUS_SUCCESS;
+    else if ((view1->protect & VPROT_SYSTEM) || (view2->protect & VPROT_SYSTEM))
+        status = STATUS_NOT_SAME_DEVICE;
+    else
+    {
+        SERVER_START_REQ( is_same_mapping )
+        {
+            req->base1 = wine_server_client_ptr( view1->base );
+            req->base2 = wine_server_client_ptr( view2->base );
+            status = wine_server_call( req );
+        }
+        SERVER_END_REQ;
+    }
+
+    server_leave_uninterrupted_section( &virtual_mutex, &sigset );
+    return status;
+}
+
+
+/**********************************************************************
+ *           NtFlushInstructionCache  (NTDLL.@)
+ */
+NTSTATUS WINAPI NtFlushInstructionCache( HANDLE handle, const void *addr, SIZE_T size )
+{
+#if defined(__x86_64__) || defined(__i386__)
+    /* no-op */
+#elif defined(HAVE___CLEAR_CACHE)
+    if (handle == GetCurrentProcess())
+    {
+        __clear_cache( (char *)addr, (char *)addr + size );
+    }
+    else
+    {
+        static int once;
+        if (!once++) FIXME( "%p %p %ld other process not supported\n", handle, addr, size );
+    }
+#else
+    static int once;
+    if (!once++) FIXME( "%p %p %ld\n", handle, addr, size );
+#endif
+    return STATUS_SUCCESS;
+}
+
+
+/**********************************************************************
+ *           NtFlushProcessWriteBuffers  (NTDLL.@)
+ */
+void WINAPI NtFlushProcessWriteBuffers(void)
+{
+    static int once = 0;
+    if (!once++) FIXME( "stub\n" );
+}
+
+
+/**********************************************************************
+ *           NtCreatePagingFile  (NTDLL.@)
+ */
+NTSTATUS WINAPI NtCreatePagingFile( UNICODE_STRING *name, LARGE_INTEGER *min_size,
+                                    LARGE_INTEGER *max_size, LARGE_INTEGER *actual_size )
+{
+    FIXME( "(%s %p %p %p) stub\n", debugstr_us(name), min_size, max_size, actual_size );
+    return STATUS_SUCCESS;
+}
+
+#ifndef _WIN64
+
+/***********************************************************************
+ *             NtWow64AllocateVirtualMemory64   (NTDLL.@)
+ *             ZwWow64AllocateVirtualMemory64   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtWow64AllocateVirtualMemory64( HANDLE process, ULONG64 *ret, ULONG64 zero_bits,
+                                                ULONG64 *size_ptr, ULONG type, ULONG protect )
+{
+    void *base;
+    SIZE_T size;
+    NTSTATUS status;
+
+    TRACE("%p %s %s %x %08x\n", process,
+          wine_dbgstr_longlong(*ret), wine_dbgstr_longlong(*size_ptr), type, protect );
+
+    if (!*size_ptr) return STATUS_INVALID_PARAMETER_4;
+    if (zero_bits > 21 && zero_bits < 32) return STATUS_INVALID_PARAMETER_3;
+
+    if (process != NtCurrentProcess())
+    {
+        apc_call_t call;
+        apc_result_t result;
+
+        memset( &call, 0, sizeof(call) );
+
+        call.virtual_alloc.type         = APC_VIRTUAL_ALLOC;
+        call.virtual_alloc.addr         = *ret;
+        call.virtual_alloc.size         = *size_ptr;
+        call.virtual_alloc.zero_bits    = zero_bits;
+        call.virtual_alloc.op_type      = type;
+        call.virtual_alloc.prot         = protect;
+        status = server_queue_process_apc( process, &call, &result );
+        if (status != STATUS_SUCCESS) return status;
+
+        if (result.virtual_alloc.status == STATUS_SUCCESS)
+        {
+            *ret      = result.virtual_alloc.addr;
+            *size_ptr = result.virtual_alloc.size;
+        }
+        return result.virtual_alloc.status;
+    }
+
+    base = (void *)(ULONG_PTR)*ret;
+    size = *size_ptr;
+    if ((ULONG_PTR)base != *ret) return STATUS_CONFLICTING_ADDRESSES;
+    if (size != *size_ptr) return STATUS_WORKING_SET_LIMIT_RANGE;
+
+    status = NtAllocateVirtualMemory( process, &base, zero_bits, &size, type, protect );
+    if (!status)
+    {
+        *ret = (ULONG_PTR)base;
+        *size_ptr = size;
+    }
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtWow64ReadVirtualMemory64   (NTDLL.@)
+ *             ZwWow64ReadVirtualMemory64   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtWow64ReadVirtualMemory64( HANDLE process, ULONG64 addr, void *buffer,
+                                            ULONG64 size, ULONG64 *bytes_read )
+{
+    NTSTATUS status;
+
+    if (size > MAXLONG) size = MAXLONG;
+
+    if (virtual_check_buffer_for_write( buffer, size ))
+    {
+        SERVER_START_REQ( read_process_memory )
+        {
+            req->handle = wine_server_obj_handle( process );
+            req->addr   = addr;
+            wine_server_set_reply( req, buffer, size );
+            if ((status = wine_server_call( req ))) size = 0;
+        }
+        SERVER_END_REQ;
+    }
+    else
+    {
+        status = STATUS_ACCESS_VIOLATION;
+        size = 0;
+    }
+    if (bytes_read) *bytes_read = size;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtWow64WriteVirtualMemory64   (NTDLL.@)
+ *             ZwWow64WriteVirtualMemory64   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtWow64WriteVirtualMemory64( HANDLE process, ULONG64 addr, const void *buffer,
+                                             ULONG64 size, ULONG64 *bytes_written )
+{
+    NTSTATUS status;
+
+    if (size > MAXLONG) size = MAXLONG;
+
+    if (virtual_check_buffer_for_read( buffer, size ))
+    {
+        SERVER_START_REQ( write_process_memory )
+        {
+            req->handle     = wine_server_obj_handle( process );
+            req->addr       = addr;
+            wine_server_add_data( req, buffer, size );
+            if ((status = wine_server_call( req ))) size = 0;
+        }
+        SERVER_END_REQ;
+    }
+    else
+    {
+        status = STATUS_PARTIAL_COPY;
+        size = 0;
+    }
+    if (bytes_written) *bytes_written = size;
+    return status;
+}
+
+
+/***********************************************************************
+ *             NtWow64GetNativeSystemInformation   (NTDLL.@)
+ *             ZwWow64GetNativeSystemInformation   (NTDLL.@)
+ */
+NTSTATUS WINAPI NtWow64GetNativeSystemInformation( SYSTEM_INFORMATION_CLASS class, void *info,
+                                                   ULONG len, ULONG *retlen )
+{
+    switch (class)
+    {
+    case SystemBasicInformation:
+    case SystemCpuInformation:
+    case SystemEmulationBasicInformation:
+    case SystemEmulationProcessorInformation:
+        return NtQuerySystemInformation( class, info, len, retlen );
+    case SystemNativeBasicInformation:
+        return NtQuerySystemInformation( SystemBasicInformation, info, len, retlen );
+    default:
+        if (is_wow64) return STATUS_INVALID_INFO_CLASS;
+        return NtQuerySystemInformation( class, info, len, retlen );
+    }
+}
+
+#endif  /* _WIN64 */
diff --git a/wine/include/wine/server_protocol.h b/wine/include/wine/server_protocol.h
index 8e5ffb8dc..1c1a913fe 100644
--- a/wine/include/wine/server_protocol.h
+++ b/wine/include/wine/server_protocol.h
@@ -5584,6 +5584,92 @@ struct get_esync_apc_fd_reply
     struct reply_header __header;
 };
 
+enum msync_type
+{
+    MSYNC_SEMAPHORE = 1,
+    MSYNC_AUTO_EVENT,
+    MSYNC_MANUAL_EVENT,
+    MSYNC_MUTEX,
+    MSYNC_AUTO_SERVER,
+    MSYNC_MANUAL_SERVER,
+    MSYNC_QUEUE,
+};
+
+
+struct create_msync_request
+{
+    struct request_header __header;
+    unsigned int access;
+    int low;
+    int high;
+    int type;
+    /* VARARG(objattr,object_attributes); */
+    char __pad_28[4];
+};
+struct create_msync_reply
+{
+    struct reply_header __header;
+    obj_handle_t handle;
+    int type;
+    unsigned int shm_idx;
+    char __pad_20[4];
+};
+
+
+struct open_msync_request
+{
+    struct request_header __header;
+    unsigned int access;
+    unsigned int attributes;
+    obj_handle_t rootdir;
+    int          type;
+    /* VARARG(name,unicode_str); */
+    char __pad_28[4];
+};
+struct open_msync_reply
+{
+    struct reply_header __header;
+    obj_handle_t handle;
+    int          type;
+    unsigned int shm_idx;
+    char __pad_20[4];
+};
+
+
+struct get_msync_idx_request
+{
+    struct request_header __header;
+    obj_handle_t handle;
+};
+struct get_msync_idx_reply
+{
+    struct reply_header __header;
+    int          type;
+    unsigned int shm_idx;
+};
+
+struct msync_msgwait_request
+{
+    struct request_header __header;
+    int          in_msgwait;
+};
+struct msync_msgwait_reply
+{
+    struct reply_header __header;
+};
+
+struct get_msync_apc_idx_request
+{
+    struct request_header __header;
+    char __pad_12[4];
+};
+struct get_msync_apc_idx_reply
+{
+    struct reply_header __header;
+    unsigned int shm_idx;
+    char __pad_12[4];
+};
+
 
 enum request
 {
@@ -5871,6 +5957,11 @@ enum request
     REQ_get_esync_write_fd,
     REQ_esync_msgwait,
     REQ_get_esync_apc_fd,
+    REQ_create_msync,
+    REQ_open_msync,
+    REQ_get_msync_idx,
+    REQ_msync_msgwait,
+    REQ_get_msync_apc_idx,
     REQ_NB_REQUESTS
 };
 
@@ -6162,6 +6253,11 @@ union generic_request
     struct get_esync_write_fd_request get_esync_write_fd_request;
     struct esync_msgwait_request esync_msgwait_request;
     struct get_esync_apc_fd_request get_esync_apc_fd_request;
+    struct create_msync_request create_msync_request;
+    struct open_msync_request open_msync_request;
+    struct get_msync_idx_request get_msync_idx_request;
+    struct msync_msgwait_request msync_msgwait_request;
+    struct get_msync_apc_idx_request get_msync_apc_idx_request;
 };
 union generic_reply
 {
@@ -6451,11 +6547,16 @@ union generic_reply
     struct get_esync_write_fd_reply get_esync_write_fd_reply;
     struct esync_msgwait_reply esync_msgwait_reply;
     struct get_esync_apc_fd_reply get_esync_apc_fd_reply;
+    struct create_msync_reply create_msync_reply;
+    struct open_msync_reply open_msync_reply;
+    struct get_msync_idx_reply get_msync_idx_reply;
+    struct msync_msgwait_reply msync_msgwait_reply;
+    struct get_msync_apc_idx_reply get_msync_apc_idx_reply;
 };
 
 /* ### protocol_version begin ### */
 
-#define SERVER_PROTOCOL_VERSION 755
+#define SERVER_PROTOCOL_VERSION 762
 
 /* ### protocol_version end ### */
 
diff --git a/wine/server/Makefile.in b/wine/server/Makefile.in
index 9f543491e..39f8569a8 100644
--- a/wine/server/Makefile.in
+++ b/wine/server/Makefile.in
@@ -15,6 +15,7 @@ C_SRCS = \
 	event.c \
 	fd.c \
 	file.c \
+	msync.c \
 	handle.c \
 	hook.c \
 	mach.c \
diff --git a/wine/server/async.c b/wine/server/async.c
index 1e8e82f6b..eebce2fe0 100644
--- a/wine/server/async.c
+++ b/wine/server/async.c
@@ -78,6 +78,7 @@ static const struct object_ops async_ops =
     remove_queue,              /* remove_queue */
     async_signaled,            /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     async_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
@@ -619,6 +620,7 @@ static const struct object_ops iosb_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
diff --git a/wine/server/atom.c b/wine/server/atom.c
index d9824de8e..d99f10d6f 100644
--- a/wine/server/atom.c
+++ b/wine/server/atom.c
@@ -80,6 +80,7 @@ static const struct object_ops atom_table_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
diff --git a/wine/server/change.c b/wine/server/change.c
index dd9e0bfee..5f8804af7 100644
--- a/wine/server/change.c
+++ b/wine/server/change.c
@@ -113,6 +113,7 @@ static const struct object_ops dir_ops =
     remove_queue,             /* remove_queue */
     default_fd_signaled,      /* signaled */
     default_fd_get_esync_fd,  /* get_esync_fd */
+    default_fd_get_msync_idx, /* get_msync_idx */
     no_satisfied,             /* satisfied */
     no_signal,                /* signal */
     dir_get_fd,               /* get_fd */
diff --git a/wine/server/clipboard.c b/wine/server/clipboard.c
index 8b265f2dc..e7149f204 100644
--- a/wine/server/clipboard.c
+++ b/wine/server/clipboard.c
@@ -77,6 +77,7 @@ static const struct object_ops clipboard_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
diff --git a/wine/server/completion.c b/wine/server/completion.c
index 3d4be86a2..d761d3723 100644
--- a/wine/server/completion.c
+++ b/wine/server/completion.c
@@ -76,6 +76,7 @@ static const struct object_ops completion_ops =
     remove_queue,              /* remove_queue */
     completion_signaled,       /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
diff --git a/wine/server/console.c b/wine/server/console.c
index b35e09abe..eba113131 100644
--- a/wine/server/console.c
+++ b/wine/server/console.c
@@ -42,6 +42,7 @@
 #include "winternl.h"
 #include "wine/condrv.h"
 #include "esync.h"
+#include "msync.h"
 
 struct screen_buffer;
 
@@ -83,6 +84,7 @@ static const struct object_ops console_ops =
     remove_queue,                     /* remove_queue */
     console_signaled,                 /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_get_fd,                   /* get_fd */
@@ -142,12 +144,14 @@ struct console_server
     int                   term_fd;     /* UNIX terminal fd */
     struct termios        termios;     /* original termios */
     struct esync_fd      *esync_fd;
+    unsigned int          msync_idx;
 };
 
 static void console_server_dump( struct object *obj, int verbose );
 static void console_server_destroy( struct object *obj );
 static int console_server_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *console_server_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int console_server_get_msync_idx( struct object *obj, enum msync_type *type );
 static struct fd *console_server_get_fd( struct object *obj );
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
                                                 unsigned int attr, struct object *root );
@@ -163,6 +167,7 @@ static const struct object_ops console_server_ops =
     remove_queue,                     /* remove_queue */
     console_server_signaled,          /* signaled */
     console_server_get_esync_fd,      /* get_esync_fd */
+    console_server_get_msync_idx,     /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_server_get_fd,            /* get_fd */
@@ -233,6 +238,7 @@ static const struct object_ops screen_buffer_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     NULL,                             /* satisfied */
     no_signal,                        /* signal */
     screen_buffer_get_fd,             /* get_fd */
@@ -283,6 +289,7 @@ static const struct object_ops console_device_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
@@ -321,6 +328,7 @@ static const struct object_ops console_input_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_input_get_fd,             /* get_fd */
@@ -379,6 +387,7 @@ static const struct object_ops console_output_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_output_get_fd,            /* get_fd */
@@ -438,6 +447,7 @@ static const struct object_ops console_connection_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_connection_get_fd,        /* get_fd */
@@ -600,8 +610,13 @@ static void disconnect_console_server( struct console_server *server )
         list_remove( &call->entry );
         console_host_ioctl_terminate( call, STATUS_CANCELLED );
     }
+
+    if (do_msync())
+        msync_clear_shm( server->msync_idx );
+
     if (do_esync())
         esync_clear( server->esync_fd );
+
     while (!list_empty( &server->read_queue ))
     {
         struct console_host_ioctl *call = LIST_ENTRY( list_head( &server->read_queue ), struct console_host_ioctl, entry );
@@ -883,6 +898,7 @@ static void console_server_destroy( struct object *obj )
     disconnect_console_server( server );
     if (server->fd) release_object( server->fd );
     if (do_esync()) esync_close_fd( server->esync_fd );
+    if (do_msync()) msync_destroy_semaphore( server->msync_idx );
 }
 
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
@@ -931,6 +947,13 @@ static struct esync_fd *console_server_get_esync_fd( struct object *obj, enum es
     return server->esync_fd;
 }
 
+static unsigned int console_server_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct console_server *server = (struct console_server*)obj;
+    *type = MSYNC_MANUAL_SERVER;
+    return server->msync_idx;
+}
+
 static struct fd *console_server_get_fd( struct object* obj )
 {
     struct console_server *server = (struct console_server*)obj;
@@ -963,6 +986,9 @@ static struct object *create_console_server( void )
     }
     allow_fd_caching(server->fd);
     server->esync_fd = NULL;
+    
+    if (do_msync())
+        server->msync_idx = msync_alloc_shm( 0, 0 );
 
     if (do_esync())
         server->esync_fd = esync_create_fd( 0, 0 );
@@ -1579,6 +1605,10 @@ DECL_HANDLER(get_next_console_request)
         /* set result of previous ioctl */
         ioctl = LIST_ENTRY( list_head( &server->queue ), struct console_host_ioctl, entry );
         list_remove( &ioctl->entry );
+
+        if (do_msync() && list_empty( &server->queue ))
+            msync_clear_shm( server->msync_idx );
+
         if (do_esync() && list_empty( &server->queue ))
             esync_clear( server->esync_fd );
     }
@@ -1666,6 +1696,10 @@ DECL_HANDLER(get_next_console_request)
     {
         set_error( STATUS_PENDING );
     }
+
+    if (do_msync() && list_empty( &server->queue ))
+        msync_clear_shm( server->msync_idx );
+
     if (do_esync() && list_empty( &server->queue ))
         esync_clear( server->esync_fd );
 
diff --git a/wine/server/debugger.c b/wine/server/debugger.c
index d85a20006..ceb3b85a5 100644
--- a/wine/server/debugger.c
+++ b/wine/server/debugger.c
@@ -87,6 +87,7 @@ static const struct object_ops debug_event_ops =
     remove_queue,                  /* remove_queue */
     debug_event_signaled,          /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
@@ -116,6 +117,7 @@ static const struct object_ops debug_obj_ops =
     remove_queue,                  /* remove_queue */
     debug_obj_signaled,            /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
diff --git a/wine/server/device.c b/wine/server/device.c
index f76590db4..baec792d9 100644
--- a/wine/server/device.c
+++ b/wine/server/device.c
@@ -40,6 +40,7 @@
 #include "request.h"
 #include "process.h"
 #include "esync.h"
+#include "msync.h"
 
 /* IRP object */
 
@@ -69,6 +70,7 @@ static const struct object_ops irp_call_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     NULL,                             /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
@@ -96,11 +98,13 @@ struct device_manager
     struct irp_call       *current_call;   /* call currently executed on client side */
     struct wine_rb_tree    kernel_objects; /* map of objects that have client side pointer associated */
     struct esync_fd       *esync_fd;       /* esync file descriptor */
+    unsigned int           msync_idx;
 };
 
 static void device_manager_dump( struct object *obj, int verbose );
 static int device_manager_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *device_manager_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int device_manager_get_msync_idx( struct object *obj, enum msync_type *type );
 static void device_manager_destroy( struct object *obj );
 
 static const struct object_ops device_manager_ops =
@@ -112,6 +116,7 @@ static const struct object_ops device_manager_ops =
     remove_queue,                     /* remove_queue */
     device_manager_signaled,          /* signaled */
     device_manager_get_esync_fd,      /* get_esync_fd */
+    device_manager_get_msync_idx,     /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
@@ -170,6 +175,7 @@ static const struct object_ops device_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
@@ -223,6 +229,7 @@ static const struct object_ops device_file_ops =
     remove_queue,                     /* remove_queue */
     default_fd_signaled,              /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     device_file_get_fd,               /* get_fd */
@@ -755,6 +762,9 @@ static void delete_file( struct device_file *file )
     /* terminate all pending requests */
     LIST_FOR_EACH_ENTRY_SAFE( irp, next, &file->requests, struct irp_call, dev_entry )
     {
+        if (do_msync() && file->device->manager && list_empty( &file->device->manager->requests ))
+            msync_clear( &file->device->manager->obj );
+
         if (do_esync() && file->device->manager && list_empty( &file->device->manager->requests ))
             esync_clear( file->device->manager->esync_fd );
 
@@ -800,6 +810,13 @@ static struct esync_fd *device_manager_get_esync_fd( struct object *obj, enum es
     return manager->esync_fd;
 }
 
+static unsigned int device_manager_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct device_manager *manager = (struct device_manager *)obj;
+    *type = MSYNC_MANUAL_SERVER;
+    return manager->msync_idx;
+}
+
 static void device_manager_destroy( struct object *obj )
 {
     struct device_manager *manager = (struct device_manager *)obj;
@@ -834,6 +851,9 @@ static void device_manager_destroy( struct object *obj )
         assert( !irp->file && !irp->async );
         release_object( irp );
     }
+    
+    if (do_msync())
+        msync_destroy_semaphore( manager->msync_idx );
 
     if (do_esync())
         esync_close_fd( manager->esync_fd );
@@ -850,6 +870,9 @@ static struct device_manager *create_device_manager(void)
         list_init( &manager->requests );
         wine_rb_init( &manager->kernel_objects, compare_kernel_object );
 
+        if (do_msync())
+            manager->msync_idx = msync_alloc_shm( 0, 0 );
+
         if (do_esync())
             manager->esync_fd = esync_create_fd( 0, 0 );
     }
@@ -1042,6 +1065,9 @@ DECL_HANDLER(get_next_device_request)
                 if (irp->file) grab_object( irp );
                 manager->current_call = irp;
 
+                if (do_msync() && list_empty( &manager->requests ))
+                    msync_clear( &manager->obj );
+
                 if (do_esync() && list_empty( &manager->requests ))
                     esync_clear( manager->esync_fd );
             }
diff --git a/wine/server/directory.c b/wine/server/directory.c
index bc161b9ab..4670e172b 100644
--- a/wine/server/directory.c
+++ b/wine/server/directory.c
@@ -70,6 +70,7 @@ static const struct object_ops object_type_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
@@ -121,6 +122,7 @@ static const struct object_ops directory_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
diff --git a/wine/server/esync.c b/wine/server/esync.c
index 7bb35c6b3..2bccd8803 100644
--- a/wine/server/esync.c
+++ b/wine/server/esync.c
@@ -43,13 +43,14 @@
 #include "request.h"
 #include "file.h"
 #include "esync.h"
+#include "msync.h"
 
 int do_esync(void)
 {
     static int do_esync_cached = -1;
 
     if (do_esync_cached == -1)
-        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC")) && !do_msync();
 
     return do_esync_cached;
 }
@@ -137,6 +138,7 @@ const struct object_ops esync_ops =
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
     esync_get_esync_fd,        /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
diff --git a/wine/server/event.c b/wine/server/event.c
index 81eb780aa..b7b6e872b 100644
--- a/wine/server/event.c
+++ b/wine/server/event.c
@@ -36,6 +36,7 @@
 #include "request.h"
 #include "security.h"
 #include "esync.h"
+#include "msync.h"
 
 static const WCHAR event_name[] = {'E','v','e','n','t'};
 
@@ -58,12 +59,14 @@ struct event
     int            manual_reset;    /* is it a manual reset event? */
     int            signaled;        /* event has been signaled */
     struct esync_fd *esync_fd;        /* esync file descriptor */
+    unsigned int   msync_idx;
 };
 
 static void event_dump( struct object *obj, int verbose );
 static int event_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void event_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *event_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int event_get_msync_idx( struct object *obj, enum msync_type *type );
 static int event_signal( struct object *obj, unsigned int access);
 static struct list *event_get_kernel_obj_list( struct object *obj );
 static void event_destroy( struct object *obj );
@@ -77,6 +80,7 @@ static const struct object_ops event_ops =
     remove_queue,              /* remove_queue */
     event_signaled,            /* signaled */
     event_get_esync_fd,        /* get_esync_fd */
+    event_get_msync_idx,       /* get_msync_idx */
     event_satisfied,           /* satisfied */
     event_signal,              /* signal */
     no_get_fd,                 /* get_fd */
@@ -125,6 +129,7 @@ static const struct object_ops keyed_event_ops =
     remove_queue,                /* remove_queue */
     keyed_event_signaled,        /* signaled */
     NULL,                        /* get_esync_fd */
+    NULL,                        /* get_msync_idx */
     no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
@@ -157,6 +162,9 @@ struct event *create_event( struct object *root, const struct unicode_str *name,
             event->manual_reset = manual_reset;
             event->signaled     = initial_state;
 
+            if (do_msync())
+                event->msync_idx = msync_alloc_shm( initial_state, 0 );
+
             if (do_esync())
                 event->esync_fd = esync_create_fd( initial_state, 0 );
         }
@@ -167,6 +175,10 @@ struct event *create_event( struct object *root, const struct unicode_str *name,
 struct event *get_event_obj( struct process *process, obj_handle_t handle, unsigned int access )
 {
     struct object *obj;
+
+    if (do_msync() && (obj = get_handle_obj( process, handle, access, &msync_ops)))
+        return (struct event *)obj; /* even though it's not an event */
+
     if (do_esync() && (obj = get_handle_obj( process, handle, access, &esync_ops)))
         return (struct event *)obj; /* even though it's not an event */
 
@@ -179,10 +191,19 @@ static void pulse_event( struct event *event )
     /* wake up all waiters if manual reset, a single one otherwise */
     wake_up( &event->obj, !event->manual_reset );
     event->signaled = 0;
+
+    if (do_msync())
+        msync_clear( &event->obj );
 }
 
 void set_event( struct event *event )
 {
+    if (do_msync() && event->obj.ops == &msync_ops)
+    {
+        msync_set_event( (struct msync *)event );
+        return;
+    }
+
     if (do_esync() && event->obj.ops == &esync_ops)
     {
         esync_set_event( (struct esync *)event );
@@ -196,6 +217,12 @@ void set_event( struct event *event )
 
 void reset_event( struct event *event )
 {
+    if (do_msync() && event->obj.ops == &msync_ops)
+    {
+        msync_reset_event( (struct msync *)event );
+        return;
+    }
+
     if (do_esync() && event->obj.ops == &esync_ops)
     {
         esync_reset_event( (struct esync *)event );
@@ -203,6 +230,9 @@ void reset_event( struct event *event )
     }
     event->signaled = 0;
 
+    if (do_msync())
+        msync_clear( &event->obj );
+
     if (do_esync())
         esync_clear( event->esync_fd );
 }
@@ -229,6 +259,13 @@ static struct esync_fd *event_get_esync_fd( struct object *obj, enum esync_type
     return event->esync_fd;
 }
 
+static unsigned int event_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct event *event = (struct event *)obj;
+    *type = MSYNC_MANUAL_SERVER;
+    return event->msync_idx;
+}
+
 static void event_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct event *event = (struct event *)obj;
@@ -261,6 +298,9 @@ static void event_destroy( struct object *obj )
 {
     struct event *event = (struct event *)obj;
 
+    if (do_msync())
+        msync_destroy_semaphore( event->msync_idx );
+    
     if (do_esync())
         esync_close_fd( event->esync_fd );
 }
diff --git a/wine/server/fd.c b/wine/server/fd.c
index 13e43bdae..5cd7b40ae 100644
--- a/wine/server/fd.c
+++ b/wine/server/fd.c
@@ -97,6 +97,7 @@
 #include "process.h"
 #include "request.h"
 #include "esync.h"
+#include "msync.h"
 
 #include "winternl.h"
 #include "winioctl.h"
@@ -195,6 +196,7 @@ struct fd
     apc_param_t          comp_key;    /* completion key to set in completion events */
     unsigned int         comp_flags;  /* completion flags */
     struct esync_fd     *esync_fd;    /* esync file descriptor */
+    unsigned int         msync_idx;   /* msync shm index */
 };
 
 static void fd_dump( struct object *obj, int verbose );
@@ -209,6 +211,7 @@ static const struct object_ops fd_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
@@ -251,6 +254,7 @@ static const struct object_ops device_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
@@ -292,6 +296,7 @@ static const struct object_ops inode_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
@@ -335,6 +340,7 @@ static const struct object_ops file_lock_ops =
     remove_queue,               /* remove_queue */
     file_lock_signaled,         /* signaled */
     NULL,                       /* get_esync_fd */
+    NULL,                       /* get_msync_idx */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
@@ -1594,6 +1600,9 @@ static void fd_destroy( struct object *obj )
         free( fd->unix_name );
     }
 
+    if (do_msync())
+        msync_destroy_semaphore( fd->msync_idx );
+    
     if (do_esync())
         esync_close_fd( fd->esync_fd );
 }
@@ -1713,6 +1722,7 @@ static struct fd *alloc_fd_object(void)
     fd->completion = NULL;
     fd->comp_flags = 0;
     fd->esync_fd   = NULL;
+    fd->msync_idx  = 0;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
@@ -1722,6 +1732,9 @@ static struct fd *alloc_fd_object(void)
     if (do_esync())
         fd->esync_fd = esync_create_fd( 1, 0 );
 
+    if (do_msync())
+        fd->msync_idx = msync_alloc_shm( 1, 0 );
+
     if ((fd->poll_index = add_poll_user( fd )) == -1)
     {
         release_object( fd );
@@ -1756,14 +1769,19 @@ struct fd *alloc_pseudo_fd( const struct fd_ops *fd_user_ops, struct object *use
     fd->comp_flags = 0;
     fd->no_fd_status = STATUS_BAD_DEVICE_TYPE;
     fd->esync_fd   = NULL;
+    fd->msync_idx  = 0;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
     list_init( &fd->inode_entry );
     list_init( &fd->locks );
+    
+    if (do_msync())
+        fd->msync_idx = msync_alloc_shm( 0, 0 );
 
     if (do_esync())
         fd->esync_fd = esync_create_fd( 0, 0 );
+    
     return fd;
 }
 
@@ -2157,6 +2175,9 @@ void set_fd_signaled( struct fd *fd, int signaled )
     fd->signaled = signaled;
     if (signaled) wake_up( fd->user, 0 );
 
+    if (do_msync() && !signaled)
+        msync_clear( fd->user );
+
     if (do_esync() && !signaled)
         esync_clear( fd->esync_fd );
 }
@@ -2193,6 +2214,15 @@ struct esync_fd *default_fd_get_esync_fd( struct object *obj, enum esync_type *t
     return ret;
 }
 
+unsigned int default_fd_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct fd *fd = get_obj_fd( obj );
+    unsigned int ret = fd->msync_idx;
+    *type = MSYNC_MANUAL_SERVER;
+    release_object( fd );
+    return ret;
+}
+
 int default_fd_get_poll_events( struct fd *fd )
 {
     int events = 0;
diff --git a/wine/server/file.c b/wine/server/file.c
index 514b9fb1f..f4ca9227d 100644
--- a/wine/server/file.c
+++ b/wine/server/file.c
@@ -95,6 +95,7 @@ static const struct object_ops file_ops =
     remove_queue,                 /* remove_queue */
     default_fd_signaled,          /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     file_get_fd,                  /* get_fd */
diff --git a/wine/server/file.h b/wine/server/file.h
index 5e68b4fd4..2cd8d2187 100644
--- a/wine/server/file.h
+++ b/wine/server/file.h
@@ -107,6 +107,7 @@ extern void get_nt_name( struct fd *fd, struct unicode_str *name );
 
 extern int default_fd_signaled( struct object *obj, struct wait_queue_entry *entry );
 extern struct esync_fd *default_fd_get_esync_fd( struct object *obj, enum esync_type *type );
+extern unsigned int default_fd_get_msync_idx( struct object *obj, enum msync_type *type );
 extern int default_fd_get_poll_events( struct fd *fd );
 extern void default_poll_event( struct fd *fd, int event );
 extern void fd_cancel_async( struct fd *fd, struct async *async );
diff --git a/wine/server/handle.c b/wine/server/handle.c
index 53cc1e4eb..406ee3505 100644
--- a/wine/server/handle.c
+++ b/wine/server/handle.c
@@ -127,6 +127,7 @@ static const struct object_ops handle_table_ops =
     NULL,                            /* remove_queue */
     NULL,                            /* signaled */
     NULL,                            /* get_esync_fd */
+    NULL,                            /* get_msync_idx */
     NULL,                            /* satisfied */
     no_signal,                       /* signal */
     no_get_fd,                       /* get_fd */
diff --git a/wine/server/hook.c b/wine/server/hook.c
index da351d679..5b5e2e33c 100644
--- a/wine/server/hook.c
+++ b/wine/server/hook.c
@@ -81,6 +81,7 @@ static const struct object_ops hook_table_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
diff --git a/wine/server/mailslot.c b/wine/server/mailslot.c
index 4cf9b73f7..d04fc2f4e 100644
--- a/wine/server/mailslot.c
+++ b/wine/server/mailslot.c
@@ -75,6 +75,7 @@ static const struct object_ops mailslot_ops =
     remove_queue,              /* remove_queue */
     default_fd_signaled,       /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     mailslot_get_fd,           /* get_fd */
@@ -135,6 +136,7 @@ static const struct object_ops mail_writer_ops =
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
     NULL,                       /* get_esync_fd */
+    NULL,                       /* get_msync_idx */
     NULL,                       /* satisfied */
     no_signal,                  /* signal */
     mail_writer_get_fd,         /* get_fd */
@@ -199,6 +201,7 @@ static const struct object_ops mailslot_device_ops =
     NULL,                           /* remove_queue */
     NULL,                           /* signaled */
     NULL,                           /* get_esync_fd */
+    NULL,                           /* get_msync_idx */
     no_satisfied,                   /* satisfied */
     no_signal,                      /* signal */
     no_get_fd,                      /* get_fd */
@@ -230,6 +233,7 @@ static const struct object_ops mailslot_device_file_ops =
     remove_queue,                           /* remove_queue */
     default_fd_signaled,                    /* signaled */
     NULL,                                   /* get_esync_fd */
+    NULL,                                   /* get_msync_idx */
     no_satisfied,                           /* satisfied */
     no_signal,                              /* signal */
     mailslot_device_file_get_fd,            /* get_fd */
diff --git a/wine/server/main.c b/wine/server/main.c
index acf6f1188..2e0ded1d5 100644
--- a/wine/server/main.c
+++ b/wine/server/main.c
@@ -35,6 +35,7 @@
 #include "request.h"
 #include "unicode.h"
 #include "esync.h"
+#include "msync.h"
 
 /* command-line options */
 int debug_level = 0;
@@ -230,9 +231,15 @@ int main( int argc, char *argv[] )
     sock_init();
     open_master_socket();
 
+    if (do_msync())
+        msync_init();
+
     if (do_esync())
         esync_init();
 
+    if (!do_msync() && !do_esync())
+        fprintf( stderr, "wineserver: using server-side synchronization.\n" );
+
     if (debug_level) fprintf( stderr, "wineserver: starting (pid=%ld)\n", (long) getpid() );
     set_current_time();
     init_signals();
diff --git a/wine/server/mapping.c b/wine/server/mapping.c
index 23d9632bd..35220ba83 100644
--- a/wine/server/mapping.c
+++ b/wine/server/mapping.c
@@ -68,6 +68,7 @@ static const struct object_ops ranges_ops =
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
@@ -106,6 +107,7 @@ static const struct object_ops shared_map_ops =
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
@@ -181,6 +183,7 @@ static const struct object_ops mapping_ops =
     NULL,                        /* remove_queue */
     NULL,                        /* signaled */
     NULL,                        /* get_esync_fd */
+    NULL,                        /* get_msync_idx */
     NULL,                        /* satisfied */
     no_signal,                   /* signal */
     mapping_get_fd,              /* get_fd */
diff --git a/wine/server/msync.c b/wine/server/msync.c
new file mode 100644
index 000000000..f79d6e7ab
--- /dev/null
+++ b/wine/server/msync.c
@@ -0,0 +1,907 @@
+/*
+ * mach semaphore-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ * Copyright (C) 2023 Marc-Aurel Zent
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "config.h"
+
+#include <errno.h>
+#include <fcntl.h>
+#include <limits.h>
+#include <stdio.h>
+#include <stdarg.h>
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#ifdef __APPLE__
+# include <mach/mach_init.h>
+# include <mach/mach_port.h>
+# include <mach/message.h>
+# include <mach/port.h>
+# include <mach/task.h>
+# include <mach/semaphore.h>
+# include <mach/error.h>
+# include <servers/bootstrap.h>
+#endif
+#include <sched.h>
+#include <pthread.h>
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winternl.h"
+
+#include "handle.h"
+#include "request.h"
+#include "msync.h"
+
+/*
+ * We can't go higher because the maximum default size of of shared memory on XNU
+ * is 4MB and we are using 8 bytes per entry.
+ */
+#define MAX_INDEX 0x80000
+
+#ifdef __APPLE__
+
+#define MACH_CHECK_ERROR(ret, operation) \
+    if (ret != KERN_SUCCESS) \
+        fprintf(stderr, "msync: error: %s failed with %d: %s\n", \
+            operation, ret, mach_error_string(ret));
+
+/* Private API to register a mach port with the bootstrap server */
+extern kern_return_t bootstrap_register2( mach_port_t bp, name_t service_name, mach_port_t sp, int flags );
+
+extern mach_msg_return_t mach_msg_overwrite_trap( mach_msg_header_t *msg, mach_msg_option_t option,
+        mach_msg_size_t send_size, mach_msg_size_t rcv_size, mach_port_name_t rcv_name, mach_msg_timeout_t timeout,
+        mach_msg_priority_t priority, mach_msg_header_t *rcv_msg, mach_msg_size_t rcv_limit);
+
+static mach_port_name_t receive_port;
+
+struct sem_node
+{
+    struct sem_node *next;
+    semaphore_t sem;
+    int tid;
+};
+
+#define MAX_POOL_NODES MAX_INDEX * 2
+
+struct node_memory_pool
+{
+    struct sem_node *nodes;
+    struct sem_node **free_nodes;
+    unsigned int count;
+};
+
+static struct node_memory_pool *pool;
+
+static void pool_init(void)
+{
+    unsigned int i;
+    pool = malloc( sizeof(struct node_memory_pool) );
+    pool->nodes = malloc( MAX_POOL_NODES * sizeof(struct sem_node) );
+    pool->free_nodes = malloc( MAX_POOL_NODES * sizeof(struct sem_node *) );
+    pool->count = MAX_POOL_NODES;
+
+    for (i = 0; i < MAX_POOL_NODES; i++)
+        pool->free_nodes[i] = &pool->nodes[i];
+}
+
+static inline struct sem_node *pool_alloc(void)
+{
+    if (pool->count == 0)
+    {
+        fprintf( stderr, "msync: warn: node memory pool exhausted\n" );
+        return malloc( sizeof(struct sem_node) );
+    }
+    return pool->free_nodes[--pool->count];
+}
+
+static inline void pool_free( struct sem_node *node )
+{
+    if (node < pool->nodes || node >= pool->nodes + MAX_POOL_NODES)
+    {
+        free(node);
+        return;
+    }
+    pool->free_nodes[pool->count++] = node;
+}
+
+struct sem_list
+{
+    struct sem_node *head;
+    int is_used;
+    volatile int lock;
+};
+
+static inline void small_pause(void)
+{
+#if defined(__i386__) || defined(__x86_64__)
+    __asm__ __volatile__( "rep;nop" : : : "memory" );
+#else
+    __asm__ __volatile__( "" : : : "memory" );
+#endif
+}
+
+static inline void spinlock_lock( volatile int *lock )
+{
+    while(__atomic_test_and_set(lock, __ATOMIC_ACQUIRE))
+        while(__atomic_load_n(lock, __ATOMIC_RELAXED))
+            small_pause();
+}
+
+static inline void spinlock_unlock( volatile int *lock )
+{
+    __atomic_clear(lock, __ATOMIC_RELEASE);
+}
+
+static inline void add_sem( struct sem_list *list, semaphore_t sem, int tid )
+{
+    struct sem_node *new_node;
+
+    new_node = pool_alloc();
+    new_node->sem = sem;
+    new_node->tid = tid;
+
+    spinlock_lock(&list->lock);
+    new_node->next = list->head;
+    list->head = new_node;
+    spinlock_unlock(&list->lock);
+}
+
+static inline void remove_sem( struct sem_list *list, int tid )
+{
+    struct sem_node *current, *prev = NULL;
+
+    spinlock_lock(&list->lock);
+    current = list->head;
+    while (current != NULL)
+    {
+        if (current->tid == tid)
+        {
+            if (prev == NULL)
+                list->head = current->next;
+            else
+                prev->next = current->next;
+            pool_free(current);
+            break;
+        }
+        prev = current;
+        current = current->next;
+    }
+    spinlock_unlock(&list->lock);
+}
+
+static inline void destroy_all( struct sem_list *list )
+{
+    struct sem_node *temp, *current;
+
+    spinlock_lock(&list->lock);
+    current = list->head;
+    list->head = NULL;
+    list->is_used = 0;
+    spinlock_unlock(&list->lock);
+
+    while (current)
+    {
+        semaphore_destroy( mach_task_self(), current->sem );
+        temp = current;
+        current = current->next;
+        pool_free(temp);
+    }
+}
+
+static struct sem_list mach_semaphore_map[MAX_INDEX];
+
+static void signal_all_internal( unsigned int shm_idx )
+{
+    struct sem_node *current, *temp;
+    struct sem_list *list = mach_semaphore_map + shm_idx;
+
+    spinlock_lock(&list->lock);
+    current = list->head;
+    list->head = NULL;
+    spinlock_unlock(&list->lock);
+
+    while (current)
+    {
+        semaphore_signal( current->sem );
+        semaphore_destroy( mach_task_self(), current->sem );
+        temp = current;
+        current = current->next;
+        pool_free(temp);
+    }
+}
+
+/* thread-safe sequentially consistent guarantees relative to register/unregister
+ * are made by the mach messaging queue */
+static inline mach_msg_return_t signal_all( unsigned int shm_idx )
+{
+    __thread static mach_msg_header_t send_header;
+    send_header.msgh_bits = MACH_MSGH_BITS_REMOTE(MACH_MSG_TYPE_COPY_SEND);
+    send_header.msgh_id = shm_idx;
+    send_header.msgh_size = sizeof(send_header);
+    send_header.msgh_remote_port = receive_port;
+    
+    return mach_msg_overwrite_trap( &send_header, MACH_SEND_MSG, send_header.msgh_size,
+                0, MACH_PORT_NULL, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL, NULL, 0 );
+}
+
+static inline void add_sem_to_map( unsigned int index, semaphore_t sem, int tid )
+{
+    add_sem( mach_semaphore_map + index, sem, tid );
+}
+
+static inline void remove_sem_from_map( unsigned int index, int tid )
+{
+    remove_sem( mach_semaphore_map + index, tid );
+}
+
+typedef struct
+{
+    mach_msg_header_t header;
+    mach_msg_body_t body;
+    mach_msg_port_descriptor_t descriptor;
+    unsigned int shm_idx[MAXIMUM_WAIT_OBJECTS + 1];
+    mach_msg_trailer_t trailer;
+} mach_register_message_t;
+
+typedef struct
+{
+    mach_msg_header_t header;
+    unsigned int shm_idx[MAXIMUM_WAIT_OBJECTS + 1];
+    mach_msg_trailer_t trailer;
+} mach_unregister_message_t;
+
+static inline mach_msg_return_t receive_mach_msg( mach_register_message_t *buffer )
+{
+    return mach_msg_overwrite_trap( (mach_msg_header_t *)buffer, MACH_RCV_MSG, 0,
+            sizeof(*buffer), receive_port, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL, NULL, 0 );
+}
+
+static void *get_shm( unsigned int idx );
+
+static inline void decode_msgh_id( unsigned int msgh_id, unsigned int *tid, unsigned int *count )
+{
+    *tid = msgh_id >> 8;
+    *count = msgh_id & 0xFF;
+}
+
+static inline unsigned int check_if_mutex(unsigned int *shm_idx)
+{
+    unsigned int is_mutex = (*shm_idx >> 19) & 1;
+    *shm_idx &= ~(1 << 19);
+    return is_mutex;
+}
+
+static void *mach_message_pump( void *args )
+{
+    int i, val;
+    unsigned int tid, count, is_mutex;
+    int *addr;
+    mach_msg_return_t mr;
+    semaphore_t sem;
+    mach_register_message_t receive_message = { 0 };
+    mach_unregister_message_t *mach_unregister_message;
+    sigset_t set;
+
+    sigfillset( &set );
+    pthread_sigmask( SIG_BLOCK, &set, NULL );
+
+    for (;;)
+    {
+        mr = receive_mach_msg( &receive_message );
+        if (mr != MACH_MSG_SUCCESS)
+        {
+            fprintf( stderr, "msync: failed to receive message\n");
+            continue;
+        }
+
+        /*
+         * A message with no body is a signal_all operation where the shm_idx is the msgh_id.
+         * See signal_all( unsigned int shm_idx ) above.
+         */
+        if (receive_message.header.msgh_size == sizeof(mach_msg_header_t))
+        {
+            signal_all_internal( receive_message.header.msgh_id );
+            continue;
+        }
+
+        /*
+         * A message with a body which is not complex means this is a
+         * server_remove_wait operation
+         */
+        decode_msgh_id( receive_message.header.msgh_id, &tid, &count );
+        if (!MACH_MSGH_BITS_IS_COMPLEX(receive_message.header.msgh_bits))
+        {
+            mach_unregister_message = (mach_unregister_message_t *)&receive_message;
+            for (i = 0; i < count; i++)
+                remove_sem_from_map( mach_unregister_message->shm_idx[i], tid );
+
+            continue;
+        }
+
+        /*
+         * Finally server_register_wait
+         */
+        sem = receive_message.descriptor.name;
+        for (i = 0; i < count; i++)
+        {
+            is_mutex = check_if_mutex( receive_message.shm_idx + i );
+            addr = (int *)get_shm( receive_message.shm_idx[i] );
+            val = __atomic_load_n( addr, __ATOMIC_SEQ_CST );
+            if ((is_mutex && (val == 0 || val == ~0 || val == tid)) || (!is_mutex && val != 0))
+            {
+                /* The client had a TOCTTOU we need to fix */
+                semaphore_signal( sem );
+                semaphore_destroy( mach_task_self(), sem );
+                continue;
+            }
+            add_sem_to_map( receive_message.shm_idx[i], sem, tid );
+        }
+    }
+
+    return NULL;
+}
+
+#endif
+
+int do_msync(void)
+{
+#ifdef __APPLE__
+    static int do_msync_cached = -1;
+
+    if (do_msync_cached == -1)
+    {
+        do_msync_cached = getenv("WINEMSYNC") && atoi(getenv("WINEMSYNC"));
+    }
+
+    return do_msync_cached;
+#else
+    return 0;
+#endif
+}
+
+static char shm_name[29];
+static int shm_fd;
+static const off_t shm_size = MAX_INDEX * 8;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+static pthread_t message_thread;
+
+static int is_msync_initialized;
+
+static void cleanup(void)
+{
+    close( shm_fd );
+    if (shm_unlink( shm_name ) == -1)
+        perror( "shm_unlink" );
+}
+
+static void set_thread_policy_qos( mach_port_t mach_thread_id )
+{
+    thread_extended_policy_data_t extended_policy;
+    thread_precedence_policy_data_t precedence_policy;
+    int throughput_qos, latency_qos;
+    kern_return_t kr;
+
+    latency_qos = LATENCY_QOS_TIER_5;
+    kr = thread_policy_set( mach_thread_id, THREAD_LATENCY_QOS_POLICY,
+                            (thread_policy_t)&latency_qos,
+                            THREAD_LATENCY_QOS_POLICY_COUNT);
+    if (kr != KERN_SUCCESS)
+        fprintf(stderr, "msync: error setting thread latency QoS.");
+
+    throughput_qos = THROUGHPUT_QOS_TIER_5;
+    kr = thread_policy_set( mach_thread_id, THREAD_THROUGHPUT_QOS_POLICY,
+                            (thread_policy_t)&throughput_qos,
+                            THREAD_THROUGHPUT_QOS_POLICY_COUNT);
+    if (kr != KERN_SUCCESS)
+        fprintf(stderr, "msync: error setting thread throughput QoS.");
+
+    extended_policy.timeshare = 0;
+    kr = thread_policy_set( mach_thread_id, THREAD_EXTENDED_POLICY,
+                            (thread_policy_t)&extended_policy,
+                            THREAD_EXTENDED_POLICY_COUNT );
+    if (kr != KERN_SUCCESS)
+        fprintf( stderr, "msync: error setting extended policy\n" );
+
+    precedence_policy.importance = 63;
+    kr = thread_policy_set( mach_thread_id, THREAD_PRECEDENCE_POLICY,
+                            (thread_policy_t)&precedence_policy,
+                            THREAD_PRECEDENCE_POLICY_COUNT );
+    if (kr != KERN_SUCCESS)
+        fprintf( stderr, "msync: error setting precedence policy\n" );
+}
+
+void msync_init(void)
+{
+#ifdef __APPLE__
+    struct stat st;
+    mach_port_t bootstrap_port;
+    mach_port_limits_t limits;
+
+    if (fstat( config_dir_fd, &st ) == -1)
+        fatal_error( "cannot stat config dir\n" );
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-msync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-msync", (unsigned long)st.st_ino );
+
+    if (!shm_unlink( shm_name ))
+        fprintf( stderr, "msync: warning: a previous shm file %s was not properly removed\n", shm_name );
+
+    shm_fd = shm_open( shm_name, O_RDWR | O_CREAT | O_EXCL, 0644 );
+    if (shm_fd == -1)
+        perror( "shm_open" );
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    mach_semaphore_map[0].is_used = 1;
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+
+    if (ftruncate( shm_fd, shm_size ) == -1)
+    {
+        perror( "ftruncate" );
+        fatal_error( "could not initialize shared memory\n" );
+    }
+    
+    /* Bootstrap mach server message pump */
+    
+    MACH_CHECK_ERROR(mach_port_allocate(mach_task_self(), MACH_PORT_RIGHT_RECEIVE, &receive_port), "mach_port_allocate");
+
+    MACH_CHECK_ERROR(mach_port_insert_right(mach_task_self(), receive_port, receive_port, MACH_MSG_TYPE_MAKE_SEND), "mach_port_insert_right");
+
+    limits.mpl_qlimit = 50;
+
+    if (getenv("WINEMSYNC_QLIMIT"))
+        limits.mpl_qlimit = atoi(getenv("WINEMSYNC_QLIMIT"));
+
+    MACH_CHECK_ERROR(mach_port_set_attributes( mach_task_self(), receive_port, MACH_PORT_LIMITS_INFO,
+                                        (mach_port_info_t)&limits, MACH_PORT_LIMITS_INFO_COUNT), "mach_port_set_attributes");
+
+    MACH_CHECK_ERROR(task_get_special_port(mach_task_self(), TASK_BOOTSTRAP_PORT, &bootstrap_port), "task_get_special_port");
+
+    MACH_CHECK_ERROR(bootstrap_register2(bootstrap_port, shm_name + 1, receive_port, 0), "bootstrap_register2");
+    
+    pool_init();
+
+    if (pthread_create( &message_thread, NULL, mach_message_pump, NULL ))
+    {
+        perror("pthread_create");
+        fatal_error( "could not create mach message pump thread\n" );
+    }
+
+    set_thread_policy_qos( pthread_mach_thread_np( message_thread )) ;
+
+    fprintf( stderr, "msync: bootstrapped mach port on %s.\n", shm_name + 1 );
+
+    is_msync_initialized = 1;
+
+    fprintf( stderr, "msync: up and running.\n" );
+
+    atexit( cleanup );
+#endif
+}
+
+static struct list mutex_list = LIST_INIT(mutex_list);
+
+struct msync
+{
+    struct object  obj;
+    unsigned int   shm_idx;
+    enum msync_type type;
+    struct list     mutex_entry;
+};
+
+static void msync_dump( struct object *obj, int verbose );
+static unsigned int msync_get_msync_idx( struct object *obj, enum msync_type *type );
+static unsigned int msync_map_access( struct object *obj, unsigned int access );
+static void msync_destroy( struct object *obj );
+
+const struct object_ops msync_ops =
+{
+    sizeof(struct msync),      /* size */
+    &no_type,                  /* type */
+    msync_dump,                /* dump */
+    no_add_queue,              /* add_queue */
+    NULL,                      /* remove_queue */
+    NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
+    msync_get_msync_idx,       /* get_msync_idx */
+    NULL,                      /* satisfied */
+    no_signal,                 /* signal */
+    no_get_fd,                 /* get_fd */
+    msync_map_access,          /* map_access */
+    default_get_sd,            /* get_sd */
+    default_set_sd,            /* set_sd */
+    no_get_full_name,          /* get_full_name */
+    no_lookup_name,            /* lookup_name */
+    directory_link_name,       /* link_name */
+    default_unlink_name,       /* unlink_name */
+    no_open_file,              /* open_file */
+    no_kernel_obj_list,        /* get_kernel_obj_list */
+    no_close_handle,           /* close_handle */
+    msync_destroy              /* destroy */
+};
+
+static void msync_dump( struct object *obj, int verbose )
+{
+    struct msync *msync = (struct msync *)obj;
+    assert( obj->ops == &msync_ops );
+    fprintf( stderr, "msync idx=%d\n", msync->shm_idx );
+}
+
+static unsigned int msync_get_msync_idx( struct object *obj, enum msync_type *type)
+{
+    struct msync *msync = (struct msync *)obj;
+    *type = msync->type;
+    return msync->shm_idx;
+}
+
+static unsigned int msync_map_access( struct object *obj, unsigned int access )
+{
+    /* Sync objects have the same flags. */
+    if (access & GENERIC_READ)    access |= STANDARD_RIGHTS_READ | EVENT_QUERY_STATE;
+    if (access & GENERIC_WRITE)   access |= STANDARD_RIGHTS_WRITE | EVENT_MODIFY_STATE;
+    if (access & GENERIC_EXECUTE) access |= STANDARD_RIGHTS_EXECUTE | SYNCHRONIZE;
+    if (access & GENERIC_ALL)     access |= STANDARD_RIGHTS_ALL | EVENT_QUERY_STATE | EVENT_MODIFY_STATE;
+    return access & ~(GENERIC_READ | GENERIC_WRITE | GENERIC_EXECUTE | GENERIC_ALL);
+}
+
+static void msync_destroy( struct object *obj )
+{
+    struct msync *msync = (struct msync *)obj;
+    if (msync->type == MSYNC_MUTEX)
+        list_remove( &msync->mutex_entry );
+#ifdef __APPLE__
+    msync_destroy_semaphore( msync->shm_idx );
+#endif
+}
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            fprintf( stderr, "msync: couldn't expand shm_addrs array to size %d\n", entry + 1 );
+
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+        {
+            fprintf( stderr, "msync: failed to map page %d (offset %#lx): ", entry, entry * pagesize );
+            perror( "mmap" );
+        }
+
+        if (debug_level)
+            fprintf( stderr, "msync: Mapping page %d at %p.\n", entry, addr );
+
+        if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    return (void *)((unsigned long)shm_addrs[entry] + offset);
+}
+
+static unsigned int shm_idx_counter = 1;
+
+unsigned int msync_alloc_shm( int low, int high )
+{
+#ifdef __APPLE__
+    int shm_idx, tries = 0;
+    int *shm;
+
+    /* this is arguably a bit of a hack, but we need some way to prevent
+     * allocating shm for the master socket */
+    if (!is_msync_initialized)
+        return 0;
+
+    shm_idx = shm_idx_counter;
+
+    while (mach_semaphore_map[shm_idx].is_used)
+    {
+        shm_idx = (shm_idx + 1) % MAX_INDEX;
+        if (tries++ > MAX_INDEX)
+        {
+            /* The ftruncate call can only be succesfully done with a non-zero length
+             * once per shared memory region with XNU. We need to terminate now.
+             * Also we initialized with the default maximum size anyways... */
+            fatal_error( "too many msync objects\n" );
+        }
+    }
+    mach_semaphore_map[shm_idx].is_used = 1;
+    assert(mach_semaphore_map[shm_idx].head == NULL);
+    shm_idx_counter = (shm_idx + 1) % MAX_INDEX;
+
+    shm = get_shm( shm_idx );
+    assert(shm);
+    shm[0] = low;
+    shm[1] = high;
+
+    return shm_idx;
+#else
+    return 0;
+#endif
+}
+
+static int type_matches( enum msync_type type1, enum msync_type type2 )
+{
+    return (type1 == type2) ||
+           ((type1 == MSYNC_AUTO_EVENT || type1 == MSYNC_MANUAL_EVENT) &&
+            (type2 == MSYNC_AUTO_EVENT || type2 == MSYNC_MANUAL_EVENT));
+}
+
+struct msync *create_msync( struct object *root, const struct unicode_str *name,
+    unsigned int attr, int low, int high, enum msync_type type,
+    const struct security_descriptor *sd )
+{
+#ifdef __APPLE__
+    struct msync *msync;
+
+    if ((msync = create_named_object( root, &msync_ops, name, attr, sd )))
+    {
+        if (get_error() != STATUS_OBJECT_NAME_EXISTS)
+        {
+            /* initialize it if it didn't already exist */
+
+            /* Initialize the shared memory portion. We want to do this on the
+             * server side to avoid a potential though unlikely race whereby
+             * the same object is opened and used between the time it's created
+             * and the time its shared memory portion is initialized. */
+
+            msync->shm_idx = msync_alloc_shm( low, high );
+            msync->type = type;
+            if (type == MSYNC_MUTEX)
+                list_add_tail( &mutex_list, &msync->mutex_entry );
+        }
+        else
+        {
+            /* validate the type */
+            if (!type_matches( type, msync->type ))
+            {
+                release_object( &msync->obj );
+                set_error( STATUS_OBJECT_TYPE_MISMATCH );
+                return NULL;
+            }
+        }
+    }
+
+    return msync;
+#else
+    set_error( STATUS_NOT_IMPLEMENTED );
+    return NULL;
+#endif
+}
+
+/* shm layout for events or event-like objects. */
+struct msync_event
+{
+    int signaled;
+    int unused;
+};
+
+void msync_signal_all( unsigned int shm_idx )
+{
+    struct msync_event *event;
+
+    if (debug_level)
+        fprintf( stderr, "msync_signal_all: index %u\n", shm_idx );
+
+    if (!shm_idx)
+        return;
+
+    event = get_shm( shm_idx );
+    if (!__atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST ))
+        signal_all( shm_idx );
+}
+
+void msync_wake_up( struct object *obj )
+{
+    enum msync_type type;
+
+    if (debug_level)
+        fprintf( stderr, "msync_wake_up: object %p\n", obj );
+
+    if (obj->ops->get_msync_idx)
+        msync_signal_all( obj->ops->get_msync_idx( obj, &type ) );
+}
+
+void msync_destroy_semaphore( unsigned int shm_idx )
+{
+    if (!shm_idx) return;
+
+    destroy_all( mach_semaphore_map + shm_idx );
+}
+
+void msync_clear_shm( unsigned int shm_idx )
+{
+    struct msync_event *event;
+
+    if (debug_level)
+        fprintf( stderr, "msync_clear_shm: index %u\n", shm_idx );
+
+    if (!shm_idx)
+        return;
+
+    event = get_shm( shm_idx );
+    __atomic_store_n( &event->signaled, 0, __ATOMIC_SEQ_CST );
+}
+
+void msync_clear( struct object *obj )
+{
+    enum msync_type type;
+
+    if (debug_level)
+        fprintf( stderr, "msync_clear: object %p\n", obj );
+
+    if (obj->ops->get_msync_idx)
+        msync_clear_shm( obj->ops->get_msync_idx( obj, &type ) );
+}
+
+void msync_set_event( struct msync *msync )
+{
+    struct msync_event *event = get_shm( msync->shm_idx );
+    assert( msync->obj.ops == &msync_ops );
+
+    if (!__atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST ))
+        signal_all( msync->shm_idx );
+}
+
+void msync_reset_event( struct msync *msync )
+{
+    struct msync_event *event = get_shm( msync->shm_idx );
+    assert( msync->obj.ops == &msync_ops );
+
+    __atomic_store_n( &event->signaled, 0, __ATOMIC_SEQ_CST );
+}
+
+struct mutex
+{
+    int tid;
+    int count;  /* recursion count */
+};
+
+void msync_abandon_mutexes( struct thread *thread )
+{
+    struct msync *msync;
+
+    LIST_FOR_EACH_ENTRY( msync, &mutex_list, struct msync, mutex_entry )
+    {
+        struct mutex *mutex = get_shm( msync->shm_idx );
+
+        if (mutex->tid == thread->id)
+        {
+            if (debug_level)
+                fprintf( stderr, "msync_abandon_mutexes() idx=%d\n", msync->shm_idx );
+            mutex->tid = ~0;
+            mutex->count = 0;
+            signal_all ( msync->shm_idx );
+        }
+    }
+}
+
+DECL_HANDLER(create_msync)
+{
+    struct msync *msync;
+    struct unicode_str name;
+    struct object *root;
+    const struct security_descriptor *sd;
+    const struct object_attributes *objattr = get_req_object_attributes( &sd, &name, &root );
+
+    if (!do_msync())
+    {
+        set_error( STATUS_NOT_IMPLEMENTED );
+        return;
+    }
+
+    if (!objattr) return;
+
+    if ((msync = create_msync( root, &name, objattr->attributes, req->low,
+                               req->high, req->type, sd )))
+    {
+        if (get_error() == STATUS_OBJECT_NAME_EXISTS)
+            reply->handle = alloc_handle( current->process, msync, req->access, objattr->attributes );
+        else
+            reply->handle = alloc_handle_no_access_check( current->process, msync,
+                                                          req->access, objattr->attributes );
+
+        reply->shm_idx = msync->shm_idx;
+        reply->type = msync->type;
+        release_object( msync );
+    }
+
+    if (root) release_object( root );
+}
+
+DECL_HANDLER(open_msync)
+{
+    struct unicode_str name = get_req_unicode_str();
+
+    reply->handle = open_object( current->process, req->rootdir, req->access,
+                                 &msync_ops, &name, req->attributes );
+
+    if (reply->handle)
+    {
+        struct msync *msync;
+
+        if (!(msync = (struct msync *)get_handle_obj( current->process, reply->handle,
+                                                      0, &msync_ops )))
+            return;
+
+        if (!type_matches( req->type, msync->type ))
+        {
+            set_error( STATUS_OBJECT_TYPE_MISMATCH );
+            release_object( msync );
+            return;
+        }
+
+        reply->type = msync->type;
+        reply->shm_idx = msync->shm_idx;
+        release_object( msync );
+    }
+}
+
+/* Retrieve the index of a shm section which will be signaled by the server. */
+DECL_HANDLER(get_msync_idx)
+{
+    struct object *obj;
+    enum msync_type type;
+
+    if (!(obj = get_handle_obj( current->process, req->handle, SYNCHRONIZE, NULL )))
+        return;
+
+    if (obj->ops->get_msync_idx)
+    {
+        reply->shm_idx = obj->ops->get_msync_idx( obj, &type );
+        reply->type = type;
+    }
+    else
+    {
+        if (debug_level)
+        {
+            fprintf( stderr, "%04x: msync: can't wait on object: ", current->id );
+            obj->ops->dump( obj, 0 );
+        }
+        set_error( STATUS_NOT_IMPLEMENTED );
+    }
+
+    release_object( obj );
+}
+
+DECL_HANDLER(get_msync_apc_idx)
+{
+    reply->shm_idx = current->msync_apc_idx;
+}
diff --git a/wine/server/msync.h b/wine/server/msync.h
new file mode 100644
index 000000000..000aa48c5
--- /dev/null
+++ b/wine/server/msync.h
@@ -0,0 +1,36 @@
+/*
+ * mach semaphore-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ * Copyright (C) 2023 Marc-Aurel Zent
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+extern int do_msync(void);
+extern void msync_init(void);
+extern unsigned int msync_alloc_shm( int low, int high );
+extern void msync_signal_all( unsigned int shm_idx );
+extern void msync_clear_shm( unsigned int shm_idx );
+extern void msync_destroy_semaphore( unsigned int shm_idx );
+extern void msync_wake_up( struct object *obj );
+extern void msync_clear( struct object *obj );
+
+struct msync;
+
+extern const struct object_ops msync_ops;
+extern void msync_set_event( struct msync *msync );
+extern void msync_reset_event( struct msync *msync );
+extern void msync_abandon_mutexes( struct thread *thread );
diff --git a/wine/server/mutex.c b/wine/server/mutex.c
index 4785a830e..6a60adee0 100644
--- a/wine/server/mutex.c
+++ b/wine/server/mutex.c
@@ -74,6 +74,7 @@ static const struct object_ops mutex_ops =
     remove_queue,              /* remove_queue */
     mutex_signaled,            /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     mutex_satisfied,           /* satisfied */
     mutex_signal,              /* signal */
     no_get_fd,                 /* get_fd */
diff --git a/wine/server/named_pipe.c b/wine/server/named_pipe.c
index e01b28f72..bd66f3504 100644
--- a/wine/server/named_pipe.c
+++ b/wine/server/named_pipe.c
@@ -120,6 +120,7 @@ static const struct object_ops named_pipe_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
@@ -169,6 +170,7 @@ static const struct object_ops pipe_server_ops =
     remove_queue,                 /* remove_queue */
     default_fd_signaled,          /* signaled */
     default_fd_get_esync_fd,      /* get_esync_fd */
+    default_fd_get_msync_idx,     /* get_msync_idx */
     no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
@@ -214,6 +216,7 @@ static const struct object_ops pipe_client_ops =
     remove_queue,                 /* remove_queue */
     default_fd_signaled,          /* signaled */
     default_fd_get_esync_fd,      /* get_esync_fd */
+    default_fd_get_msync_idx,     /* get_msync_idx */
     no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
@@ -262,6 +265,7 @@ static const struct object_ops named_pipe_device_ops =
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
     NULL,                             /* get_esync_fd */
+    NULL,                             /* get_msync_idx */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
@@ -294,6 +298,7 @@ static const struct object_ops named_pipe_device_file_ops =
     remove_queue,                            /* remove_queue */
     default_fd_signaled,                     /* signaled */
     NULL,                                    /* get_esync_fd */
+    NULL,                                    /* get_msync_idx */
     no_satisfied,                            /* satisfied */
     no_signal,                               /* signal */
     named_pipe_device_file_get_fd,           /* get_fd */
diff --git a/wine/server/object.h b/wine/server/object.h
index d435aecfc..3bd0d0d41 100644
--- a/wine/server/object.h
+++ b/wine/server/object.h
@@ -80,6 +80,8 @@ struct object_ops
     int  (*signaled)(struct object *,struct wait_queue_entry *);
     /* return the esync fd for this object */
     struct esync_fd *(*get_esync_fd)(struct object *, enum esync_type *type);
+    /* return the msync shm idx for this object */
+    unsigned int (*get_msync_idx)(struct object *, enum msync_type *type);
     /* wait satisfied */
     void (*satisfied)(struct object *,struct wait_queue_entry *);
     /* signal an object */
diff --git a/wine/server/process.c b/wine/server/process.c
index fe8da762e..9b96bda61 100644
--- a/wine/server/process.c
+++ b/wine/server/process.c
@@ -64,6 +64,7 @@
 #include "user.h"
 #include "security.h"
 #include "esync.h"
+#include "msync.h"
 
 /* process object */
 
@@ -97,6 +98,7 @@ static void process_poll_event( struct fd *fd, int event );
 static struct list *process_get_kernel_obj_list( struct object *obj );
 static void process_destroy( struct object *obj );
 static struct esync_fd *process_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int process_get_msync_idx( struct object *obj, enum msync_type *type );
 static void terminate_process( struct process *process, struct thread *skip, int exit_code );
 
 static const struct object_ops process_ops =
@@ -108,6 +110,7 @@ static const struct object_ops process_ops =
     remove_queue,                /* remove_queue */
     process_signaled,            /* signaled */
     process_get_esync_fd,        /* get_esync_fd */
+    process_get_msync_idx,       /* get_msync_idx */
     no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
@@ -160,6 +163,7 @@ static const struct object_ops startup_info_ops =
     remove_queue,                  /* remove_queue */
     startup_info_signaled,         /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
@@ -222,6 +226,7 @@ static const struct object_ops job_ops =
     remove_queue,                  /* remove_queue */
     job_signaled,                  /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
@@ -843,6 +848,7 @@ struct process *create_process( int fd, struct process *parent, unsigned int fla
     process->rawinput_kbd    = NULL;
     memset( &process->image_info, 0, sizeof(process->image_info) );
     process->esync_fd        = NULL;
+    process->msync_idx       = 0;
     list_init( &process->kernel_object );
     list_init( &process->thread_list );
     list_init( &process->locks );
@@ -900,6 +906,9 @@ struct process *create_process( int fd, struct process *parent, unsigned int fla
      * makes more sense for the time being. */
     if (!token_assign_label( process->token, &high_label_sid ))
         goto error;
+    
+    if (do_msync())
+        process->msync_idx = msync_alloc_shm( 0, 0 );
 
     if (do_esync())
         process->esync_fd = esync_create_fd( 0, 0 );
@@ -951,6 +960,7 @@ static void process_destroy( struct object *obj )
     free( process->dir_cache );
     free( process->image );
     if (do_esync()) esync_close_fd( process->esync_fd );
+    if (do_msync()) msync_destroy_semaphore( process->msync_idx );
 }
 
 /* dump a process on stdout for debugging purposes */
@@ -975,6 +985,13 @@ static struct esync_fd *process_get_esync_fd( struct object *obj, enum esync_typ
     return process->esync_fd;
 }
 
+static unsigned int process_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct process *process = (struct process *)obj;
+    *type = MSYNC_MANUAL_SERVER;
+    return process->msync_idx;
+}
+
 static unsigned int process_map_access( struct object *obj, unsigned int access )
 {
     access = default_map_access( obj, access );
diff --git a/wine/server/process.h b/wine/server/process.h
index fc01e8b80..9db413acd 100644
--- a/wine/server/process.h
+++ b/wine/server/process.h
@@ -92,6 +92,7 @@ struct process
     struct list          kernel_object;   /* list of kernel object pointers */
     pe_image_info_t      image_info;      /* main exe image info */
     struct esync_fd     *esync_fd;        /* esync file descriptor (signaled on exit) */
+    unsigned int         msync_idx;
 };
 
 /* process functions */
diff --git a/wine/server/protocol.def b/wine/server/protocol.def
index 6232eebd2..668507860 100644
--- a/wine/server/protocol.def
+++ b/wine/server/protocol.def
@@ -3830,3 +3830,57 @@ enum esync_type
 /* Retrieve the fd to wait on for user APCs. */
 @REQ(get_esync_apc_fd)
 @END
+
+enum msync_type
+{
+    MSYNC_SEMAPHORE = 1,
+    MSYNC_AUTO_EVENT,
+    MSYNC_MANUAL_EVENT,
+    MSYNC_MUTEX,
+    MSYNC_AUTO_SERVER,
+    MSYNC_MANUAL_SERVER,
+    MSYNC_QUEUE,
+};
+
+/* Create a new mach-based synchronization object */
+@REQ(create_msync)
+    unsigned int access;        /* wanted access rights */
+    int low;                    /* initial value of low word */
+    int high;                   /* initial value of high word */
+    int type;                   /* type of msync object */
+    VARARG(objattr,object_attributes); /* object attributes */
+@REPLY
+    obj_handle_t handle;        /* handle to the object */
+    int type;                   /* type of msync object */
+    unsigned int shm_idx;       /* this object's index into the shm section */
+@END
+
+/* Open an msync object */
+@REQ(open_msync)
+    unsigned int access;        /* wanted access rights */
+    unsigned int attributes;    /* object attributes */
+    obj_handle_t rootdir;       /* root directory */
+    int          type;          /* type of msync object */
+    VARARG(name,unicode_str);   /* object name */
+@REPLY
+    obj_handle_t handle;        /* handle to the event */
+    int          type;          /* type of msync object */
+    unsigned int shm_idx;       /* this object's index into the shm section */
+@END
+
+/* Retrieve the shm index for an object. */
+@REQ(get_msync_idx)
+    obj_handle_t handle;        /* handle to the object */
+@REPLY
+    int          type;
+    unsigned int shm_idx;
+@END
+
+@REQ(msync_msgwait)
+    int          in_msgwait;    /* are we in a message wait? */
+@END
+
+@REQ(get_msync_apc_idx)
+@REPLY
+    unsigned int shm_idx;
+@END
diff --git a/wine/server/queue.c b/wine/server/queue.c
index 6d37cb2c6..8cdd76fe8 100644
--- a/wine/server/queue.c
+++ b/wine/server/queue.c
@@ -42,6 +42,7 @@
 #include "request.h"
 #include "user.h"
 #include "esync.h"
+#include "msync.h"
 
 #define WM_NCMOUSEFIRST WM_NCMOUSEMOVE
 #define WM_NCMOUSELAST  (WM_NCMOUSEFIRST+(WM_MOUSELAST-WM_MOUSEFIRST))
@@ -141,6 +142,8 @@ struct msg_queue
     timeout_t              last_get_msg;    /* time of last get message call */
     struct esync_fd       *esync_fd;        /* esync file descriptor (signalled on message) */
     int                    esync_in_msgwait; /* our thread is currently waiting on us */
+    unsigned int           msync_idx;
+    int                    msync_in_msgwait; /* our thread is currently waiting on us */
     /* FIXME: consider something cleaner */
     int                    pending_surface_flush; /* flag if there is a surface flush expected
                                                    * on this queue (meaning that queue needs
@@ -165,6 +168,7 @@ static int msg_queue_add_queue( struct object *obj, struct wait_queue_entry *ent
 static void msg_queue_remove_queue( struct object *obj, struct wait_queue_entry *entry );
 static int msg_queue_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *msg_queue_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int msg_queue_get_msync_idx( struct object *obj, enum msync_type *type );
 static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void msg_queue_destroy( struct object *obj );
 static void msg_queue_poll_event( struct fd *fd, int event );
@@ -181,6 +185,7 @@ static const struct object_ops msg_queue_ops =
     msg_queue_remove_queue,    /* remove_queue */
     msg_queue_signaled,        /* signaled */
     msg_queue_get_esync_fd,    /* get_esync_fd */
+    msg_queue_get_msync_idx,   /* get_msync_idx */
     msg_queue_satisfied,       /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
@@ -219,6 +224,7 @@ static const struct object_ops thread_input_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
@@ -318,6 +324,8 @@ static struct msg_queue *create_msg_queue( struct thread *thread, struct thread_
         queue->last_get_msg    = current_time;
         queue->esync_fd        = NULL;
         queue->esync_in_msgwait = 0;
+        queue->msync_idx       = 0;
+        queue->msync_in_msgwait = 0;
         queue->pending_surface_flush = 0;
         queue->surface_flushed = NULL;
         list_init( &queue->send_result );
@@ -328,6 +336,9 @@ static struct msg_queue *create_msg_queue( struct thread *thread, struct thread_
 
         if (do_esync())
             queue->esync_fd = esync_create_fd( 0, 0 );
+        
+        if (do_msync())
+            queue->msync_idx = msync_alloc_shm( 0, 0 );
 
         thread->queue = queue;
     }
@@ -507,6 +518,9 @@ static inline void clear_queue_bits( struct msg_queue *queue, unsigned int bits
 {
     queue->wake_bits &= ~bits;
     queue->changed_bits &= ~bits;
+    
+    if (do_msync() && !is_signaled( queue ))
+        msync_clear( &queue->obj );
 
     if (do_esync() && !is_signaled( queue ))
         esync_clear( queue->esync_fd );
@@ -960,6 +974,9 @@ static int is_queue_hung( struct msg_queue *queue )
             return 0;  /* thread is waiting on queue -> not hung */
     }
 
+    if (do_msync() && queue->msync_in_msgwait)
+        return 0;   /* thread is waiting on queue in absentia -> not hung */
+
     if (do_esync() && queue->esync_in_msgwait)
         return 0;   /* thread is waiting on queue in absentia -> not hung */
 
@@ -1035,6 +1052,13 @@ static struct esync_fd *msg_queue_get_esync_fd( struct object *obj, enum esync_t
     return queue->esync_fd;
 }
 
+static unsigned int msg_queue_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+    *type = MSYNC_QUEUE;
+    return queue->msync_idx;
+}
+
 static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct msg_queue *queue = (struct msg_queue *)obj;
@@ -1082,6 +1106,9 @@ static void msg_queue_destroy( struct object *obj )
 
     if (do_esync())
         esync_close_fd( queue->esync_fd );
+    
+    if (do_msync())
+        msync_destroy_semaphore( queue->msync_idx );
 }
 
 static void msg_queue_poll_event( struct fd *fd, int event )
@@ -2487,6 +2514,8 @@ DECL_HANDLER(set_queue_mask)
             if (req->skip_wait) queue->wake_mask = queue->changed_mask = 0;
             else wake_up( &queue->obj, 0 );
         }
+        if (do_msync() && !is_signaled( queue ))
+            msync_clear( &queue->obj );
 
         if (do_esync() && !is_signaled( queue ))
             esync_clear( queue->esync_fd );
@@ -2504,6 +2533,9 @@ DECL_HANDLER(get_queue_status)
         reply->changed_bits = queue->changed_bits;
         queue->changed_bits &= ~req->clear_bits;
 
+        if (do_msync() && !is_signaled( queue ))
+            msync_clear( &queue->obj );
+
         if (do_esync() && !is_signaled( queue ))
             esync_clear( queue->esync_fd );
     }
@@ -2760,6 +2792,9 @@ DECL_HANDLER(get_message)
     queue->wake_mask = req->wake_mask;
     queue->changed_mask = req->changed_mask;
     set_error( STATUS_PENDING );  /* FIXME */
+    
+    if (do_msync() && !is_signaled( queue ))
+        msync_clear( &queue->obj );
 
     if (do_esync() && !is_signaled( queue ))
         esync_clear( queue->esync_fd );
@@ -3498,3 +3533,18 @@ DECL_HANDLER(esync_msgwait)
     if (queue->fd)
         set_fd_events( queue->fd, req->in_msgwait ? POLLIN : 0 );
 }
+
+DECL_HANDLER(msync_msgwait)
+{
+    struct msg_queue *queue = get_current_queue();
+
+    if (!queue) return;
+    queue->msync_in_msgwait = req->in_msgwait;
+
+    if (current->process->idle_event && !(queue->wake_mask & QS_SMRESULT))
+        set_event( current->process->idle_event );
+
+    /* and start/stop waiting on the driver */
+    if (queue->fd)
+        set_fd_events( queue->fd, req->in_msgwait ? POLLIN : 0 );
+}
diff --git a/wine/server/registry.c b/wine/server/registry.c
index b2a7214f4..ca7e43ead 100644
--- a/wine/server/registry.c
+++ b/wine/server/registry.c
@@ -184,6 +184,7 @@ static const struct object_ops key_ops =
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
     NULL,                    /* get_esync_fd */
+    NULL,                    /* get_msync_idx */
     NULL,                    /* satisfied */
     no_signal,               /* signal */
     no_get_fd,               /* get_fd */
diff --git a/wine/server/request.c b/wine/server/request.c
index ca83fdbd2..753e78d84 100644
--- a/wine/server/request.c
+++ b/wine/server/request.c
@@ -91,6 +91,7 @@ static const struct object_ops master_socket_ops =
     NULL,                          /* remove_queue */
     NULL,                          /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     NULL,                          /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
diff --git a/wine/server/request.h b/wine/server/request.h
index 6f9f6a8df..a1eada5af 100644
--- a/wine/server/request.h
+++ b/wine/server/request.h
@@ -403,6 +403,11 @@ DECL_HANDLER(get_esync_read_fd);
 DECL_HANDLER(get_esync_write_fd);
 DECL_HANDLER(esync_msgwait);
 DECL_HANDLER(get_esync_apc_fd);
+DECL_HANDLER(create_msync);
+DECL_HANDLER(open_msync);
+DECL_HANDLER(get_msync_idx);
+DECL_HANDLER(msync_msgwait);
+DECL_HANDLER(get_msync_apc_idx);
 
 #ifdef WANT_REQUEST_HANDLERS
 
@@ -693,6 +698,11 @@ static const req_handler req_handlers[REQ_NB_REQUESTS] =
     (req_handler)req_get_esync_write_fd,
     (req_handler)req_esync_msgwait,
     (req_handler)req_get_esync_apc_fd,
+    (req_handler)req_create_msync,
+    (req_handler)req_open_msync,
+    (req_handler)req_get_msync_idx,
+    (req_handler)req_msync_msgwait,
+    (req_handler)req_get_msync_apc_idx,
 };
 
 C_ASSERT( sizeof(abstime_t) == 8 );
@@ -2314,6 +2324,34 @@ C_ASSERT( sizeof(struct get_esync_write_fd_reply) == 8 );
 C_ASSERT( FIELD_OFFSET(struct esync_msgwait_request, in_msgwait) == 12 );
 C_ASSERT( sizeof(struct esync_msgwait_request) == 16 );
 C_ASSERT( sizeof(struct get_esync_apc_fd_request) == 16 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_request, access) == 12 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_request, low) == 16 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_request, high) == 20 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_request, type) == 24 );
+C_ASSERT( sizeof(struct create_msync_request) == 32 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_reply, handle) == 8 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_reply, type) == 12 );
+C_ASSERT( FIELD_OFFSET(struct create_msync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct create_msync_reply) == 24 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_request, access) == 12 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_request, attributes) == 16 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_request, rootdir) == 20 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_request, type) == 24 );
+C_ASSERT( sizeof(struct open_msync_request) == 32 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_reply, handle) == 8 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_reply, type) == 12 );
+C_ASSERT( FIELD_OFFSET(struct open_msync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct open_msync_reply) == 24 );
+C_ASSERT( FIELD_OFFSET(struct get_msync_idx_request, handle) == 12 );
+C_ASSERT( sizeof(struct get_msync_idx_request) == 16 );
+C_ASSERT( FIELD_OFFSET(struct get_msync_idx_reply, type) == 8 );
+C_ASSERT( FIELD_OFFSET(struct get_msync_idx_reply, shm_idx) == 12 );
+C_ASSERT( sizeof(struct get_msync_idx_reply) == 16 );
+C_ASSERT( FIELD_OFFSET(struct msync_msgwait_request, in_msgwait) == 12 );
+C_ASSERT( sizeof(struct msync_msgwait_request) == 16 );
+C_ASSERT( sizeof(struct get_msync_apc_idx_request) == 16 );
+C_ASSERT( FIELD_OFFSET(struct get_msync_apc_idx_reply, shm_idx) == 8 );
+C_ASSERT( sizeof(struct get_msync_apc_idx_reply) == 16 );
 
 #endif  /* WANT_REQUEST_HANDLERS */
 
diff --git a/wine/server/semaphore.c b/wine/server/semaphore.c
index e3889f246..8d3c325c0 100644
--- a/wine/server/semaphore.c
+++ b/wine/server/semaphore.c
@@ -71,6 +71,7 @@ static const struct object_ops semaphore_ops =
     remove_queue,                  /* remove_queue */
     semaphore_signaled,            /* signaled */
     NULL,                          /* get_esync_fd */
+    NULL,                          /* get_msync_idx */
     semaphore_satisfied,           /* satisfied */
     semaphore_signal,              /* signal */
     no_get_fd,                     /* get_fd */
diff --git a/wine/server/serial.c b/wine/server/serial.c
index 11e204e44..60a173bc4 100644
--- a/wine/server/serial.c
+++ b/wine/server/serial.c
@@ -86,6 +86,7 @@ static const struct object_ops serial_ops =
     remove_queue,                 /* remove_queue */
     default_fd_signaled,          /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     serial_get_fd,                /* get_fd */
diff --git a/wine/server/signal.c b/wine/server/signal.c
index 55cd6aa03..e86ad49df 100644
--- a/wine/server/signal.c
+++ b/wine/server/signal.c
@@ -63,6 +63,7 @@ static const struct object_ops handler_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
diff --git a/wine/server/sock.c b/wine/server/sock.c
index b0432b6a3..3d109d520 100644
--- a/wine/server/sock.c
+++ b/wine/server/sock.c
@@ -256,6 +256,7 @@ static const struct object_ops sock_ops =
     remove_queue,                 /* remove_queue */
     default_fd_signaled,          /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     sock_get_fd,                  /* get_fd */
@@ -3167,6 +3168,7 @@ static const struct object_ops ifchange_ops =
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
     NULL,                    /* get_esync_fd */
+    NULL,                    /* get_msync_idx */
     no_satisfied,            /* satisfied */
     no_signal,               /* signal */
     ifchange_get_fd,         /* get_fd */
@@ -3389,6 +3391,7 @@ static const struct object_ops socket_device_ops =
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
     NULL,                       /* get_esync_fd */
+    NULL,                       /* get_msync_idx */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
diff --git a/wine/server/symlink.c b/wine/server/symlink.c
index 8cb24b4ff..abcc4c750 100644
--- a/wine/server/symlink.c
+++ b/wine/server/symlink.c
@@ -72,6 +72,7 @@ static const struct object_ops symlink_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
diff --git a/wine/server/thread.c b/wine/server/thread.c
index cf9591426..524807543 100644
--- a/wine/server/thread.c
+++ b/wine/server/thread.c
@@ -51,6 +51,7 @@
 #include "user.h"
 #include "security.h"
 #include "esync.h"
+#include "msync.h"
 
 
 /* thread queues */
@@ -98,6 +99,7 @@ static const struct object_ops thread_apc_ops =
     remove_queue,               /* remove_queue */
     thread_apc_signaled,        /* signaled */
     NULL,                       /* get_esync_fd */
+    NULL,                       /* get_msync_idx */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
@@ -144,6 +146,7 @@ static const struct object_ops context_ops =
     remove_queue,               /* remove_queue */
     context_signaled,           /* signaled */
     NULL,                       /* get_esync_fd */
+    NULL,                       /* get_msync_idx */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
@@ -181,6 +184,7 @@ struct type_descr thread_type =
 static void dump_thread( struct object *obj, int verbose );
 static int thread_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *thread_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int thread_get_msync_idx( struct object *obj, enum msync_type *type );
 static unsigned int thread_map_access( struct object *obj, unsigned int access );
 static void thread_poll_event( struct fd *fd, int event );
 static struct list *thread_get_kernel_obj_list( struct object *obj );
@@ -195,6 +199,7 @@ static const struct object_ops thread_ops =
     remove_queue,               /* remove_queue */
     thread_signaled,            /* signaled */
     thread_get_esync_fd,        /* get_esync_fd */
+    thread_get_msync_idx,       /* get_msync_idx */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
@@ -236,6 +241,7 @@ static inline void init_thread_structure( struct thread *thread )
     thread->entry_point     = 0;
     thread->esync_fd        = NULL;
     thread->esync_apc_fd    = NULL;
+    thread->msync_idx       = 0;
     thread->system_regs     = 0;
     thread->queue           = NULL;
     thread->wait            = NULL;
@@ -382,6 +388,12 @@ struct thread *create_thread( int fd, struct process *process, const struct secu
             release_object( desktop );
         }
     }
+    
+    if (do_msync())
+    {
+        thread->msync_idx = msync_alloc_shm( 0, 0 );
+        thread->msync_apc_idx = msync_alloc_shm( 0, 0 );
+    }
 
     if (do_esync())
     {
@@ -473,6 +485,12 @@ static void destroy_thread( struct object *obj )
         esync_close_fd( thread->esync_fd );
         esync_close_fd( thread->esync_apc_fd );
     }
+    
+    if (do_msync())
+    {
+        msync_destroy_semaphore( thread->msync_idx );
+        msync_destroy_semaphore( thread->msync_apc_idx );
+    }
 }
 
 /* dump a thread on stdout for debugging purposes */
@@ -498,6 +516,13 @@ static struct esync_fd *thread_get_esync_fd( struct object *obj, enum esync_type
     return thread->esync_fd;
 }
 
+static unsigned int thread_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct thread *thread = (struct thread *)obj;
+    *type = MSYNC_MANUAL_SERVER;
+    return thread->msync_idx;
+}
+
 static unsigned int thread_map_access( struct object *obj, unsigned int access )
 {
     access = default_map_access( obj, access );
@@ -549,6 +574,7 @@ static struct thread_apc *create_apc( struct object *owner, const apc_call_t *ca
         apc->result.type = APC_NONE;
         if (owner) grab_object( owner );
     }
+
     return apc;
 }
 
@@ -1088,6 +1114,9 @@ void wake_up( struct object *obj, int max )
     struct list *ptr;
     int ret;
 
+    if (do_msync())
+        msync_wake_up( obj );
+
     if (do_esync())
         esync_wake_up( obj );
 
@@ -1178,6 +1207,9 @@ static int queue_apc( struct process *process, struct thread *thread, struct thr
     {
         wake_thread( thread );
 
+        if (do_msync() && queue == &thread->user_apc)
+            msync_signal_all( thread->msync_apc_idx );
+
         if (do_esync() && queue == &thread->user_apc)
             esync_wake_fd( thread->esync_apc_fd );
     }
@@ -1228,6 +1260,9 @@ static struct thread_apc *thread_dequeue_apc( struct thread *thread, int system
         list_remove( ptr );
     }
 
+    if (do_msync() && list_empty( &thread->system_apc ) && list_empty( &thread->user_apc ))
+        msync_clear( &thread->obj );
+
     if (do_esync() && list_empty( &thread->system_apc ) && list_empty( &thread->user_apc ))
         esync_clear( thread->esync_apc_fd );
 
@@ -1326,6 +1361,8 @@ void kill_thread( struct thread *thread, int violent_death )
     }
     kill_console_processes( thread, 0 );
     abandon_mutexes( thread );
+    if (do_msync())
+        msync_abandon_mutexes( thread );
     if (do_esync())
         esync_abandon_mutexes( thread );
     wake_up( &thread->obj, 0 );
diff --git a/wine/server/thread.h b/wine/server/thread.h
index 3ed439b3f..fc3459e5b 100644
--- a/wine/server/thread.h
+++ b/wine/server/thread.h
@@ -56,6 +56,8 @@ struct thread
     struct list            mutex_list;    /* list of currently owned mutexes */
     struct esync_fd       *esync_fd;      /* esync file descriptor (signalled on exit) */
     struct esync_fd       *esync_apc_fd;  /* esync apc fd (signalled when APCs are present) */
+    unsigned int           msync_idx;
+    unsigned int           msync_apc_idx;
     unsigned int           system_regs;   /* which system regs have been set */
     struct msg_queue      *queue;         /* message queue */
     struct thread_wait    *wait;          /* current wait condition if sleeping */
diff --git a/wine/server/timer.c b/wine/server/timer.c
index 7ae923f6b..cf924a5bf 100644
--- a/wine/server/timer.c
+++ b/wine/server/timer.c
@@ -36,6 +36,7 @@
 #include "handle.h"
 #include "request.h"
 #include "esync.h"
+#include "msync.h"
 
 static const WCHAR timer_name[] = {'T','i','m','e','r'};
 
@@ -63,11 +64,13 @@ struct timer
     client_ptr_t         callback;  /* callback APC function */
     client_ptr_t         arg;       /* callback argument */
     struct esync_fd     *esync_fd;  /* esync file descriptor */
+    unsigned int         msync_idx; /* msync shm index */
 };
 
 static void timer_dump( struct object *obj, int verbose );
 static int timer_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct esync_fd *timer_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int timer_get_msync_idx( struct object *obj, enum msync_type *type );
 static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void timer_destroy( struct object *obj );
 
@@ -80,6 +83,7 @@ static const struct object_ops timer_ops =
     remove_queue,              /* remove_queue */
     timer_signaled,            /* signaled */
     timer_get_esync_fd,        /* get_esync_fd */
+    timer_get_msync_idx,       /* get_msync_idx */
     timer_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
@@ -115,6 +119,9 @@ static struct timer *create_timer( struct object *root, const struct unicode_str
             timer->timeout  = NULL;
             timer->thread   = NULL;
             timer->esync_fd = NULL;
+            
+            if (do_msync())
+                timer->msync_idx = msync_alloc_shm( 0, 0 );
 
             if (do_esync())
                 timer->esync_fd = esync_create_fd( 0, 0 );
@@ -190,6 +197,9 @@ static int set_timer( struct timer *timer, timeout_t expire, unsigned int period
         period = 0;  /* period doesn't make any sense for a manual timer */
         timer->signaled = 0;
 
+        if (do_msync())
+            msync_clear( &timer->obj );
+
         if (do_esync())
             esync_clear( timer->esync_fd );
     }
@@ -226,6 +236,13 @@ static struct esync_fd *timer_get_esync_fd( struct object *obj, enum esync_type
     return timer->esync_fd;
 }
 
+static unsigned int timer_get_msync_idx( struct object *obj, enum msync_type *type )
+{
+    struct timer *timer = (struct timer *)obj;
+    *type = timer->manual ? MSYNC_MANUAL_SERVER : MSYNC_AUTO_SERVER;
+    return timer->msync_idx;
+}
+
 static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct timer *timer = (struct timer *)obj;
@@ -242,6 +259,8 @@ static void timer_destroy( struct object *obj )
     if (timer->thread) release_object( timer->thread );
     if (do_esync())
         esync_close_fd( timer->esync_fd );
+    if (do_msync())
+        msync_destroy_semaphore( timer->msync_idx );
 }
 
 /* create a timer */
diff --git a/wine/server/token.c b/wine/server/token.c
index 76a6bc279..599cf3512 100644
--- a/wine/server/token.c
+++ b/wine/server/token.c
@@ -151,6 +151,7 @@ static const struct object_ops token_ops =
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
     NULL,                      /* get_esync_fd */
+    NULL,                      /* get_msync_idx */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
diff --git a/wine/server/trace.c b/wine/server/trace.c
index 62a1a4a23..c5531220a 100644
--- a/wine/server/trace.c
+++ b/wine/server/trace.c
@@ -4567,6 +4567,63 @@ static void dump_get_esync_apc_fd_request( const struct get_esync_apc_fd_request
 {
 }
 
+static void dump_create_msync_request( const struct create_msync_request *req )
+{
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", low=%d", req->low );
+    fprintf( stderr, ", high=%d", req->high );
+    fprintf( stderr, ", type=%d", req->type );
+    dump_varargs_object_attributes( ", objattr=", cur_size );
+}
+
+static void dump_create_msync_reply( const struct create_msync_reply *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_open_msync_request( const struct open_msync_request *req )
+{
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", attributes=%08x", req->attributes );
+    fprintf( stderr, ", rootdir=%04x", req->rootdir );
+    fprintf( stderr, ", type=%d", req->type );
+    dump_varargs_unicode_str( ", name=", cur_size );
+}
+
+static void dump_open_msync_reply( const struct open_msync_reply *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_get_msync_idx_request( const struct get_msync_idx_request *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+}
+
+static void dump_get_msync_idx_reply( const struct get_msync_idx_reply *req )
+{
+    fprintf( stderr, " type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_msync_msgwait_request( const struct msync_msgwait_request *req )
+{
+    fprintf( stderr, " in_msgwait=%d", req->in_msgwait );
+}
+
+static void dump_get_msync_apc_idx_request( const struct get_msync_apc_idx_request *req )
+{
+}
+
+static void dump_get_msync_apc_idx_reply( const struct get_msync_apc_idx_reply *req )
+{
+    fprintf( stderr, " shm_idx=%08x", req->shm_idx );
+}
+
 static const dump_func req_dumpers[REQ_NB_REQUESTS] = {
     (dump_func)dump_new_process_request,
     (dump_func)dump_get_new_process_info_request,
@@ -4852,6 +4909,11 @@ static const dump_func req_dumpers[REQ_NB_REQUESTS] = {
     (dump_func)dump_get_esync_write_fd_request,
     (dump_func)dump_esync_msgwait_request,
     (dump_func)dump_get_esync_apc_fd_request,
+    (dump_func)dump_create_msync_request,
+    (dump_func)dump_open_msync_request,
+    (dump_func)dump_get_msync_idx_request,
+    (dump_func)dump_msync_msgwait_request,
+    (dump_func)dump_get_msync_apc_idx_request,
 };
 
 static const dump_func reply_dumpers[REQ_NB_REQUESTS] = {
@@ -5139,6 +5201,11 @@ static const dump_func reply_dumpers[REQ_NB_REQUESTS] = {
     NULL,
     NULL,
     NULL,
+    (dump_func)dump_create_msync_reply,
+    (dump_func)dump_open_msync_reply,
+    (dump_func)dump_get_msync_idx_reply,
+    NULL,
+    (dump_func)dump_get_msync_apc_idx_reply,
 };
 
 static const char * const req_names[REQ_NB_REQUESTS] = {
@@ -5426,6 +5493,11 @@ static const char * const req_names[REQ_NB_REQUESTS] = {
     "get_esync_write_fd",
     "esync_msgwait",
     "get_esync_apc_fd",
+    "create_msync",
+    "open_msync",
+    "get_msync_idx",
+    "msync_msgwait",
+    "get_msync_apc_idx",
 };
 
 static const struct
diff --git a/wine/server/window.c b/wine/server/window.c
index 7a5827326..89e4df0b8 100644
--- a/wine/server/window.c
+++ b/wine/server/window.c
@@ -110,6 +110,7 @@ static const struct object_ops window_ops =
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
     NULL,                     /* get_esync_fd */
+    NULL,                     /* get_msync_idx */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
@@ -151,6 +152,7 @@ static const struct object_ops shm_surface_ops =
     remove_queue,                /* remove_queue */
     shm_surface_signaled,        /* signaled */
     NULL,                        /* get_esync_fd */
+    NULL,                        /* get_msync_idx */
     no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
diff --git a/wine/server/winstation.c b/wine/server/winstation.c
index a99c60a28..43fe6b44f 100644
--- a/wine/server/winstation.c
+++ b/wine/server/winstation.c
@@ -76,6 +76,7 @@ static const struct object_ops winstation_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
@@ -117,6 +118,7 @@ static const struct object_ops desktop_ops =
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
     NULL,                         /* get_esync_fd */
+    NULL,                         /* get_msync_idx */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-- 
2.39.3 (Apple Git-145)

